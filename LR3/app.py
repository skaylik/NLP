# ============================================================
# –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ò–ú–ü–û–†–¢ –ú–û–î–£–õ–ï–ô
# ============================================================
import streamlit as st

# –°–ù–ê–ß–ê–õ–ê –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
st.set_page_config(
    page_title="–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–π –ø—Ä–∞–∫—Ç–∏–∫—É–º ‚Ññ3",
    page_icon="üß™",
    layout="wide"
)

# –ü–û–¢–û–ú –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏
import pandas as pd
import numpy as np
import json
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import traceback
import zipfile
import io
import os
import sys

# PyTorch –∏–º–ø–æ—Ä—Ç—ã
try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# –ù–∞—à–∏ –º–æ–¥—É–ª–∏
try:
    from auto_labeling import AutoLabeler
    from data_splitter import StratifiedDataSplitter
    from text_preprocessing import TextDataProcessor
    MODULES_AVAILABLE = True
except ImportError:
    MODULES_AVAILABLE = False

# –ú–æ–¥—É–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ - –û–î–ò–ù –∏–º–ø–æ—Ä—Ç –í–°–ï–ì–û –ù–£–ñ–ù–û–ì–û
try:
    from classical_classifiers import ClassicalClassifier, ModelComparator, create_model_configs, train_all_tasks
    CLASSIFIERS_AVAILABLE = True
except ImportError:
    CLASSIFIERS_AVAILABLE = False
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è ModelComparator –∏ –¥—Ä—É–≥–∏—Ö
    class ModelComparator:
        def __init__(self, models_config=None):
            self.models_config = models_config or []
            self.models = {}
            self.results = {}
            self.best_model = None
            self.best_score = 0
            self.best_model_name = None
        
        def add_model(self, model_name, model):
            self.models[model_name] = model
        
        def train_and_compare(self, X_train, y_train, X_val=None, y_val=None, task_name='category'):
            return {}
        
        def get_best_model(self):
            return None
    
    def create_model_configs(task_type='category'):
        return []
    
    def train_all_tasks(X_train, y_train_all, X_val, y_val_all, task_names=None):
        return {}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —ç—Ç–∞–ø–∞ 3
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    import catboost as cb
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False

try:
    from tpot import TPOTClassifier
    TPOT_AVAILABLE = True
except ImportError:
    TPOT_AVAILABLE = False

try:
    import h2o
    from h2o.automl import H2OAutoML
    H2O_AVAILABLE = True
except ImportError:
    H2O_AVAILABLE = False

# –ú–æ–¥—É–ª—å –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
try:
    from neural_classifiers import (
        SimpleNNClassifier, 
        CNNClassifier, 
        RNNClassifier, 
        TransformerClassifier,
        NeuralModelComparator,
        TextDataset,
        create_neural_pipeline,
        train_and_evaluate_neural_model
    )
    NEURAL_MODULES_AVAILABLE = True
except ImportError:
    NEURAL_MODULES_AVAILABLE = False

# 5 —ç—Ç–∞–ø
try:
    from imbalance_handling import (
        ClassWeightBalancer,
        SamplingBalancer,
        TextAugmenter,
        ClassBalanceAnalyzer,
        ImbalanceHandler,
        create_imbalance_report,
        visualize_imbalance_comparison,
        get_available_balancing_methods,
        get_available_augmentation_methods
    )
    IMBALANCE_MODULES_AVAILABLE = True
except ImportError:
    IMBALANCE_MODULES_AVAILABLE = False

# 6 —ç—Ç–∞–ø
try:
    from advanced_tuning import (
        create_tuning_pipeline,
        AdvancedModelTuner,
        CrossValidationManager,
        HyperparameterOptimizer,
        ComprehensiveModelEvaluator,
        analyze_model_stability,
        UniversalModelWrapper  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É
    )
    TUNING_MODULES_AVAILABLE = True
    st.success("‚úÖ –ú–æ–¥—É–ª—å advanced_tuning –∑–∞–≥—Ä—É–∂–µ–Ω (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    
except ImportError as e:
    TUNING_MODULES_AVAILABLE = False
    st.warning(f"‚ö†Ô∏è –ú–æ–¥—É–ª—å advanced_tuning –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}")
    st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª advanced_tuning.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")

# 7 —ç—Ç–∞–ø
try:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ final_analysis.py –≤–º–µ—Å—Ç–æ –∫–ª–∞—Å—Å–∞ FinalModelAnalyzer
    from final_analysis import perform_complete_analysis, create_final_analysis_pipeline
    FINAL_ANALYSIS_AVAILABLE = True
    
    def create_final_analyzer():
        """–°–æ–∑–¥–∞–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        return create_final_analysis_pipeline()
except ImportError as e:
    st.error(f"‚ùå –ú–æ–¥—É–ª—å final_analysis –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}")
    st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª final_analysis.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    FINAL_ANALYSIS_AVAILABLE = False

# ============================================================
# –ó–ê–ì–õ–£–®–ö–ò –î–õ–Ø –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–• –ö–õ–ê–°–°–û–í
# ============================================================

class SimpleClassifierStub:
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞, –µ—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω"""
    def __init__(self, is_multi_label=False):
        self.is_multi_label = is_multi_label
        self.is_trained = False
    
    def fit(self, X, y, X_val=None, y_val=None):
        self.is_trained = True
        return self
    
    def predict(self, X):
        if self.is_multi_label:
            # –î–ª—è multi-label –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ 0/1
            return np.random.randint(0, 2, size=(len(X), 3))  # 3 —Ç–µ–≥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        else:
            # –î–ª—è –æ–±—ã—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–µ—Ç–∫–∏
            return np.random.randint(0, 5, size=len(X))  # 5 –∫–ª–∞—Å—Å–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def evaluate(self, X, y_true):
        return {
            'accuracy': 0.5,
            'f1': 0.5,
            'precision': 0.5,
            'recall': 0.5,
            'is_multi_label': self.is_multi_label
        }


class EnsembleClassifier:
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    def __init__(self, **kwargs):
        pass


class AutoMLClassifier:
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è AutoML"""
    def __init__(self, **kwargs):
        pass


# ============================================================
# –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ï–°–°–ò–ò
# ============================================================
def init_session_state():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏"""
    session_vars = {
        # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        "raw_data": None,
        "dataframe": None,
        "labeled_articles": None,
        "data_splits": None,
        "splitter": None,
        "text_processor": None,
        "processed_results": None,
        "last_file_name": None,
        
        # –°—Ç–∞—Ç—É—Å—ã —ç—Ç–∞–ø–æ–≤
        "step1_completed": False,  # –≠—Ç–∞–ø 1: –†–∞–∑–º–µ—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        "step2_completed": False,  # –≠—Ç–∞–ø 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        "step3_completed": False,  # –≠—Ç–∞–ø 3: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        "step4_completed": False,  # –≠—Ç–∞–ø 4: –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏
        "step5_completed": False,  # –≠—Ç–∞–ø 5: –ë–æ—Ä—å–±–∞ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
        "step6_completed": False,  # –≠—Ç–∞–ø 6: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        "step7_completed": False,  # –≠—Ç–∞–ø 7: –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        "step8_completed": False,  # –≠—Ç–∞–ø 8: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        
        # –î–ª—è —ç—Ç–∞–ø–∞ 3 (–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
        "comparator": None,
        "comparison_results": None,
        "best_model": None,
        "test_metrics": None,
        "training_completed": False,
        "unique_classes": None,
        
        # –î–ª—è —ç—Ç–∞–ø–∞ 4 (–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏)
        "neural_models": {},
        "neural_results": {},
        "neural_best_model": None,
        "neural_comparator": None,
        "neural_training_history": {},
        "neural_training_completed": False,
        "neural_label_field": 'category',
        
        # –î–ª—è —ç—Ç–∞–ø–∞ 5 (–î–∏—Å–±–∞–ª–∞–Ω—Å)
        "balanced_data": {},
        "balanced_models": {},
        "imbalance_handler": None,
        "class_balance_report": None,
        "original_class_distribution": None,
        "balance_analysis_completed": False,
        "balance_comparison": None,
        "imbalance_handling_completed": False,
        
        # –î–ª—è —ç—Ç–∞–ø–∞ 6 (–ù–∞—Å—Ç—Ä–æ–π–∫–∞)
        "model_tuner": None,
        "tuning_results": {},
        "evaluation_results": {},
        "best_tuned_model": None,
        "stability_analysis": None,
        "cv_results": None,
        "hyperparameter_search_completed": False,
        "comprehensive_evaluation": None,
        "feature_names": None,
        "selected_model_for_tuning": None,
        "selected_model_name_for_tuning": None,
        
        # –î–ª—è —ç—Ç–∞–ø–∞ 7 (–ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑)
        "final_analysis_completed": False,
        "final_analyzer": None,
        "champion_model": None,
        "champion_score": None,
        "champion_stage": None,
        
    }
    
    for var, default in session_vars.items():
        if var not in st.session_state:
            st.session_state[var] = default

init_session_state()

# ============================================================
# –£–¢–ò–õ–ò–¢–´
# ============================================================
def normalize_article_fields(article: dict) -> dict:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–µ–π —Å—Ç–∞—Ç—å–∏"""
    normalized = {}
    
    # –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–ª—è
    for key, value in article.items():
        normalized[key] = value
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è
    normalized["title"] = article.get("title") or article.get("–∑–∞–≥–æ–ª–æ–≤–æ–∫") or article.get("headline") or ""
    normalized["text"] = article.get("text") or article.get("–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç") or article.get("content") or article.get("body") or ""
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category = article.get("category") or article.get("–∫–∞—Ç–µ–≥–æ—Ä–∏—è") or article.get("label") or article.get("—Ç–µ–º–∞")
    if isinstance(category, dict):
        category = str(category)
    normalized["category"] = category or ""
    
    return normalized

def to_jsonl(records):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JSONL"""
    return "\n".join(json.dumps(r, ensure_ascii=False) for r in records)

def create_download_zip(files_dict, zip_name="results.zip"):
    """–°–æ–∑–¥–∞–Ω–∏–µ ZIP –∞—Ä—Ö–∏–≤–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for filename, content in files_dict.items():
            if isinstance(content, str):
                zip_file.writestr(filename, content)
            elif isinstance(content, bytes):
                zip_file.writestr(filename, content)
    zip_buffer.seek(0)
    return zip_buffer

# ============================================================
# –ó–ê–ì–û–õ–û–í–û–ö –ò –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨
# ============================================================
st.title("üß™ –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–π –ø—Ä–∞–∫—Ç–∏–∫—É–º ‚Ññ3")
st.subheader("–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö")

with st.sidebar:
    st.title("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSONL —Ñ–∞–π–ª",
        type=['jsonl', 'json'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∑–∞–ø–∏—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–æ—Ä–µ JSONL (JSON Lines)",
        key="file_uploader"
    )

# ============================================================
# –û–°–ù–û–í–ù–ê–Ø –ß–ê–°–¢–¨ - –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
# ============================================================
if uploaded_file is not None:
    try:
        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        current_file_name = uploaded_file.name
        if st.session_state.last_file_name != current_file_name:
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
            st.session_state.raw_data = None
            st.session_state.dataframe = None
            st.session_state.labeled_articles = None
            st.session_state.data_splits = None
            st.session_state.text_processor = None
            st.session_state.processed_results = None
            st.session_state.last_file_name = current_file_name
            st.session_state.step1_completed = False
            st.session_state.step2_completed = False
            st.session_state.step3_completed = False
            st.session_state.step4_completed = False
            st.session_state.comparator = None
            st.session_state.comparison_results = None
            st.session_state.best_model = None
            st.session_state.test_metrics = None
            st.session_state.training_completed = False
            # –°–±—Ä–æ—Å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
            st.session_state.neural_models = {}
            st.session_state.neural_results = {}
            st.session_state.neural_best_model = None
            st.session_state.neural_comparator = None
            st.session_state.neural_training_history = {}
            st.session_state.neural_training_completed = False
        
        # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        data = []
        error_lines = 0
        
        for i, line in enumerate(uploaded_file):
            line = line.decode('utf-8').strip()
            if line:
                try:
                    data.append(json.loads(line))
                except json.JSONDecodeError:
                    error_lines += 1
                    continue
        
        if error_lines > 0:
            st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {error_lines} —Å—Ç—Ä–æ–∫ —Å –æ—à–∏–±–∫–∞–º–∏ JSON")
        
        if not data:
            st.error("‚ùå –§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        else:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            df = pd.DataFrame(data)
            st.session_state.raw_data = data
            st.session_state.dataframe = df
            
            st.success(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(df))
            with col2:
                category_cols = [c for c in df.columns if any(word in c.lower() for word in ['–∫–∞—Ç–µ–≥–æ—Ä–∏—è', 'category', 'label'])]
                if category_cols:
                    categories = df[category_cols[0]].nunique()
                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π", categories)
                else:
                    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–π", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            with col3:
                text_cols = [c for c in df.columns if any(word in c.lower() for word in ['—Ç–µ–∫—Å—Ç', 'text', 'content'])]
                st.metric("–¢–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π", len(text_cols))
            with col4:
                date_cols = [c for c in df.columns if any(word in c.lower() for word in ['–¥–∞—Ç–∞', 'date'])]
                st.metric("–î–∞—Ç–∞", "‚úÖ" if date_cols else "‚ùå")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            if category_cols:
                st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                
                category_counts = df[category_cols[0]].value_counts().reset_index()
                category_counts.columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
                
                col1, col2 = st.columns(2)
                
                with col1:
                    fig = px.bar(category_counts.head(15), x='–ö–∞—Ç–µ–≥–æ—Ä–∏—è', y='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                                title='–¢–æ–ø-15 –∫–∞—Ç–µ–≥–æ—Ä–∏–π', color='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                                color_continuous_scale='Blues')
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    fig = px.pie(category_counts.head(10), values='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 
                                names='–ö–∞—Ç–µ–≥–æ—Ä–∏—è', title='–¢–æ–ø-10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π',
                                hole=0.3)
                    fig.update_traces(textposition='inside', textinfo='percent+label')
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
            
            # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö
            st.subheader("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.dataframe(df.head(10), use_container_width=True, height=300)
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
        st.code(traceback.format_exc())

else:
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ JSONL —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –±–æ–∫–æ–≤—É—é –ø–∞–Ω–µ–ª—å")
    
    st.markdown("### üìù –ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (JSONL)")
    example = '''{"title": "–ù–æ–≤–æ—Å—Ç–∏ –∫–∏–Ω–æ", "text": "–í—ã—à–µ–ª –Ω–æ–≤—ã–π —Ñ–∏–ª—å–º...", "category": "–ö–∏–Ω–æ"}
{"title": "–°–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è", "text": "–ù–∞—à–∏ —Å–ø–æ—Ä—Ç—Å–º–µ–Ω—ã –ø–æ–±–µ–¥–∏–ª–∏...", "category": "–°–ø–æ—Ä—Ç"}
{"title": "–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏", "text": "–†—ã–Ω–æ–∫ –ø–æ–∫–∞–∑–∞–ª —Ä–æ—Å—Ç...", "category": "–≠–∫–æ–Ω–æ–º–∏–∫–∞"}'''
    st.code(example, language='json')
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –Ω–æ –±–ª–æ–∫–∏—Ä—É–µ–º –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
    st.markdown("---")
    
    # –≠—Ç–∞–ø 1 - –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
    st.header("ü§ñ –≠—Ç–∞–ø 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    st.warning("‚è≥ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
    
    st.markdown("---")
    
    # –≠—Ç–∞–ø 2 - –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–∞ 1
    st.header("üîß –≠—Ç–∞–ø 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
    st.warning("‚è≥ –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 1 –¥–ª—è —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏")
    
    st.markdown("---")
    
    # –≠—Ç–∞–ø 3 - –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–∞ 2
    st.header("üéØ –≠—Ç–∞–ø 3: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤")
    st.warning("‚è≥ –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 2 –¥–ª—è —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏")
    
    st.markdown("---")
    
    # –≠—Ç–∞–ø 4 - –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–∞ 3
    st.header("üß† –≠—Ç–∞–ø 4: –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏")
    st.warning("‚è≥ –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 3 –¥–ª—è —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏")
    
    # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞, —á—Ç–æ–±—ã –¥–∞–ª—å—à–µ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å
    st.stop()

# ============================================================
# –≠–¢–ê–ü 1: –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –†–ê–ó–ú–ï–¢–ö–ê –ò –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•
# ============================================================
st.markdown("---")

st.header("ü§ñ –≠—Ç–∞–ø 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")

if st.session_state.raw_data is not None:
    st.markdown("""
    ### üìã –ß—Ç–æ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
    
    1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞** —Å—Ç–∞—Ç–µ–π:
       - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (positive/negative)
       - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–º–∞–º
       - –ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–¥–æ 2 —Ç–µ–º –Ω–∞ —Å—Ç–∞—Ç—å—é)
    
    2. **–°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ**:
       - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ Train/Validation/Test
       - –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ 70/15/15
       - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –∫–∞–∂–¥–æ–º —Ä–∞–∑–¥–µ–ª–µ
    """)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥—É–ª–µ–π
    if not MODULES_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª–∏ auto_labeling, data_splitter –∏–ª–∏ text_preprocessing –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
    else:
        # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–£–°–ö
        if not st.session_state.get("step1_completed", False):
            with st.spinner("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                    use_sentiment = True
                    use_multilabel = True
                    random_seed = 42
                    stratify_by = 'category'
                    
                    # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                    articles_for_labeling = [normalize_article_fields(item) for item in st.session_state.raw_data]
                    
                    # 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞
                    labeler = AutoLabeler()
                    labeled_articles = labeler.label_articles(articles_for_labeling)
                    st.session_state.labeled_articles = labeled_articles
                    
                    # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                    splitter = StratifiedDataSplitter(seed=random_seed)
                    splits = splitter.split_stratified(
                        labeled_articles,
                        train_ratio=0.7,
                        val_ratio=0.15,
                        test_ratio=0.15,
                        stratify_column=stratify_by,
                        save_splits=True,
                        output_dir="data_splits"
                    )
                    
                    st.session_state.data_splits = splits
                    st.session_state.splitter = splitter
                    st.session_state.step1_completed = True
                    
                    st.success("‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
                    st.code(traceback.format_exc())
        
        # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        if st.session_state.labeled_articles is not None:
            labeled_df = pd.DataFrame(st.session_state.labeled_articles)
            
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–º–µ—Ç–∫–∏")
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–†–∞–∑–º–µ—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π", len(labeled_df))
            with col2:
                if 'sentiment' in labeled_df.columns:
                    st.metric("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π", labeled_df['sentiment'].nunique())
                else:
                    st.metric("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π", 0)
            with col3:
                if 'category' in labeled_df.columns:
                    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–π", labeled_df['category'].nunique())
                else:
                    st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–π", 0)
            with col4:
                if 'categories' in labeled_df.columns:
                    avg_topics = labeled_df['categories'].apply(len).mean()
                    st.metric("–°—Ä. —Ç–µ–º –Ω–∞ —Å—Ç–∞—Ç—å—é", f"{avg_topics:.1f}")
                else:
                    st.metric("–°—Ä. —Ç–µ–º –Ω–∞ —Å—Ç–∞—Ç—å—é", 0)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏
            col1, col2 = st.columns(2)
            
            with col1:
                if 'sentiment' in labeled_df.columns:
                    sentiment_counts = labeled_df['sentiment'].value_counts().reset_index()
                    sentiment_counts.columns = ['–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
                    
                    fig = px.bar(sentiment_counts, x='–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', y='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π',
                                color='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', color_continuous_scale='Teal')
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                if 'category' in labeled_df.columns:
                    category_counts = labeled_df['category'].value_counts().head(10).reset_index()
                    category_counts.columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
                    
                    fig = px.pie(category_counts, values='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', names='–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                                title='–¢–æ–ø-10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π', hole=0.3)
                    fig.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig, use_container_width=True)
            
            # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if st.session_state.data_splits is not None:
                splits = st.session_state.data_splits
                
                st.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Train", len(splits['train']))
                with col2:
                    st.metric("Validation", len(splits['validation']))
                with col3:
                    st.metric("Test", len(splits['test']))
                
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
                split_data = pd.DataFrame({
                    '–†–∞–∑–¥–µ–ª': ['Train', 'Validation', 'Test'],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': [len(splits['train']), len(splits['validation']), len(splits['test'])]
                })
                
                fig = px.pie(split_data, values='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', names='–†–∞–∑–¥–µ–ª',
                            title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º',
                            color_discrete_sequence=px.colors.sequential.Blues)
                st.plotly_chart(fig, use_container_width=True)
                
                # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞–∑–¥–µ–ª–æ–≤
                with st.expander("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"):
                    tab1, tab2, tab3 = st.tabs(["Train", "Validation", "Test"])
                    
                    with tab1:
                        train_df = pd.DataFrame(splits['train'])
                        st.dataframe(train_df.head(), use_container_width=True, height=250)
                        st.caption(f"Train: {len(splits['train'])} –∑–∞–ø–∏—Å–µ–π")
                    
                    with tab2:
                        val_df = pd.DataFrame(splits['validation'])
                        st.dataframe(val_df.head(), use_container_width=True, height=250)
                        st.caption(f"Validation: {len(splits['validation'])} –∑–∞–ø–∏—Å–µ–π")
                    
                    with tab3:
                        test_df = pd.DataFrame(splits['test'])
                        st.dataframe(test_df.head(), use_container_width=True, height=250)
                        st.caption(f"Test: {len(splits['test'])} –∑–∞–ø–∏—Å–µ–π")
else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≠—Ç–∞–ø–∞ 1")

# ============================================================
# –≠–¢–ê–ü 2: –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò
# ============================================================
st.markdown("---")

st.header("üîß –≠—Ç–∞–ø 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")

if st.session_state.step1_completed:
    splits = st.session_state.data_splits
    
    st.markdown("""
    ### üìã –ß—Ç–æ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
    
    1. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞**:
       - –û—á–∏—Å—Ç–∫–∞ –æ—Ç HTML, URL, —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
       - –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
       - –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
    
    2. **–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**:
       - –ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏ (—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ, —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ, –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ)
       - –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (TF-IDF, BOW, Word2Vec, FastText, BERT)
    
    3. **–†–∞–±–æ—Ç–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏**:
       - –û–±—É—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ **Train** –¥–∞–Ω–Ω—ã—Ö
       - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ **Validation** –∏ **Test** –±–µ–∑ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    """)
    
    if not MODULES_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª—å text_preprocessing –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª text_preprocessing.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    else:
        # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–£–°–ö
        if not st.session_state.get("step2_completed", False):
            with st.spinner("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ù–ê–°–¢–†–û–ô–ö–ò
                    remove_stopwords = True
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å spaCy
                    try:
                        import spacy
                        SPACY_AVAILABLE = True
                        use_spacy = True
                    except ImportError:
                        SPACY_AVAILABLE = False
                        use_spacy = False
                    
                    extract_meta = True
                    vectorization_method = "tfidf"
                    max_features = 2000
                    text_field = 'text'
                    batch_size = 100
                    
                    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞
                    vectorizer_params = {
                        'method': vectorization_method,
                        'max_features': max_features
                    }
                    
                    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                    preprocessor_params = {
                        'language': 'russian',
                        'remove_stopwords': remove_stopwords,
                        'use_spacy': use_spacy
                    }
                    
                    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
                    processor = TextDataProcessor(
                        preprocessor_params=preprocessor_params,
                        vectorizer_params=vectorizer_params
                    )
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã
                    results = processor.process_splits_with_fallback(
                        splits,
                        extract_meta=extract_meta,
                        create_vectors=True,
                        text_field=text_field
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    st.session_state.text_processor = processor
                    st.session_state.processed_results = results
                    st.session_state.step2_completed = True
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫
                    processor.save_processed_data("processed_data")
                    
                    st.success("‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                    
                    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è fallback
                    if hasattr(processor, 'fallback_to_tfidf') and processor.fallback_to_tfidf:
                        st.warning(f"‚ö†Ô∏è –ò—Å—Ö–æ–¥–Ω—ã–π –º–µ—Ç–æ–¥ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ '{vectorization_method}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª. "
                                  f"–ë—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ 'tfidf'.")
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                    st.code(traceback.format_exc())
        
        # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        if st.session_state.get("processed_results") is not None:
            results = st.session_state.processed_results
            
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
            for split_name in ['train', 'validation', 'test']:
                if split_name in results:
                    split_results = results[split_name]
                    
                    with st.expander(f"{split_name.upper()} –Ω–∞–±–æ—Ä", expanded=(split_name == 'train')):
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("–¢–µ–∫—Å—Ç–æ–≤", len(split_results.get('processed_texts', [])))
                        
                        with col2:
                            if 'meta_features' in split_results:
                                st.metric("–ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤", 
                                         split_results['meta_features'].shape[1])
                            else:
                                st.metric("–ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤", 0)
                        
                        with col3:
                            if 'text_vectors' in split_results and split_results['text_vectors'] is not None:
                                st.metric("–í–µ–∫—Ç–æ—Ä–æ–≤", 
                                         split_results['text_vectors'].shape[1])
                            else:
                                st.metric("–í–µ–∫—Ç–æ—Ä–æ–≤", 0)
                        
                        # –ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                        if 'processed_texts' in split_results and split_results['processed_texts']:
                            st.caption("–ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
                            st.code(split_results['processed_texts'][0][:200] + "...")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            tab1, tab2, tab3 = st.tabs(["–ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏", "–í–µ–∫—Ç–æ—Ä—ã", "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ"])
            
            with tab1:
                if 'train' in results and 'meta_features' in results['train']:
                    meta_df = results['train']['meta_features']
                    
                    numeric_cols = meta_df.select_dtypes(include=[np.number]).columns.tolist()
                    
                    if numeric_cols:
                        selected_features = st.multiselect(
                            "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏",
                            numeric_cols,
                            default=numeric_cols[:5] if len(numeric_cols) >= 5 else numeric_cols,
                            key="feature_select"
                        )
                        
                        if selected_features:
                            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                            corr_matrix = meta_df[selected_features].corr()
                            
                            fig = go.Figure(data=go.Heatmap(
                                z=corr_matrix.values,
                                x=corr_matrix.columns,
                                y=corr_matrix.columns,
                                colorscale='RdBu',
                                zmin=-1, zmax=1
                            ))
                            fig.update_layout(title='–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
                                            height=500)
                            st.plotly_chart(fig, use_container_width=True)
            
            with tab2:
                if 'train' in results and 'text_vectors' in results['train']:
                    vectors = results['train']['text_vectors']
                    
                    if vectors is not None:
                        st.metric("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤", vectors.shape[1])
                        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤", vectors.shape[0])
                        
                        # PCA –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                        try:
                            from sklearn.decomposition import PCA
                            
                            # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                            pca = PCA(n_components=2)
                            vectors_2d = pca.fit_transform(vectors[:100])  # –ü–µ—Ä–≤—ã–µ 100 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                            
                            # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                            pca_df = pd.DataFrame({
                                'PC1': vectors_2d[:, 0],
                                'PC2': vectors_2d[:, 1]
                            })
                            
                            fig = px.scatter(pca_df, x='PC1', y='PC2', 
                                            title='PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π',
                                            opacity=0.7)
                            st.plotly_chart(fig, use_container_width=True)
                            
                        except Exception as e:
                            st.info("–î–ª—è PCA —Ç—Ä–µ–±—É–µ—Ç—Å—è scikit-learn: pip install scikit-learn")
            
            with tab3:
                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤
                comparison_data = []
                for split_name in ['train', 'validation', 'test']:
                    if split_name in results:
                        vectors = results[split_name].get('text_vectors')
                        if vectors is not None:
                            comparison_data.append({
                                '–†–∞–∑–¥–µ–ª': split_name,
                                '–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å': vectors.shape[1],
                                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': vectors.shape[0]
                            })
                
                if comparison_data:
                    comp_df = pd.DataFrame(comparison_data)
                    
                    fig = px.bar(comp_df, x='–†–∞–∑–¥–µ–ª', y='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                                title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ä–∞–∑–¥–µ–ª–æ–≤',
                                color='–†–∞–∑–¥–µ–ª', text='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
                    st.plotly_chart(fig, use_container_width=True)
            
            # –í—ã–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            with st.expander("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 2"):
                col1, col2 = st.columns(2)
                
                with col1:
                    # –í–µ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å
                    files_dict = {}
                    
                    for split_name in ['train', 'validation', 'test']:
                        if split_name in results:
                            split_results = results[split_name]
                            
                            # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
                            if 'processed_texts' in split_results:
                                files_dict[f'{split_name}/texts.json'] = json.dumps(
                                    split_results['processed_texts'], 
                                    ensure_ascii=False, 
                                    indent=2
                                )
                            
                            # –ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏
                            if 'meta_features' in split_results:
                                files_dict[f'{split_name}/meta_features.csv'] = split_results['meta_features'].to_csv(index=False)
                    
                    zip_buffer = create_download_zip(files_dict, "processed_texts.zip")
                    st.download_button(
                        label="–°–∫–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã",
                        data=zip_buffer,
                        file_name="processed_texts.zip",
                        mime="application/zip"
                    )
                
                with col2:
                    # –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                    import pickle
                    
                    vectors_dict = {}
                    for split_name in ['train', 'validation', 'test']:
                        if split_name in results:
                            vectors = results[split_name].get('text_vectors')
                            if vectors is not None:
                                vectors_dict[split_name] = vectors
                    
                    if vectors_dict:
                        vectors_bytes = pickle.dumps(vectors_dict)
                        st.download_button(
                            label="–°–∫–∞—á–∞—Ç—å –≤–µ–∫—Ç–æ—Ä—ã (pickle)",
                            data=vectors_bytes,
                            file_name="text_vectors.pkl",
                            mime="application/octet-stream"
                        )
else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 1: –†–∞–∑–º–µ—Ç–∫—É –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")

# ============================================================
# –≠–¢–ê–ü 3: –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –¢–ï–ö–°–¢–û–í
# ============================================================
st.markdown("---")

st.header("üéØ –≠—Ç–∞–ø 3. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")

if st.session_state.step2_completed:
    st.markdown("""
    ### üìã –ß—Ç–æ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
    
    1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö** –¥–ª—è –í–°–ï–• —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á:
       - üìä –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (sentiment) - **–±–∏–Ω–∞—Ä–Ω–∞—è/–º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è**
       - üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (category) - **–º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è**
       - üè∑Ô∏è –ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (categories) - **multi-label**
    
    2. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫**:
       - –ü—Ä–∏–∑–Ω–∞–∫–∏: **combined** (–º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏ + –≤–µ–∫—Ç–æ—Ä—ã —Ç–µ–∫—Å—Ç–∞)
       - –ú–æ–¥–µ–ª–∏: **–í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ** (Logistic Regression, Random Forest, SVM –∏ –¥—Ä.)
       - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: **–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é** (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞)
    
    3. **–û—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∑–∞–¥–∞—á
    4. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π** –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ 8 —ç—Ç–∞–ø–µ
    """)
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö
    def get_model_description(model_type):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø–æ —Ç–∏–ø—É"""
        descriptions = {
            'logistic': "–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π",
            'svm_linear': "–ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å –ª–∏–Ω–µ–π–Ω—ã–º —è–¥—Ä–æ–º",
            'svm_rbf': "–ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å RBF —è–¥—Ä–æ–º",
            'random_forest': "–ê–Ω—Å–∞–º–±–ª—å —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤",
            'xgboost': "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ –Ω–∞ –¥–µ—Ä–µ–≤—å—è—Ö (XGBoost)",
            'lightgbm': "–ë—ã—Å—Ç—Ä—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ (LightGBM)",
            'catboost': "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏",
            'naive_bayes': "–ù–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä",
            'knn': "–ú–µ—Ç–æ–¥ k-–±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π"
        }
        return descriptions.get(model_type, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")

    def get_model_hyperparams(config):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –≤ —á–∏—Ç–∞–µ–º–æ–º –≤–∏–¥–µ"""
        model_type = config.get('model_type', '')
        
        if model_type == 'logistic':
            return f"C={config.get('C', 1.0)}, penalty={config.get('penalty', 'l2')}"
        elif model_type == 'random_forest':
            return f"n_estimators={config.get('n_estimators', 100)}, max_depth={'None' if not config.get('max_depth') else config.get('max_depth')}"
        elif model_type == 'svm_linear':
            return f"C={config.get('C', 1.0)}"
        elif model_type == 'svm_rbf':
            return f"C={config.get('C', 1.0)}, gamma={config.get('gamma', 'scale')}"
        elif model_type == 'xgboost':
            return f"n_estimators={config.get('n_estimators', 100)}, max_depth={config.get('max_depth', 6)}"
        elif model_type == 'lightgbm':
            return f"n_estimators={config.get('n_estimators', 100)}, max_depth={'None' if config.get('max_depth') == -1 else config.get('max_depth', -1)}"
        elif model_type == 'catboost':
            return f"iterations={config.get('iterations', 100)}, depth={config.get('depth', 6)}"
        elif model_type == 'naive_bayes':
            return "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é (–±–µ–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)"
        elif model_type == 'knn':
            return f"n_neighbors={config.get('n_neighbors', 5)}"
        else:
            return "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é"
    
    if st.session_state.get("processed_results") is not None:
        splits = st.session_state.data_splits
        results = st.session_state.processed_results
        
        # 1. –ü–û–ö–ê–ó–ê–¢–¨ –ë–£–î–£–©–ò–ï –ú–û–î–ï–õ–ò –ü–ï–†–ï–î –û–ë–£–ß–ï–ù–ò–ï–ú
        if not st.session_state.get("training_completed", False):
            st.markdown("---")
            st.subheader("üîç –ú–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            all_model_configs = create_model_configs()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            model_info = []
            for config in all_model_configs:
                model_info.append({
                    "–¢–∏–ø –º–æ–¥–µ–ª–∏": config.get('name', 'Unknown'),
                    "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ": get_model_description(config.get('model_type')),
                    "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ multi-label": "‚úÖ" if config.get('multi_label', False) else "‚úÖ",
                    "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã": get_model_hyperparams(config)
                })
            
            if model_info:
                model_df = pd.DataFrame(model_info)
                
                # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π
                st.markdown("#### üìä –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
                linear_models = ["Logistic Regression", "SVM (linear)", "SVM (RBF)"]
                linear_df = model_df[model_df["–¢–∏–ø –º–æ–¥–µ–ª–∏"].isin(linear_models)]
                st.dataframe(linear_df, use_container_width=True, hide_index=True)
                
                st.markdown("#### üå≥ –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏:")
                ensemble_models = ["Random Forest"]
                if XGBOOST_AVAILABLE:
                    ensemble_models.append("XGBoost")
                if LIGHTGBM_AVAILABLE:
                    ensemble_models.append("LightGBM")
                if CATBOOST_AVAILABLE:
                    ensemble_models.append("CatBoost")
                
                ensemble_df = model_df[model_df["–¢–∏–ø –º–æ–¥–µ–ª–∏"].isin(ensemble_models)]
                st.dataframe(ensemble_df, use_container_width=True, hide_index=True)
                
                st.markdown("#### üß† –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏:")
                other_models = ["Naive Bayes", "K-Nearest Neighbors"]
                other_df = model_df[model_df["–¢–∏–ø –º–æ–¥–µ–ª–∏"].isin(other_models)]
                st.dataframe(other_df, use_container_width=True, hide_index=True)
                
                st.info(f"‚úÖ –í—Å–µ–≥–æ –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–æ **{len(all_model_configs)}** –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏")
            
            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏", "3")
            with col2:
                st.metric("–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ", f"{len(ensemble_models)}")
            with col3:
                st.metric("–î—Ä—É–≥–∏–µ", "2")
        
        # 2. –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–£–°–ö - –±–µ–∑ –≤—ã–±–æ—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        if not st.session_state.get("training_completed", False):
            with st.spinner("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞..."):
                try:
                    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
                    progress_placeholder = st.empty()
                    status_placeholder = st.empty()
                    
                    # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ù–ê–°–¢–†–û–ô–ö–ò (–≤—Å–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
                    feature_type = "combined"  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä
                    
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    X_train_data = results['train'].get('combined_features')
                    X_val_data = results['validation'].get('combined_features')
                    X_test_data = results['test'].get('combined_features')
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã –≤ –ø–ª–æ—Ç–Ω—ã–µ
                    try:
                        from scipy.sparse import issparse
                        
                        if issparse(X_train_data):
                            X_train_data = X_train_data.toarray()
                            if X_val_data is not None:
                                X_val_data = X_val_data.toarray()
                            if X_test_data is not None:
                                X_test_data = X_test_data.toarray()
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    if X_train_data is None or len(splits['train']) == 0:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                        st.stop()
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è –í–°–ï–• —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                    y_train_all = {}
                    y_val_all = {}
                    y_test_all = {}
                    
                    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
                    all_possible_tasks = ['sentiment', 'category', 'categories']
                    
                    # –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏
                    all_unique_tags = set()
                    for item in splits['train']:
                        if 'categories' in item and isinstance(item['categories'], list):
                            all_unique_tags.update(item['categories'])
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–≥–∏ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
                    all_unique_tags = sorted(list(all_unique_tags))
                    st.session_state.all_unique_tags = all_unique_tags
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
                    for task_type in all_possible_tasks:
                        train_labels = []
                        val_labels = []
                        test_labels = []
                        
                        if task_type == 'categories':
                            # –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –ú–ù–û–ì–û–ú–ï–¢–û–ß–ù–û–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò
                            # –°–æ–∑–¥–∞–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è multi-label –∑–∞–¥–∞—á–∏
                            try:
                                from sklearn.preprocessing import MultiLabelBinarizer
                                mlb = MultiLabelBinarizer(classes=all_unique_tags)
                                
                                # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ç–µ–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
                                train_tags = []
                                for item in splits['train']:
                                    if 'categories' in item and isinstance(item['categories'], list):
                                        train_tags.append(item['categories'])
                                    else:
                                        train_tags.append([])
                                
                                val_tags = []
                                for item in splits['validation']:
                                    if 'categories' in item and isinstance(item['categories'], list):
                                        val_tags.append(item['categories'])
                                    else:
                                        val_tags.append([])
                                
                                test_tags = []
                                for item in splits['test']:
                                    if 'categories' in item and isinstance(item['categories'], list):
                                        test_tags.append(item['categories'])
                                    else:
                                        test_tags.append([])
                                
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
                                if train_tags:
                                    y_train_all[task_type] = mlb.fit_transform(train_tags)
                                    if val_tags:
                                        y_val_all[task_type] = mlb.transform(val_tags)
                                    if test_tags:
                                        y_test_all[task_type] = mlb.transform(test_tags)
                                    
                                    # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ multi-label –∑–∞–¥–∞—á–µ
                                    progress_placeholder.info(
                                        f"‚úÖ **–ù–∞–π–¥–µ–Ω–∞ multi-label –∑–∞–¥–∞—á–∞:** {len(all_unique_tags)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–≥–æ–≤\n"
                                        f"–ü—Ä–∏–º–µ—Ä—ã —Ç–µ–≥–æ–≤: {', '.join(all_unique_tags[:5])}{'...' if len(all_unique_tags) > 5 else ''}"
                                    )
                                
                                st.session_state.mlb = mlb
                                
                            except Exception as e:
                                # Fallback: –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–≥
                                for item in splits['train']:
                                    if 'categories' in item and isinstance(item['categories'], list) and len(item['categories']) > 0:
                                        train_labels.append(str(item['categories'][0]))
                                    else:
                                        train_labels.append('unknown')
                                
                                for item in splits['validation']:
                                    if 'categories' in item and isinstance(item['categories'], list) and len(item['categories']) > 0:
                                        val_labels.append(str(item['categories'][0]))
                                    else:
                                        val_labels.append('unknown')
                                
                                for item in splits['test']:
                                    if 'categories' in item and isinstance(item['categories'], list) and len(item['categories']) > 0:
                                        test_labels.append(str(item['categories'][0]))
                                    else:
                                        test_labels.append('unknown')
                                
                                if train_labels:
                                    y_train_all[task_type] = np.array(train_labels)
                                    y_val_all[task_type] = np.array(val_labels)
                                    y_test_all[task_type] = np.array(test_labels)
                                    progress_placeholder.warning(f"‚ö†Ô∏è –î–ª—è {task_type} –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback (–ø–µ—Ä–≤—ã–π —Ç–µ–≥)")
                        else:
                            # –î–ª—è sentiment –∏ category (–æ–±—ã—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
                            for item in splits['train']:
                                train_labels.append(str(item.get(task_type, 'unknown')))
                            
                            for item in splits['validation']:
                                val_labels.append(str(item.get(task_type, 'unknown')))
                            
                            for item in splits['test']:
                                test_labels.append(str(item.get(task_type, 'unknown')))
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫
                            unique_train_labels = set([l for l in train_labels if l != 'unknown'])
                            if len(unique_train_labels) >= 2:
                                y_train_all[task_type] = np.array(train_labels)
                                y_val_all[task_type] = np.array(val_labels)
                                y_test_all[task_type] = np.array(test_labels)
                                progress_placeholder.info(
                                    f"‚úÖ **–ù–∞–π–¥–µ–Ω–∞ –∑–∞–¥–∞—á–∞ {task_type}:** {len(unique_train_labels)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫"
                                )
                            else:
                                progress_placeholder.warning(
                                    f"‚ö†Ô∏è –î–ª—è {task_type} –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(unique_train_labels)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–∫"
                                )
                    
                    if not y_train_all:
                        st.error("‚ùå –ù–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ –∑–∞–¥–∞—á —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                        st.stop()
                    
                    # –ü–æ–∫–∞–∑–∞—Ç—å —Å–≤–æ–¥–∫—É –∑–∞–¥–∞—á
                    progress_placeholder.success(f"üìä **–ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò –û–ü–†–ï–î–ï–õ–ï–ù–´ –ó–ê–î–ê–ß–ò:** {len(y_train_all)} —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á")
                    for task_type in y_train_all.keys():
                        if task_type == 'categories' and hasattr(st.session_state, 'mlb'):
                            st.caption(f"  - {task_type}: {len(all_unique_tags)} —Ç–µ–≥–æ–≤ (multi-label)")
                        else:
                            unique_labels = set(y_train_all[task_type])
                            st.caption(f"  - {task_type}: {len(unique_labels)} –∫–ª–∞—Å—Å–æ–≤")
                    
                    # –ò–°–ü–û–õ–¨–ó–£–ï–ú –†–ï–ê–õ–¨–ù–´–ô ModelComparator –∏–∑ classical_classifiers.py
                    if CLASSIFIERS_AVAILABLE:
                        progress_placeholder.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é —Ä–µ–∞–ª—å–Ω—ã–π ModelComparator –∏–∑ classical_classifiers.py")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é train_all_tasks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
                        status_placeholder.text("üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
                        
                        all_results = train_all_tasks(
                            X_train_data, y_train_all,
                            X_val_data, y_val_all,
                            task_names=list(y_train_all.keys())
                        )
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        st.session_state.all_comparison_results = all_results
                        st.session_state.y_test_all = y_test_all
                        st.session_state.X_test_data = X_test_data
                        
                        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–∏
                        if all_results:
                            first_task = list(all_results.keys())[0]
                            st.session_state.comparison_results = all_results[first_task]
                            st.session_state.training_completed = True
                            
                            # –û—Ü–µ–Ω–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                            best_model_info = all_results[first_task]
                            if 'best_model' in best_model_info and best_model_info['best_model'] is not None:
                                best_model = best_model_info['best_model']
                                if first_task in y_test_all:
                                    test_metrics = best_model.evaluate(X_test_data, y_test_all[first_task])
                                    st.session_state.test_metrics = test_metrics
                                    st.session_state.best_model = best_model
                        
                        st.session_state.step3_completed = True
                        
                        status_placeholder.empty()
                        progress_placeholder.success(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è {len(y_train_all)} —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
                    else:
                        st.error("‚ùå –ú–æ–¥—É–ª—å classical_classifiers.py –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
                        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª classical_classifiers.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π: {str(e)}")
                    st.code(traceback.format_exc())
        
        # 2. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        if st.session_state.get("training_completed", False):
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –æ–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if st.session_state.all_comparison_results:
                st.markdown("### üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                comparison_data = []
                for task_name, task_results in st.session_state.all_comparison_results.items():
                    if 'best_score' in task_results:
                        comparison_data.append({
                            '–ó–∞–¥–∞—á–∞': task_name,
                            'F1-Score': task_results['best_score'],
                            '–¢–∏–ø': 'Multi-label' if task_name == 'categories' else 'Single-label',
                            '–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å': task_results.get('best_model_name', 'Unknown'),
                            '–ú–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω–æ': len(task_results.get('results', {}))
                        })
                
                if comparison_data:
                    comparison_df = pd.DataFrame(comparison_data)
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ F1-Score
                    comparison_df = comparison_df.sort_values('F1-Score', ascending=False)
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.dataframe(comparison_df, use_container_width=True)
                    
                    with col2:
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
                        total_models = sum(row['–ú–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω–æ'] for _, row in comparison_df.iterrows())
                        st.metric("–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π", total_models)
                        st.metric("–¢–∏–ø–æ–≤ –∑–∞–¥–∞—á", len(comparison_df))
                        st.metric("–õ—É—á—à–∏–π F1", f"{comparison_df.iloc[0]['F1-Score']:.4f}")
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                    fig = px.bar(comparison_df, x='–ó–∞–¥–∞—á–∞', y='F1-Score',
                                color='–¢–∏–ø', title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∑–∞–¥–∞—á–∞–º',
                                text='F1-Score',
                                hover_data=['–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å', '–ú–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω–æ'])
                    st.plotly_chart(fig, use_container_width=True)
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
            st.markdown("### üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–æ–¥–µ–ª—è–º")
            
            if st.session_state.all_comparison_results:
                task_tabs = st.tabs(list(st.session_state.all_comparison_results.keys()))
                
                for i, (task_name, task_results) in enumerate(st.session_state.all_comparison_results.items()):
                    with task_tabs[i]:
                        if 'comparator' in task_results and task_results['comparator'] is not None:
                            comparator = task_results['comparator']
                            
                            # 1. –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
                            st.markdown(f"#### üèÜ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–¥–∞—á–∏: **{task_name}**")
                            
                            # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            results_df = comparator.get_results_table()
                            
                            if not results_df.empty:
                                # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π
                                results_df_sorted = results_df.sort_values('F1-Score', ascending=False)
                                st.dataframe(results_df_sorted, use_container_width=True, height=350)
                                
                                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                                fig = px.bar(results_df_sorted, x='Model', y='F1-Score',
                                            title=f'F1-Score –º–æ–¥–µ–ª–µ–π –¥–ª—è {task_name}',
                                            color='F1-Score',
                                            text='F1-Score',
                                            color_continuous_scale='Viridis',
                                            height=400)
                                fig.update_layout(xaxis_tickangle=-45)
                                st.plotly_chart(fig, use_container_width=True)
                                
                                # –ú–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                                best_model_name = results_df_sorted.iloc[0]['Model']
                                st.success(f"üèÜ **–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:** {best_model_name} (F1: {results_df_sorted.iloc[0]['F1-Score']:.4f})")
                            else:
                                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–æ–¥–µ–ª—è—Ö –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏")
                        
                        # 2. –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        if task_name in st.session_state.y_test_all:
                            test_metrics = task_results.get('best_model', {}).evaluate(
                                st.session_state.X_test_data,
                                st.session_state.y_test_all[task_name]
                            ) if task_results.get('best_model') else None
                            
                            if test_metrics:
                                st.markdown(f"#### üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                                
                                # –ü–æ–∫–∞–∑–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                                col1, col2, col3, col4 = st.columns(4)
                                
                                with col1:
                                    st.metric("F1-Score", f"{test_metrics.get('f1', 0):.4f}")
                                
                                with col2:
                                    st.metric("Accuracy", f"{test_metrics.get('accuracy', 0):.4f}")
                                
                                with col3:
                                    if 'precision' in test_metrics:
                                        st.metric("Precision", f"{test_metrics['precision']:.4f}")
                                    else:
                                        st.metric("Precision", "N/A")
                                
                                with col4:
                                    if 'recall' in test_metrics:
                                        st.metric("Recall", f"{test_metrics['recall']:.4f}")
                                    else:
                                        st.metric("Recall", "N/A")
                                
                                # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –∑–∞–¥–∞—á–∏
                                if test_metrics.get('is_multi_label', False):
                                    st.info(f"**Multi-label –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** - {len(st.session_state.all_unique_tags)} —Ç–µ–≥–æ–≤")
                                    
                                    # –î–ª—è multi-label –ø–æ–∫–∞–∂–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        if 'hamming_loss' in test_metrics:
                                            st.metric("Hamming Loss", f"{test_metrics['hamming_loss']:.4f}")
                                    
                                    with col2:
                                        if 'jaccard_score' in test_metrics:
                                            st.metric("Jaccard Score", f"{test_metrics['jaccard_score']:.4f}")
                                    
                                    with col3:
                                        if 'f1_micro' in test_metrics:
                                            st.metric("F1 Micro", f"{test_metrics['f1_micro']:.4f}")
                                else:
                                    st.info(f"**Single-label –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** - {len(np.unique(st.session_state.y_test_all[task_name]))} –∫–ª–∞—Å—Å–æ–≤")
                                    
                                    # –î–ª—è single-label –ø–æ–∫–∞–∂–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ –µ—Å–ª–∏ –µ—Å—Ç—å
                                    if 'confusion_matrix' in test_metrics:
                                        st.markdown("#### üéØ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
                                        cm = np.array(test_metrics['confusion_matrix'])
                                        fig = px.imshow(cm, text_auto=True, 
                                                       title="Confusion Matrix",
                                                       labels=dict(x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π", y="–ò—Å—Ç–∏–Ω–Ω—ã–π"),
                                                       color_continuous_scale='Blues')
                                        st.plotly_chart(fig, use_container_width=True)
                        
                        else:
                            st.warning(f"–î–ª—è –∑–∞–¥–∞—á–∏ '{task_name}' –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏")
    else:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")

# ============================================================
# –≠–¢–ê–ü 4: –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –û–ë–£–ß–ï–ù–ò–ï –í–°–ï–• –ù–ï–ô–†–û–°–ï–¢–ï–í–´–• –ú–û–î–ï–õ–ï–ô –î–õ–Ø –í–°–ï–• –ó–ê–î–ê–ß
# ============================================================
st.markdown("---")

st.header("üß† –≠—Ç–∞–ø 4. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")

if st.session_state.step3_completed:
    st.markdown("""
    ### üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫:
    
    **–î–ª—è –∫–∞–∂–¥–æ–π –∏–∑ 3 –∑–∞–¥–∞—á –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã:**
    1. **–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω (MLP)** - –Ω–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è—Ö
    2. **–°–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å (CNN)** - –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    3. **–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ (LSTM/GRU)** - –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    4. **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ (RuBERT)** - –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ
    
    ‚úÖ **–í–°–ï –ó–ê–î–ê–ß–ò** (sentiment, category, categories) –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
    """)
    
    if not NEURAL_MODULES_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª—å neural_classifiers –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª neural_classifiers.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    elif not TORCH_AVAILABLE:
        st.error("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        st.info("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch: pip install torch torchvision")
    else:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if st.session_state.get("processed_results") is None:
            st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            st.stop()
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        splits = st.session_state.data_splits
        results = st.session_state.processed_results
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        if splits is None or results is None:
            st.error("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —ç—Ç–∞–ø—ã.")
            st.stop()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á –∏–∑ –≠—Ç–∞–ø–∞ 3
        if not st.session_state.get("all_comparison_results"):
            st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 3 –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞—á")
            st.stop()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –í–°–ï –∑–∞–¥–∞—á–∏ –∏–∑ –≠—Ç–∞–ø–∞ 3
        all_tasks = list(st.session_state.all_comparison_results.keys())
        
        st.success(f"üìä **–ù–∞–π–¥–µ–Ω–æ {len(all_tasks)} –∑–∞–¥–∞—á –∏–∑ –≠—Ç–∞–ø–∞ 3:** {', '.join(all_tasks)}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        use_gpu = torch.cuda.is_available()  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º GPU
        batch_size = 32
        max_epochs = 10  # –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        
        # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–£–°–ö –ë–ï–ó –ö–ù–û–ü–ö–ò
        if not st.session_state.get("neural_training_completed", False):
            st.markdown("---")
            st.subheader("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –í–°–ï–• –∑–∞–¥–∞—á")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ö–ê–ñ–î–û–ô –∑–∞–¥–∞—á–∏
            neural_results_all_tasks = {}
            neural_models_all_tasks = {}
            neural_comparators_all_tasks = {}
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
            for task_idx, task_name in enumerate(all_tasks):
                status_text.text(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ {task_idx+1}/{len(all_tasks)}: {task_name}")
                progress_bar.progress(task_idx / len(all_tasks))
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–¥–∞—á–∞ multi-label
                is_multi_label = (task_name == 'categories')
                st.info(f"üéØ **–ó–∞–¥–∞—á–∞:** {task_name} ({'multi-label' if is_multi_label else 'single-label'})")
                
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                available_models = []
                model_configs = []
                
                # 1. MLP - –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ã)
                if 'train' in results and ('text_vectors' in results['train'] or 'combined_features' in results['train']):
                    available_models.append('mlp')
                    model_configs.append({
                        'id': 'mlp',
                        'name': 'MLP Classifier',
                        'type': 'mlp',
                        'hidden_dims': [256, 128],
                        'dropout': 0.3,
                        'learning_rate': 1e-3,
                        'is_multi_label': is_multi_label
                    })
                
                # 2. CNN - –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
                available_models.append('cnn')
                model_configs.append({
                    'id': 'cnn',
                    'name': 'CNN Classifier',
                    'type': 'cnn',
                    'model_type': 'cnn',
                    'num_filters': 100,
                    'filter_sizes': [3, 4, 5],
                    'dropout': 0.5,
                    'learning_rate': 1e-3,
                    'is_multi_label': is_multi_label
                })
                
                # 3. LSTM - –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
                available_models.append('lstm')
                model_configs.append({
                    'id': 'lstm',
                    'name': 'LSTM Classifier',
                    'type': 'rnn',
                    'model_type': 'rnn',
                    'rnn_type': 'lstm',
                    'hidden_dim': 128,
                    'num_layers': 2,
                    'bidirectional': True,
                    'attention': False,
                    'learning_rate': 1e-3,
                    'is_multi_label': is_multi_label
                })
                
                # 4. GRU - –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
                available_models.append('gru')
                model_configs.append({
                    'id': 'gru',
                    'name': 'GRU Classifier',
                    'type': 'rnn',
                    'model_type': 'rnn',
                    'rnn_type': 'gru',
                    'hidden_dim': 128,
                    'num_layers': 2,
                    'bidirectional': True,
                    'attention': False,
                    'learning_rate': 1e-3,
                    'is_multi_label': is_multi_label
                })
                
                # 5. Transformer - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
                rubert_local_path = "./models/rubert-tiny"
                if os.path.exists(rubert_local_path):
                    model_files = os.listdir(rubert_local_path) if os.path.exists(rubert_local_path) else []
                    has_model_files = any(f.endswith(('.bin', '.safetensors', '.pth', '.pt')) for f in model_files)
                    
                    if has_model_files:
                        available_models.append('transformer')
                        model_configs.append({
                            'id': 'transformer',
                            'name': 'RuBERT (–ª–æ–∫–∞–ª—å–Ω–∞—è)',
                            'type': 'transformer',
                            'model_type': 'transformer',
                            'model_name': rubert_local_path,
                            'max_length': 128,
                            'learning_rate': 2e-5,
                            'is_multi_label': is_multi_label
                        })
                
                st.info(f"‚úÖ –î–ª—è –∑–∞–¥–∞—á–∏ '{task_name}' –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–æ {len(available_models)} –º–æ–¥–µ–ª–µ–π")
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç—Ç–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏
                train_texts = []
                train_labels = []
                val_texts = []
                val_labels = []
                test_texts = []
                test_labels = []
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ –º–µ—Ç–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
                for item in splits['train']:
                    text = item.get('text') or item.get('title') or ''
                    if text and text.strip():
                        train_texts.append(text.strip())
                        label_val = item.get(task_name, 'unknown')
                        if isinstance(label_val, list):
                            if is_multi_label:
                                train_labels.append(label_val)
                            else:
                                label_val = label_val[0] if label_val else 'unknown'
                                train_labels.append(str(label_val))
                        else:
                            train_labels.append(str(label_val))
                
                for item in splits['validation']:
                    text = item.get('text') or item.get('title') or ''
                    if text and text.strip():
                        val_texts.append(text.strip())
                        label_val = item.get(task_name, 'unknown')
                        if isinstance(label_val, list):
                            if is_multi_label:
                                val_labels.append(label_val)
                            else:
                                label_val = label_val[0] if label_val else 'unknown'
                                val_labels.append(str(label_val))
                        else:
                            val_labels.append(str(label_val))
                
                for item in splits['test']:
                    text = item.get('text') or item.get('title') or ''
                    if text and text.strip():
                        test_texts.append(text.strip())
                        label_val = item.get(task_name, 'unknown')
                        if isinstance(label_val, list):
                            if is_multi_label:
                                test_labels.append(label_val)
                            else:
                                label_val = label_val[0] if label_val else 'unknown'
                                test_labels.append(str(label_val))
                        else:
                            test_labels.append(str(label_val))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                if not train_texts:
                    st.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ '{task_name}'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue
                
                # –î–ª—è multi-label –∑–∞–¥–∞—á –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç–∫–∏ –≤ –±–∏–Ω–∞—Ä–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
                if is_multi_label:
                    from sklearn.preprocessing import MultiLabelBinarizer
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏
                    all_tags = set()
                    for tags in train_labels + val_labels + test_labels:
                        if isinstance(tags, list):
                            all_tags.update(tags)
                    
                    if len(all_tags) == 0:
                        st.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ç–µ–≥–æ–≤ –¥–ª—è multi-label –∑–∞–¥–∞—á–∏ '{task_name}'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                        continue
                    
                    mlb = MultiLabelBinarizer(classes=sorted(list(all_tags)))
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç–∫–∏
                    y_train_mlb = mlb.fit_transform(train_labels)
                    y_val_mlb = mlb.transform(val_labels)
                    y_test_mlb = mlb.transform(test_labels)
                    
                    y_train = y_train_mlb
                    y_val = y_val_mlb
                    y_test = y_test_mlb
                    num_classes = y_train.shape[1]
                    
                    st.success(f"‚úÖ Multi-label –∑–∞–¥–∞—á–∞: {num_classes} —Ç–µ–≥–æ–≤")
                else:
                    # –î–ª—è single-label –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    from sklearn.preprocessing import LabelEncoder
                    le = LabelEncoder()
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –º–µ—Ç–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
                    all_labels = train_labels + val_labels + test_labels
                    le.fit(all_labels)
                    
                    y_train = le.transform(train_labels)
                    y_val = le.transform(val_labels)
                    y_test = le.transform(test_labels)
                    num_classes = len(le.classes_)
                    
                    st.success(f"‚úÖ Single-label –∑–∞–¥–∞—á–∞: {num_classes} –∫–ª–∞—Å—Å–æ–≤")
                
                # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞—Ä–∞—Ç–æ—Ä –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                neural_comparator = NeuralModelComparator()
                models_for_task = {}
                
                # –û–±—É—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
                for i, model_id in enumerate(available_models):
                    config = None
                    for cfg in model_configs:
                        if cfg['id'] == model_id:
                            config = cfg
                            break
                    
                    if not config:
                        continue
                    
                    model_name = config['name']
                    
                    status_text.text(f"üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {i+1}/{len(available_models)}: {model_name} –¥–ª—è –∑–∞–¥–∞—á–∏ '{task_name}'")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                    device = 'cuda' if use_gpu and torch.cuda.is_available() else 'cpu'
                    
                    try:
                        if config['type'] == 'mlp':
                            # MLP —Ç—Ä–µ–±—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                            X_train_vectors = results['train'].get('text_vectors')
                            X_val_vectors = results['validation'].get('text_vectors') if results.get('validation') else None
                            X_test_vectors = results['test'].get('text_vectors') if results.get('test') else None
                            
                            if X_train_vectors is not None:
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø–ª–æ—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                                try:
                                    from scipy.sparse import issparse
                                    if issparse(X_train_vectors):
                                        X_train_vectors = X_train_vectors.toarray()
                                        if X_val_vectors is not None:
                                            X_val_vectors = X_val_vectors.toarray()
                                        if X_test_vectors is not None:
                                            X_test_vectors = X_test_vectors.toarray()
                                except:
                                    pass
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                                if X_train_vectors.shape[0] != len(train_texts):
                                    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ n –æ–±—Ä–∞–∑—Ü–æ–≤
                                    n_samples = min(X_train_vectors.shape[0], len(train_texts))
                                    X_train_vectors_sub = X_train_vectors[:n_samples]
                                    train_texts_sub = train_texts[:n_samples]
                                    y_train_sub = y_train[:n_samples]
                                else:
                                    X_train_vectors_sub = X_train_vectors
                                    train_texts_sub = train_texts
                                    y_train_sub = y_train
                                
                                # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º MLP
                                model = SimpleNNClassifier(
                                    input_dim=X_train_vectors_sub.shape[1],
                                    hidden_dims=config.get('hidden_dims', [256, 128]),
                                    dropout=config.get('dropout', 0.3),
                                    is_multi_label=is_multi_label,
                                    device=device
                                )
                                
                                model.num_classes = num_classes
                                model.build_model()
                                
                                if is_multi_label:
                                    model.mlb = mlb
                                else:
                                    model.label_encoder = le
                                
                                # –û–±—É—á–∞–µ–º
                                model.fit(
                                    X_train_vectors_sub, y_train_sub,
                                    X_val_vectors, y_val,
                                    epochs=max_epochs,
                                    batch_size=batch_size,
                                    learning_rate=config.get('learning_rate', 1e-3),
                                    verbose=False
                                )
                                
                                neural_comparator.add_model(model_name, model)
                                models_for_task[model_name] = model
                                
                                st.success(f"‚úÖ {model_name} –æ–±—É—á–µ–Ω–∞ –¥–ª—è '{task_name}'")
                            else:
                                st.warning(f"‚ö†Ô∏è –î–ª—è MLP –Ω—É–∂–Ω—ã vector features. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {model_name} –¥–ª—è '{task_name}'")
                        
                        elif config['type'] == 'cnn':
                            # CNN –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—Å—Ç—ã
                            model = CNNClassifier(
                                vocab_size=10000,
                                embedding_dim=128,
                                max_length=200,
                                num_filters=config.get('num_filters', 100),
                                filter_sizes=config.get('filter_sizes', [3, 4, 5]),
                                dropout=config.get('dropout', 0.5),
                                is_multi_label=is_multi_label,
                                device=device
                            )
                            
                            # –°–æ–∑–¥–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
                            model.create_tokenizer(train_texts)
                            
                            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã
                            X_train_cnn = model.prepare_texts(train_texts)
                            X_val_cnn = model.prepare_texts(val_texts) if val_texts else None
                            X_test_cnn = model.prepare_texts(test_texts) if test_texts else None
                            
                            model.num_classes = num_classes
                            model.build_model()
                            
                            if is_multi_label:
                                model.mlb = mlb
                            else:
                                model.label_encoder = le
                            
                            # –û–±—É—á–∞–µ–º
                            model.fit(
                                X_train_cnn, y_train,
                                X_val_cnn, y_val,
                                epochs=max_epochs,
                                batch_size=batch_size,
                                learning_rate=config.get('learning_rate', 1e-3),
                                verbose=False
                            )
                            
                            neural_comparator.add_model(model_name, model)
                            models_for_task[model_name] = model
                            
                            st.success(f"‚úÖ {model_name} –æ–±—É—á–µ–Ω–∞ –¥–ª—è '{task_name}'")
                        
                        elif config['type'] == 'rnn':
                            # RNN (LSTM/GRU)
                            model = RNNClassifier(
                                vocab_size=10000,
                                embedding_dim=128,
                                max_length=200,
                                hidden_dim=config.get('hidden_dim', 128),
                                num_layers=config.get('num_layers', 2),
                                rnn_type=config.get('rnn_type', 'lstm'),
                                bidirectional=config.get('bidirectional', True),
                                dropout=config.get('dropout', 0.3),
                                attention=config.get('attention', False),
                                is_multi_label=is_multi_label,
                                device=device
                            )
                            
                            # –°–æ–∑–¥–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
                            model.create_tokenizer(train_texts)
                            
                            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã
                            X_train_rnn = model.prepare_texts(train_texts)
                            X_val_rnn = model.prepare_texts(val_texts) if val_texts else None
                            X_test_rnn = model.prepare_texts(test_texts) if test_texts else None
                            
                            model.num_classes = num_classes
                            model.build_model()
                            
                            if is_multi_label:
                                model.mlb = mlb
                            else:
                                model.label_encoder = le
                            
                            # –û–±—É—á–∞–µ–º
                            model.fit(
                                X_train_rnn, y_train,
                                X_val_rnn, y_val,
                                epochs=max_epochs,
                                batch_size=batch_size,
                                learning_rate=config.get('learning_rate', 1e-3),
                                verbose=False
                            )
                            
                            neural_comparator.add_model(model_name, model)
                            models_for_task[model_name] = model
                            
                            st.success(f"‚úÖ {model_name} –æ–±—É—á–µ–Ω–∞ –¥–ª—è '{task_name}'")
                        
                        elif config['type'] == 'transformer':
                            # Transformer
                            try:
                                model = TransformerClassifier(
                                    model_name=config.get('model_name', "./models/rubert-tiny"),
                                    num_classes=num_classes,
                                    max_length=config.get('max_length', 128),
                                    dropout=config.get('dropout', 0.1),
                                    learning_rate=config.get('learning_rate', 2e-5),
                                    use_fp16=config.get('use_fp16', False),
                                    is_multi_label=is_multi_label,
                                    device=device
                                )
                                
                                # –°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å
                                model.build_model()
                                
                                if model.tokenizer is None:
                                    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è {model_name}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                                    continue
                                
                                if is_multi_label:
                                    model.mlb = mlb
                                else:
                                    model.label_encoder = le
                                
                                # –û–±—É—á–∞–µ–º
                                model.fit(
                                    train_texts, y_train,
                                    val_texts, y_val,
                                    epochs=max_epochs,
                                    batch_size=batch_size,
                                    learning_rate=config.get('learning_rate', 2e-5),
                                    verbose=False
                                )
                                
                                neural_comparator.add_model(model_name, model)
                                models_for_task[model_name] = model
                                
                                st.success(f"‚úÖ {model_name} –æ–±—É—á–µ–Ω–∞ –¥–ª—è '{task_name}'")
                                
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–æ–π –º–æ–¥–µ–ª–∏ {model_name} –¥–ª—è '{task_name}': {str(e)}")
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º MLP –∫–∞–∫ fallback
                                if 'train' in results and 'text_vectors' in results['train']:
                                    X_train_vectors = results['train'].get('text_vectors')
                                    try:
                                        from scipy.sparse import issparse
                                        if issparse(X_train_vectors):
                                            X_train_vectors = X_train_vectors.toarray()
                                    except:
                                        pass
                                    
                                    mlp_fallback = SimpleNNClassifier(
                                        input_dim=X_train_vectors.shape[1],
                                        hidden_dims=[256, 128],
                                        dropout=0.3,
                                        is_multi_label=is_multi_label,
                                        device=device
                                    )
                                    
                                    mlp_fallback.num_classes = num_classes
                                    mlp_fallback.build_model()
                                    
                                    if is_multi_label:
                                        mlp_fallback.mlb = mlb
                                    else:
                                        mlp_fallback.label_encoder = le
                                    
                                    mlp_fallback.fit(
                                        X_train_vectors, y_train,
                                        X_val_vectors, y_val,
                                        epochs=max_epochs,
                                        batch_size=batch_size,
                                        learning_rate=1e-3,
                                        verbose=False
                                    )
                                    
                                    neural_comparator.add_model(f"{model_name} (fallback MLP)", mlp_fallback)
                                    models_for_task[f"{model_name} (fallback MLP)"] = mlp_fallback
                                    
                                    st.success(f"‚úÖ {model_name} –æ–±—É—á–µ–Ω–∞ (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ MLP –∫–∞–∫ fallback) –¥–ª—è '{task_name}'")
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ {model_name} –¥–ª—è '{task_name}': {str(e)}")
                        continue
                
                # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
                if models_for_task:
                    status_text.text(f"üìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–¥–∞—á–∏ '{task_name}'...")
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                    test_data_prepared = {}
                    
                    for model_name, model in models_for_task.items():
                        try:
                            if "MLP" in model_name or "fallback" in model_name:
                                # –î–ª—è MLP –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
                                if 'test' in results and 'text_vectors' in results['test']:
                                    X_test_vectors = results['test'].get('text_vectors')
                                    try:
                                        from scipy.sparse import issparse
                                        if issparse(X_test_vectors):
                                            X_test_vectors = X_test_vectors.toarray()
                                    except:
                                        pass
                                    
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
                                    if X_test_vectors.shape[0] >= len(test_texts):
                                        test_data_prepared[model_name] = X_test_vectors[:len(test_texts)]
                                    else:
                                        # –ï—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ –º–µ–Ω—å—à–µ, —á–µ–º —Ç–µ–∫—Å—Ç–æ–≤
                                        padding = np.zeros((len(test_texts) - X_test_vectors.shape[0], X_test_vectors.shape[1]))
                                        test_data_prepared[model_name] = np.vstack([X_test_vectors, padding])
                            elif "CNN" in model_name or "LSTM" in model_name or "GRU" in model_name:
                                # –î–ª—è CNN/RNN –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
                                if hasattr(model, 'prepare_texts'):
                                    X_test_prepared = model.prepare_texts(test_texts)
                                    test_data_prepared[model_name] = X_test_prepared
                            elif "Transformer" in model_name or "RuBERT" in model_name:
                                # –î–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—ã—Ä—ã–µ —Ç–µ–∫—Å—Ç—ã
                                test_data_prepared[model_name] = test_texts
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {model_name}: {e}")
                    
                    # –û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
                    if test_data_prepared:
                        try:
                            comparison_results = neural_comparator.compare_models(
                                test_data_prepared, y_test,
                                metrics=['accuracy', 'f1', 'precision', 'recall']
                            )
                            
                            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                            neural_results_all_tasks[task_name] = comparison_results
                            neural_models_all_tasks[task_name] = models_for_task
                            neural_comparators_all_tasks[task_name] = neural_comparator
                            
                            st.success(f"‚úÖ –ó–∞–¥–∞—á–∞ '{task_name}' –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models_for_task)}")
                            
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è '{task_name}': {str(e)}")
                    else:
                        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–¥–∞—á–∏ '{task_name}'")
                else:
                    st.warning(f"‚ö†Ô∏è –î–ª—è –∑–∞–¥–∞—á–∏ '{task_name}' –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            progress_bar.progress(1.0)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –∑–∞–¥–∞—á
            if neural_results_all_tasks:
                st.session_state.neural_results_all_tasks = neural_results_all_tasks
                st.session_state.neural_models_all_tasks = neural_models_all_tasks
                st.session_state.neural_comparators_all_tasks = neural_comparators_all_tasks
                st.session_state.neural_training_completed = True
                st.session_state.step4_completed = True
                
                # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –∑–∞–¥–∞—á—É –∏ –º–æ–¥–µ–ª—å
                best_task_name = None
                best_model_name = None
                best_f1_score = -1
                
                for task_name, task_results in neural_results_all_tasks.items():
                    if task_results is not None and not task_results.empty and 'f1' in task_results.columns:
                        task_best_idx = task_results['f1'].idxmax()
                        task_best_f1 = task_results.iloc[task_best_idx]['f1']
                        task_best_model = task_results.iloc[task_best_idx]['model']
                        
                        if task_best_f1 > best_f1_score:
                            best_f1_score = task_best_f1
                            best_task_name = task_name
                            best_model_name = task_best_model
                
                if best_task_name and best_model_name:
                    st.session_state.neural_best_model = neural_models_all_tasks[best_task_name].get(best_model_name)
                    st.session_state.neural_best_task = best_task_name
                    st.session_state.neural_best_score = best_f1_score
                
                st.success(f"‚úÖ –≠—Ç–∞–ø 4 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {len(neural_results_all_tasks)} –∑–∞–¥–∞—á")
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏")
        
        # –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –≠–¢–ê–ü–ê 4
        if st.session_state.get("neural_training_completed", False):
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 4: –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –í–°–ï–• –∑–∞–¥–∞—á")
            
            neural_results_all_tasks = st.session_state.get("neural_results_all_tasks", {})
            
            if neural_results_all_tasks:
                # 1. –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º
                st.markdown("### üìã –°–≤–æ–¥–∫–∞ –ø–æ –∑–∞–¥–∞—á–∞–º")
                
                summary_data = []
                for task_name, task_results in neural_results_all_tasks.items():
                    if task_results is not None and not task_results.empty and 'f1' in task_results.columns:
                        best_f1 = task_results['f1'].max()
                        best_model = task_results.loc[task_results['f1'].idxmax(), 'model']
                        avg_f1 = task_results['f1'].mean()
                        num_models = len(task_results)
                        
                        summary_data.append({
                            '–ó–∞–¥–∞—á–∞': task_name,
                            '–õ—É—á—à–∏–π F1': f"{best_f1:.4f}",
                            '–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å': best_model,
                            '–°—Ä–µ–¥–Ω–∏–π F1': f"{avg_f1:.4f}",
                            '–ú–æ–¥–µ–ª–µ–π': num_models
                        })
                
                if summary_data:
                    summary_df = pd.DataFrame(summary_data)
                    st.dataframe(summary_df, use_container_width=True, height=200)
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á
                    fig = px.bar(summary_df, x='–ó–∞–¥–∞—á–∞', y='–õ—É—á—à–∏–π F1',
                                title='–õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–¥–∞—á–∞–º (–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏)',
                                color='–õ—É—á—à–∏–π F1', text='–õ—É—á—à–∏–π F1',
                                color_continuous_scale='Viridis')
                    st.plotly_chart(fig, use_container_width=True)
                
                # 2. –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–µ
                st.markdown("### üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–¥–∞—á–∞–º")
                
                task_tabs = st.tabs(list(neural_results_all_tasks.keys()))
                
                for i, (task_name, task_results) in enumerate(neural_results_all_tasks.items()):
                    with task_tabs[i]:
                        if task_results is not None and not task_results.empty:
                            st.markdown(f"#### üéØ –ó–∞–¥–∞—á–∞: {task_name}")
                            
                            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ F1-score
                            display_df = task_results.copy()
                            if 'f1' in display_df.columns:
                                display_df = display_df.sort_values('f1', ascending=False)
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª
                            for col in ['accuracy', 'f1', 'precision', 'recall']:
                                if col in display_df.columns:
                                    display_df[col] = display_df[col].apply(lambda x: f"{x:.4f}")
                            
                            if 'inference_time' in display_df.columns:
                                display_df['inference_time'] = display_df['inference_time'].apply(lambda x: f"{x:.3f} —Å–µ–∫")
                            
                            st.dataframe(display_df, use_container_width=True, height=300)
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                            if 'f1' in task_results.columns:
                                sorted_df = task_results.sort_values('f1', ascending=True)
                                
                                fig = go.Figure()
                                
                                metrics_to_plot = [
                                    ('accuracy', 'Accuracy', 'lightblue'),
                                    ('precision', 'Precision', 'lightgreen'),
                                    ('recall', 'Recall', 'lightcoral'),
                                    ('f1', 'F1-Score', 'gold')
                                ]
                                
                                for metric, name, color in metrics_to_plot:
                                    if metric in sorted_df.columns:
                                        fig.add_trace(go.Bar(
                                            y=sorted_df['model'],
                                            x=sorted_df[metric],
                                            name=name,
                                            orientation='h',
                                            marker_color=color,
                                            text=sorted_df[metric].apply(lambda x: f"{x:.3f}"),
                                            textposition='auto'
                                        ))
                                
                                fig.update_layout(
                                    title=f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–¥–∞—á–∏: {task_name}',
                                    yaxis_title='–ú–æ–¥–µ–ª—å',
                                    xaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏',
                                    barmode='group',
                                    height=max(400, len(sorted_df) * 40),
                                    showlegend=True
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                
                # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç—Ç–∞–ø–æ–≤ 3 –∏ 4 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
                if st.session_state.get("all_comparison_results"):
                    st.markdown("### ‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç—Ç–∞–ø–æ–≤ 3 –∏ 4")
                    
                    comparison_data = []
                    
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 3 (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏)
                    stage3_results = st.session_state.all_comparison_results
                    for task_name, task_data in stage3_results.items():
                        if 'best_score' in task_data:
                            comparison_data.append({
                                '–ó–∞–¥–∞—á–∞': task_name,
                                '–≠—Ç–∞–ø': '3 (–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ)',
                                'F1-Score': task_data['best_score']
                            })
                    
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 4 (–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏)
                    for task_name, task_results in neural_results_all_tasks.items():
                        if task_results is not None and not task_results.empty and 'f1' in task_results.columns:
                            best_f1 = task_results['f1'].max()
                            best_model = task_results.loc[task_results['f1'].idxmax(), 'model']
                            comparison_data.append({
                                '–ó–∞–¥–∞—á–∞': task_name,
                                '–≠—Ç–∞–ø': f'4 (–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ - {best_model})',
                                'F1-Score': best_f1
                            })
                    
                    if comparison_data:
                        comparison_df = pd.DataFrame(comparison_data)
                        
                        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–û
                        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ
                        stage3_df = comparison_df[comparison_df['–≠—Ç–∞–ø'] == '3 (–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ)']
                        stage4_df = comparison_df[comparison_df['–≠—Ç–∞–ø'].str.startswith('4 (–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ')]
                        
                        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                        summary_data = []
                        for task in stage3_df['–ó–∞–¥–∞—á–∞'].unique():
                            stage3_score = stage3_df[stage3_df['–ó–∞–¥–∞—á–∞'] == task]['F1-Score'].values[0]
                            stage4_score = stage4_df[stage4_df['–ó–∞–¥–∞—á–∞'] == task]['F1-Score'].values[0] if task in stage4_df['–ó–∞–¥–∞—á–∞'].values else 0
                            
                            improvement = ((stage4_score - stage3_score) / stage3_score * 100) if stage3_score > 0 else 0
                            
                            summary_data.append({
                                '–ó–∞–¥–∞—á–∞': task,
                                '–≠—Ç–∞–ø 3 (F1)': f"{stage3_score:.4f}",
                                '–≠—Ç–∞–ø 4 (F1)': f"{stage4_score:.4f}",
                                '–£–ª—É—á—à–µ–Ω–∏–µ (%)': f"{improvement:.1f}%",
                                '–°—Ç–∞—Ç—É—Å': '‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ' if improvement > 0 else '‚ùå –£—Ö—É–¥—à–µ–Ω–∏–µ' if improvement < 0 else '‚ûñ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π'
                            })
                        
                        if summary_data:
                            improvement_df = pd.DataFrame(summary_data)
                            st.dataframe(improvement_df, use_container_width=True)
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                            fig = px.bar(comparison_df, x='–ó–∞–¥–∞—á–∞', y='F1-Score', color='–≠—Ç–∞–ø',
                                        title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∑–∞–¥–∞—á–∞–º',
                                        barmode='group', text='F1-Score')
                            st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è...")
        else:
            # –ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –Ω–æ –º—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
            if not st.session_state.get("neural_training_completed", False):
                st.info("‚è≥ –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ...")
                st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")
else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 3: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–æ–≤")


# ============================================================
# –≠–¢–ê–ü 5: –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ë–û–†–¨–ë–ê –° –î–ò–°–ë–ê–õ–ê–ù–°–û–ú –ö–õ–ê–°–°–û–í
# ============================================================
st.markdown("---")

st.header("‚öñÔ∏è –≠—Ç–∞–ø 5. –ë–æ—Ä—å–±–∞ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤")

if st.session_state.step4_completed:
    st.markdown("""
    ### üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫:
    
    **–î–ª—è –∫–∞–∂–¥–æ–π –∏–∑ 3 –∑–∞–¥–∞—á –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω—ã:**
    1. **–ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–µ–ø–µ–Ω–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
    2. **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏** - class_weight, random_oversample
    3. **–û–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π** - –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
    4. **–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤** - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –º–µ—Ç–æ–¥–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
    
    ‚úÖ **–í–°–ï –ó–ê–î–ê–ß–ò** –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
    """)
    
    # –°–ù–ê–ß–ê–õ–ê –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ sklearn
    try:
        from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
        SKLEARN_METRICS_AVAILABLE = True
    except ImportError:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ sklearn.metrics")
        st.info("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ scikit-learn: pip install scikit-learn")
        SKLEARN_METRICS_AVAILABLE = False
    
    if not IMBALANCE_MODULES_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª—å imbalance_handling –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª imbalance_handling.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    elif not SKLEARN_METRICS_AVAILABLE:
        st.error("‚ùå –ú–µ—Ç—Ä–∏–∫–∏ sklearn –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")
    else:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        splits = st.session_state.data_splits
        results = st.session_state.processed_results
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        if splits is None or results is None:
            st.error("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —ç—Ç–∞–ø—ã.")
            st.stop()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á –∏–∑ –≠—Ç–∞–ø–∞ 3
        if not st.session_state.get("all_comparison_results"):
            st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 3 –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞—á")
            st.stop()
        
        all_tasks = list(st.session_state.all_comparison_results.keys())
        
        st.success(f"üìä **–ù–∞–π–¥–µ–Ω–æ {len(all_tasks)} –∑–∞–¥–∞—á –∏–∑ –≠—Ç–∞–ø–∞ 3:** {', '.join(all_tasks)}")
        
        # –ö–ù–û–ü–ö–ê –î–õ–Ø –ó–ê–ü–£–°–ö–ê
        if not st.session_state.get("step5_completed", False):
            st.markdown("---")
            st.subheader("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –¥–ª—è –í–°–ï–• –∑–∞–¥–∞—á")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞
            if st.button("‚ö° **–ó–ê–ü–£–°–¢–ò–¢–¨ –≠–¢–ê–ü 5: –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ë–û–†–¨–ë–ê –° –î–ò–°–ë–ê–õ–ê–ù–°–û–ú**", 
                        type="primary", 
                        key="run_step5",
                        use_container_width=True,
                        help="–ó–∞–ø—É—Å—Ç–∏—Ç –∞–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç –º–µ—Ç–æ–¥—ã –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏"):
                
                with st.spinner("–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞..."):
                    try:
                        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ö–ê–ñ–î–û–ô –∑–∞–¥–∞—á–∏
                        imbalance_results_all_tasks = {}
                        balanced_models_all_tasks = {}
                        balance_comparisons_all_tasks = {}
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for task_idx, task_name in enumerate(all_tasks):
                            status_text.text(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ {task_idx+1}/{len(all_tasks)}: {task_name}")
                            progress_bar.progress(task_idx / len(all_tasks))
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–¥–∞—á–∞ multi-label
                            is_multi_label = (task_name == 'categories')
                            st.info(f"üéØ **–ó–∞–¥–∞—á–∞:** {task_name} ({'multi-label' if is_multi_label else 'single-label'})")
                            
                            # 1. –ê–ù–ê–õ–ò–ó –î–ò–°–ë–ê–õ–ê–ù–°–ê
                            with st.spinner(f"–ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –¥–ª—è '{task_name}'..."):
                                try:
                                    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                                    train_labels = []
                                    for item in splits['train']:
                                        label = item.get(task_name, 'unknown')
                                        if is_multi_label and isinstance(label, list):
                                            # –î–ª—è multi-label –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                                            train_labels.append(label[0] if label else 'unknown')
                                        else:
                                            train_labels.append(str(label))
                                    
                                    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
                                    from imbalance_handling import ImbalanceHandler
                                    handler = ImbalanceHandler(random_state=42, language='rus', max_samples=5000)
                                    report = handler.analyze_imbalance(train_labels)
                                    
                                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                                    if 'imbalance_results_all_tasks' not in st.session_state:
                                        st.session_state.imbalance_results_all_tasks = {}
                                    st.session_state.imbalance_results_all_tasks[task_name] = {
                                        'report': report,
                                        'handler': handler
                                    }
                                    
                                    # –ü–æ–∫–∞–∑–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric(
                                            "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞",
                                            f"{report.get('imbalance_ratio', 0):.2f}",
                                            help="–û—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∫ —Å–∞–º–æ–º—É –º–∞–ª–µ–Ω—å–∫–æ–º—É"
                                        )
                                    with col2:
                                        st.metric(
                                            "–£—Ä–æ–≤–µ–Ω—å –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞",
                                            report.get('imbalance_level', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                                        )
                                    with col3:
                                        st.metric(
                                            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤",
                                            report.get('n_classes', 0)
                                        )
                                    
                                    st.success(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –¥–ª—è '{task_name}' –∑–∞–≤–µ—Ä—à–µ–Ω")
                                    
                                except Exception as e:
                                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –¥–ª—è '{task_name}': {e}")
                                    continue
                            
                            # 2. –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ò
                            with st.spinner(f"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–ª—è '{task_name}'..."):
                                try:
                                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                                    X_train = results['train'].get('combined_features')
                                    X_test = results['test'].get('combined_features')
                                    
                                    if X_train is None:
                                        X_train = results['train'].get('text_vectors')
                                    if X_test is None:
                                        X_test = results['test'].get('text_vectors')
                                    
                                    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫
                                    train_labels_list = [item.get(task_name, 'unknown') for item in splits['train']]
                                    test_labels_list = [item.get(task_name, 'unknown') for item in splits['test']]
                                    
                                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                                    try:
                                        from scipy.sparse import issparse
                                        if issparse(X_train):
                                            X_train = X_train.toarray()
                                        if issparse(X_test):
                                            X_test = X_test.toarray()
                                    except:
                                        pass
                                    
                                    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
                                    from sklearn.preprocessing import LabelEncoder
                                    le = LabelEncoder()
                                    
                                    if is_multi_label:
                                        # –î–ª—è multi-label –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–≥
                                        train_labels_simple = []
                                        for label in train_labels_list:
                                            if isinstance(label, list) and label:
                                                train_labels_simple.append(str(label[0]))
                                            else:
                                                train_labels_simple.append(str(label))
                                        
                                        test_labels_simple = []
                                        for label in test_labels_list:
                                            if isinstance(label, list) and label:
                                                test_labels_simple.append(str(label[0]))
                                            else:
                                                test_labels_simple.append(str(label))
                                        
                                        y_train_encoded = le.fit_transform(train_labels_simple)
                                        y_test_encoded = le.transform(test_labels_simple)
                                    else:
                                        y_train_encoded = le.fit_transform(train_labels_list)
                                        y_test_encoded = le.transform(test_labels_list)
                                    
                                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                                    if X_train is None or len(y_train_encoded) == 0:
                                        st.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∑–∞–¥–∞—á–∏ '{task_name}'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                                        continue
                                    
                                    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
                                    balancing_methods = ['none', 'class_weight', 'random_oversample']
                                    comparison_results = []
                                    models_for_task = {}
                                    
                                    for method in balancing_methods:
                                        try:
                                            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
                                            if method == 'none':
                                                X_balanced = X_train
                                                y_balanced = y_train_encoded
                                                balance_info = {'method': 'none'}
                                            else:
                                                X_balanced, y_balanced, balance_info = handler.apply_balancing(
                                                    X_train, y_train_encoded, method=method
                                                )
                                            
                                            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                                            from sklearn.linear_model import LogisticRegression
                                            from sklearn.ensemble import RandomForestClassifier
                                            
                                            # –û–±—É—á–∞–µ–º –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é
                                            lr_model = LogisticRegression(
                                                max_iter=200, 
                                                random_state=42, 
                                                n_jobs=-1,
                                                class_weight='balanced' if method == 'class_weight' else None
                                            )
                                            lr_model.fit(X_balanced, y_balanced)
                                            
                                            # –û–±—É—á–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
                                            rf_model = RandomForestClassifier(
                                                n_estimators=50,
                                                random_state=42,
                                                n_jobs=-1,
                                                max_depth=10,
                                                class_weight='balanced' if method == 'class_weight' else None
                                            )
                                            rf_model.fit(X_balanced, y_balanced)
                                            
                                            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
                                            lr_pred = lr_model.predict(X_test)
                                            rf_pred = rf_model.predict(X_test)
                                            
                                            # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
                                            lr_metrics = {
                                                'balancing_method': method,
                                                'model': 'logistic_regression',
                                                'accuracy': accuracy_score(y_test_encoded, lr_pred),
                                                'f1': f1_score(y_test_encoded, lr_pred, average='weighted', zero_division=0),
                                                'precision': precision_score(y_test_encoded, lr_pred, average='weighted', zero_division=0),
                                                'recall': recall_score(y_test_encoded, lr_pred, average='weighted', zero_division=0)
                                            }
                                            
                                            # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞
                                            rf_metrics = {
                                                'balancing_method': method,
                                                'model': 'random_forest',
                                                'accuracy': accuracy_score(y_test_encoded, rf_pred),
                                                'f1': f1_score(y_test_encoded, rf_pred, average='weighted', zero_division=0),
                                                'precision': precision_score(y_test_encoded, rf_pred, average='weighted', zero_division=0),
                                                'recall': recall_score(y_test_encoded, rf_pred, average='weighted', zero_division=0)
                                            }
                                            
                                            comparison_results.extend([lr_metrics, rf_metrics])
                                            
                                            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
                                            key_lr = f"{task_name}_{method}_logistic_regression"
                                            key_rf = f"{task_name}_{method}_random_forest"
                                            
                                            if 'balanced_models' not in st.session_state:
                                                st.session_state.balanced_models = {}
                                            
                                            st.session_state.balanced_models[key_lr] = {
                                                'model': lr_model,
                                                'task': task_name,
                                                'method': method,
                                                'model_type': 'logistic_regression'
                                            }
                                            
                                            st.session_state.balanced_models[key_rf] = {
                                                'model': rf_model,
                                                'task': task_name,
                                                'method': method,
                                                'model_type': 'random_forest'
                                            }
                                            
                                            models_for_task[f"{method}_lr"] = lr_model
                                            models_for_task[f"{method}_rf"] = rf_model
                                            
                                            st.success(f"‚úÖ –ú–µ—Ç–æ–¥ '{method}' –ø—Ä–∏–º–µ–Ω–µ–Ω –¥–ª—è '{task_name}'")
                                            
                                        except Exception as e:
                                            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –º–µ—Ç–æ–¥–∞ '{method}' –¥–ª—è '{task_name}': {e}")
                                            continue
                                    
                                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                                    if comparison_results:
                                        comparison_df = pd.DataFrame(comparison_results)
                                        comparison_df['task'] = task_name
                                        
                                        if 'balance_comparisons_all_tasks' not in st.session_state:
                                            st.session_state.balance_comparisons_all_tasks = {}
                                        
                                        st.session_state.balance_comparisons_all_tasks[task_name] = comparison_df
                                        
                                        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –º–µ—Ç–æ–¥
                                        best_row = comparison_df.loc[comparison_df['f1'].idxmax()]
                                        best_method = best_row['balancing_method']
                                        best_model = best_row['model']
                                        best_f1 = best_row['f1']
                                        
                                        st.success(f"üèÜ –î–ª—è –∑–∞–¥–∞—á–∏ '{task_name}' –ª—É—á—à–∏–π –º–µ—Ç–æ–¥: {best_method} —Å –º–æ–¥–µ–ª—å—é {best_model} (F1: {best_f1:.4f})")
                                        
                                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                                        best_key = f"{task_name}_{best_method}_{best_model}"
                                        if best_key in st.session_state.balanced_models:
                                            if 'best_balanced_models' not in st.session_state:
                                                st.session_state.best_balanced_models = {}
                                            st.session_state.best_balanced_models[task_name] = st.session_state.balanced_models[best_key]
                                    
                                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–¥–∞—á–∏
                                    balanced_models_all_tasks[task_name] = models_for_task
                                    
                                except Exception as e:
                                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ –¥–ª—è '{task_name}': {e}")
                                    continue
                            
                            progress_bar.progress((task_idx + 1) / len(all_tasks))
                        
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
                        progress_bar.progress(1.0)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        st.session_state.imbalance_results_all_tasks = imbalance_results_all_tasks
                        st.session_state.balanced_models_all_tasks = balanced_models_all_tasks
                        st.session_state.balance_comparisons_all_tasks = balance_comparisons_all_tasks
                        st.session_state.step5_completed = True
                        st.session_state.imbalance_handling_completed = True
                        
                        st.success(f"‚úÖ –≠—Ç–∞–ø 5 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–¥–∞—á: {len(all_tasks)}")
                        st.balloons()
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —ç—Ç–∞–ø–∞ 5: {e}")
            else:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É
                st.info("**–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≤—ã—à–µ, —á—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á**")
        
        # –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –≠–¢–ê–ü–ê 5
        if st.session_state.get("step5_completed", False):
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 5: –ë–æ—Ä—å–±–∞ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –¥–ª—è –í–°–ï–• –∑–∞–¥–∞—á")
            
            # 1. –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º
            st.markdown("### üìã –°–≤–æ–¥–∫–∞ –ø–æ –∑–∞–¥–∞—á–∞–º")
            
            summary_data = []
            for task_name in all_tasks:
                if task_name in st.session_state.get("balance_comparisons_all_tasks", {}):
                    comparison_df = st.session_state.balance_comparisons_all_tasks[task_name]
                    
                    if not comparison_df.empty:
                        # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                        best_idx = comparison_df['f1'].idxmax()
                        best_row = comparison_df.loc[best_idx]
                        
                        # –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å
                        if (st.session_state.get("imbalance_results_all_tasks") and 
                            task_name in st.session_state.imbalance_results_all_tasks):
                            imbalance_report = st.session_state.imbalance_results_all_tasks[task_name]['report']
                            imbalance_ratio = imbalance_report.get('imbalance_ratio', 0)
                        else:
                            imbalance_ratio = 0
                        
                        summary_data.append({
                            '–ó–∞–¥–∞—á–∞': task_name,
                            '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞': f"{imbalance_ratio:.2f}",
                            '–õ—É—á—à–∏–π –º–µ—Ç–æ–¥': best_row['balancing_method'],
                            '–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å': best_row['model'],
                            '–õ—É—á—à–∏–π F1': f"{best_row['f1']:.4f}",
                            '–£–ª—É—á—à–µ–Ω–∏–µ': "‚úÖ" if best_row['balancing_method'] != 'none' else "‚ûñ"
                        })
            
            if summary_data:
                summary_df = pd.DataFrame(summary_data)
                st.dataframe(summary_df, use_container_width=True, height=200)
                
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                fig = px.bar(summary_df, x='–ó–∞–¥–∞—á–∞', y='–õ—É—á—à–∏–π F1',
                            color='–õ—É—á—à–∏–π –º–µ—Ç–æ–¥', title='–õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–¥–∞—á–∞–º',
                            text='–õ—É—á—à–∏–π F1')
                st.plotly_chart(fig, use_container_width=True)
            
            # 2. –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–µ
            st.markdown("### üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–¥–∞—á–∞–º")
            
            if st.session_state.get("balance_comparisons_all_tasks"):
                task_tabs = st.tabs(list(st.session_state.balance_comparisons_all_tasks.keys()))
                
                for i, (task_name, comparison_df) in enumerate(st.session_state.balance_comparisons_all_tasks.items()):
                    with task_tabs[i]:
                        if not comparison_df.empty:
                            st.markdown(f"#### üéØ –ó–∞–¥–∞—á–∞: {task_name}")
                            
                            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ F1-score
                            display_df = comparison_df.copy()
                            display_df = display_df.sort_values('f1', ascending=False)
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª
                            for col in ['accuracy', 'f1', 'precision', 'recall']:
                                display_df[col] = display_df[col].apply(lambda x: f"{x:.4f}")
                            
                            st.dataframe(display_df, use_container_width=True, height=300)
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                            if 'f1' in comparison_df.columns:
                                sorted_df = comparison_df.sort_values('f1', ascending=True)
                                
                                fig = go.Figure()
                                
                                # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Ç–æ–¥–∞–º –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
                                for method in sorted_df['balancing_method'].unique():
                                    method_data = sorted_df[sorted_df['balancing_method'] == method]
                                    fig.add_trace(go.Bar(
                                        y=method_data['model'] + " (" + method + ")",
                                        x=method_data['f1'],
                                        name=method,
                                        orientation='h',
                                        text=method_data['f1'].apply(lambda x: f"{x:.3f}"),
                                        textposition='auto'
                                    ))
                                
                                fig.update_layout(
                                    title=f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–ª—è –∑–∞–¥–∞—á–∏: {task_name}',
                                    xaxis_title='F1-Score',
                                    yaxis_title='–ú–æ–¥–µ–ª—å + –ú–µ—Ç–æ–¥',
                                    height=400,
                                    showlegend=True
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
            
            # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ø–∞–º–∏ 3 –∏ 4
            st.markdown("### ‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç—Ç–∞–ø–∞–º–∏")
            
            comparison_data = []
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 3 (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏)
            if st.session_state.get("all_comparison_results"):
                stage3_results = st.session_state.all_comparison_results
                for task_name, task_data in stage3_results.items():
                    if 'best_score' in task_data:
                        comparison_data.append({
                            '–ó–∞–¥–∞—á–∞': task_name,
                            '–≠—Ç–∞–ø': '3 (–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ)',
                            'F1-Score': task_data['best_score']
                        })
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 4 (–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏)
            if st.session_state.get("neural_results_all_tasks"):
                stage4_results = st.session_state.neural_results_all_tasks
                for task_name, task_results in stage4_results.items():
                    if task_results is not None and not task_results.empty and 'f1' in task_results.columns:
                        best_f1 = task_results['f1'].max()
                        comparison_data.append({
                            '–ó–∞–¥–∞—á–∞': task_name,
                            '–≠—Ç–∞–ø': '4 (–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ)',
                            'F1-Score': best_f1
                        })
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 5 (—Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π)
            if st.session_state.get("balance_comparisons_all_tasks"):
                stage5_results = st.session_state.balance_comparisons_all_tasks
                for task_name, comparison_df in stage5_results.items():
                    if not comparison_df.empty and 'f1' in comparison_df.columns:
                        best_f1 = comparison_df['f1'].max()
                        comparison_data.append({
                            '–ó–∞–¥–∞—á–∞': task_name,
                            '–≠—Ç–∞–ø': '5 (–° –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π)',
                            'F1-Score': best_f1
                        })
            
            if comparison_data:
                comparison_df = pd.DataFrame(comparison_data)
                
                # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                fig = px.bar(comparison_df, x='–ó–∞–¥–∞—á–∞', y='F1-Score', color='–≠—Ç–∞–ø',
                            title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —ç—Ç–∞–ø–∞–º',
                            barmode='group', text='F1-Score')
                st.plotly_chart(fig, use_container_width=True)
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.markdown("---")
            st.subheader("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            with st.expander("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 5", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
                    if st.session_state.get("best_balanced_models"):
                        try:
                            import pickle
                            models_bytes = pickle.dumps(st.session_state.best_balanced_models)
                            
                            st.download_button(
                                label="ü§ñ –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π",
                                data=models_bytes,
                                file_name=f"balanced_models_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl",
                                mime="application/octet-stream"
                            )
                        except Exception as e:
                            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏: {e}")
                
                with col2:
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤
                    if st.session_state.get("balance_comparisons_all_tasks"):
                        all_reports = {}
                        for task_name, comparison_df in st.session_state.balance_comparisons_all_tasks.items():
                            all_reports[task_name] = comparison_df.to_dict(orient='records')
                        
                        reports_json = json.dumps(all_reports, indent=2, ensure_ascii=False, default=str)
                        
                        st.download_button(
                            label="üìã –û—Ç—á–µ—Ç—ã –ø–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ (JSON)",
                            data=reports_json,
                            file_name=f"balance_reports_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                
                # –ü–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤
                if st.button("üì¶ –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ —ç—Ç–∞–ø–∞ 5", key="create_stage5_archive"):
                    with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞..."):
                        files_dict = {}
                        
                        # –û—Ç—á–µ—Ç—ã
                        if st.session_state.get("balance_comparisons_all_tasks"):
                            for task_name, comparison_df in st.session_state.balance_comparisons_all_tasks.items():
                                files_dict[f'{task_name}/comparison.csv'] = comparison_df.to_csv(index=False)
                        
                        # –°–≤–æ–¥–∫–∞
                        summary = f"""
                        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 5: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –±–æ—Ä—å–±–∞ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
                        –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                        
                        –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–¥–∞—á: {len(all_tasks)}
                        –ó–∞–¥–∞—á–∏: {', '.join(all_tasks)}
                        
                        –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:
                        """
                        
                        if summary_data:
                            for row in summary_data:
                                summary += f"\n- {row['–ó–∞–¥–∞—á–∞']}: {row['–õ—É—á—à–∏–π –º–µ—Ç–æ–¥']} + {row['–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å']} (F1: {row['–õ—É—á—à–∏–π F1']})"
                        
                        files_dict['summary.txt'] = summary
                        
                        # –°–æ–∑–¥–∞–Ω–∏–µ ZIP
                        zip_buffer = create_download_zip(files_dict, "stage5_balance_results.zip")
                        
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ —ç—Ç–∞–ø–∞ 5",
                            data=zip_buffer,
                            file_name=f"stage5_balance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            mime="application/zip"
                        )
        else:
            st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≤—ã—à–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞")
else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 4: –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏")


# ============================================================
# –≠–¢–ê–ü 6: –ù–ê–°–¢–†–û–ô–ö–ê –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í –ò –í–°–ï–°–¢–û–†–û–ù–ù–Ø–Ø –û–¶–ï–ù–ö–ê
# ============================================================
st.markdown("---")

st.header("‚öôÔ∏è –≠—Ç–∞–ø 6: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π")

if st.session_state.step5_completed:
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º F1-Score –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_score = st.session_state.get('best_model_score', 0)
    
    if best_model_score >= 0.99:
        st.warning(f"""
        ‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ:** –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π F1-Score ({best_model_score:.4f}).
        
        **–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**
        1. **–°–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ** –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        2. **–£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö** –º–µ–∂–¥—É –æ–±—É—á–∞—é—â–µ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞–º–∏
        3. **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞** –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        4. **–û—à–∏–±–∫–∞ –≤ –æ—Ü–µ–Ω–∫–µ –º–µ—Ç—Ä–∏–∫**
        
        **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏.
        –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–∂–µ—Ç –Ω–µ –¥–∞—Ç—å –∑–Ω–∞—á–∏–º–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è, –Ω–æ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏.
        """)
    
    st.markdown("""
    ### üéØ **–ó–∞–¥–∞—á–∞:** –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ—Ç–æ–¥–∏–∫—É –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π.
    
    **–£–∫–∞–∑–∞–Ω–∏—è –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é:**
    
    **1. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è:**
    - üéØ **Stratified K-Fold** - –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
    - üìÖ **–í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ** - –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
    - üë• **Group K-Fold** - –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å –≥—Ä—É–ø–ø–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    
    **2. –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:**
    - üîç **Grid Search** - –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–±–æ—Ä–∞
    - üé≤ **Random Search** - –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    - üß† **Bayesian Optimization** (Optuna, Hyperopt) - –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    - ü§ñ **–î–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤:** –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è, —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö
    
    **3. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:**
    - üìè **L1, L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è** - –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    - üö´ **Dropout** - –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
    - ‚öñÔ∏è **Weight decay** - –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤
    - ‚èπÔ∏è **Early Stopping, ReduceLROnPlateau** - –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
    
    **4. –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏:**
    - üéØ **–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫**
    - üìä **Accuracy, Precision, Recall, F1-Score** —Å —É—á–µ—Ç–æ–º –º–∞–∫—Ä–æ/–º–∏–∫—Ä–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
    - üìà **ROC-AUC** - –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    - üìâ **PR-AUC** - –¥–ª—è –∑–∞–¥–∞—á —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤
    - üìâ **Log Loss** (–∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è)
    - ü§ñ **–î–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤:** –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    """)
    
    if not TUNING_MODULES_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª—å advanced_tuning –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        st.info("""
        –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª advanced_tuning.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
        –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
        ```
        pip install scikit-learn optuna hyperopt numpy pandas scipy
        ```
        """)
    else:
        # 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ù–ê–°–¢–†–û–ô–ö–ò
        st.markdown("---")
        st.subheader("‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### üìä –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è")
            cv_strategy = st.selectbox(
                "–°—Ç—Ä–∞—Ç–µ–≥–∏—è CV",
                ["stratified", "timeseries", "group"],
                index=0,
                help="Stratified K-Fold: –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ | Time Series: –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã | Group K-Fold: –≥—Ä—É–ø–ø–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"
            )
            
            cv_splits = st.slider(
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤",
                min_value=3,
                max_value=10,
                value=5,
                help="–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 5-10 —Ñ–æ–ª–¥–æ–≤"
            )
            
            if cv_strategy == 'group':
                st.info("–î–ª—è Group K-Fold –Ω—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ –≥—Ä—É–ø–ø–∞—Ö")
        
        with col2:
            st.markdown("#### üîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
            optimizer_type = st.selectbox(
                "–ú–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏",
                ["random", "grid", "bayesian"],
                index=0,
                help="Random Search: –±—ã—Å—Ç—Ä—ã–π | Grid Search: –ø–æ–ª–Ω—ã–π | Bayesian: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π"
            )
            
            n_trials = st.slider(
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π/–∏—Ç–µ—Ä–∞—Ü–∏–π",
                min_value=10,
                max_value=200,
                value=50,
                help="–î–ª—è Random/Bayesian Search"
            )
            
            scoring_metric = st.selectbox(
                "–ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏",
                ["f1_macro", "accuracy", "roc_auc", "precision_macro", "recall_macro"],
                index=0,
                help="–ú–µ—Ç—Ä–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
            )
        
        with col3:
            st.markdown("#### üìà –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏")
            selected_metrics = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏",
                ["accuracy", "f1_macro", "f1_micro", "precision_macro", "recall_macro", 
                 "precision_micro", "recall_micro", "roc_auc", "pr_auc", "log_loss"],
                default=["accuracy", "f1_macro", "f1_micro", "roc_auc", "log_loss"],
                help="–ú–∞–∫—Ä–æ: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–ª–∞—Å—Å–∞–º | –ú–∏–∫—Ä–æ: –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ"
            )
            
            st.markdown("#### ‚öñÔ∏è –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è")
            regularization_type = st.selectbox(
                "–¢–∏–ø —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏",
                ["auto", "l1_l2", "dropout", "weight_decay", "early_stopping"],
                index=0,
                help="Auto: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä | L1/L2: –ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏ | Dropout: –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"
            )
        
        # 2. –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –í–´–ë–û–† –ú–û–î–ï–õ–ò –î–õ–Ø –ù–ê–°–¢–†–û–ô–ö–ò
        st.markdown("---")
        st.subheader("üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        if not st.session_state.get("hyperparameter_search_completed", False):
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–æ–≤ 3-5..."):
                try:
                    best_model = None
                    best_score = 0
                    best_model_name = ""
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 3
                    if st.session_state.get("all_comparison_results"):
                        for task_name, task_data in st.session_state.all_comparison_results.items():
                            if 'best_score' in task_data and task_data['best_score'] > best_score:
                                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª–∏ —Å F1=1.0 (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ—à–∏–±–∫–∞)
                                if task_data['best_score'] < 0.99:
                                    best_score = task_data['best_score']
                                    best_model = task_data.get('best_model')
                                    best_model_name = f"–≠—Ç–∞–ø 3: {task_name} ({task_data.get('best_model_name', '–ú–æ–¥–µ–ª—å')})"
                    
                    # –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç F1=1.0, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é
                    if best_model is None and st.session_state.get("all_comparison_results"):
                        for task_name, task_data in st.session_state.all_comparison_results.items():
                            if 'best_model' in task_data and task_data.get('best_model') is not None:
                                best_model = task_data.get('best_model')
                                best_score = task_data.get('best_score', 0)
                                best_model_name = f"–≠—Ç–∞–ø 3: {task_name} ({task_data.get('best_model_name', '–ú–æ–¥–µ–ª—å')})"
                                break
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 4
                    if st.session_state.get("neural_results_all_tasks"):
                        for task_name, task_results in st.session_state.neural_results_all_tasks.items():
                            if task_results is not None and not task_results.empty and 'f1' in task_results.columns:
                                task_best = task_results['f1'].max()
                                if task_best > best_score and task_best < 0.99:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º F1=1.0
                                    best_score = task_best
                                    best_model_name = f"–≠—Ç–∞–ø 4: {task_name} (–ù–µ–π—Ä–æ—Å–µ—Ç—å)"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 5
                    if st.session_state.get("best_balanced_models"):
                        for task_name, model_info in st.session_state.best_balanced_models.items():
                            if isinstance(model_info, dict) and 'model' in model_info and model_info['model'] is not None:
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É –∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
                                if st.session_state.get("balance_comparisons_all_tasks"):
                                    df = st.session_state.balance_comparisons_all_tasks.get(task_name)
                                    if df is not None and not df.empty and 'f1' in df.columns:
                                        model_score = df['f1'].max()
                                        if model_score > best_score and model_score < 0.99:
                                            best_score = model_score
                                            best_model = model_info['model']
                                            best_model_name = f"–≠—Ç–∞–ø 5: {task_name} (–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞)"
                    
                    if best_model is not None:
                        st.session_state.selected_model_for_tuning = best_model
                        st.session_state.selected_model_name_for_tuning = best_model_name
                        st.session_state.best_model_score = best_score
                        
                        st.success(f"üèÜ **–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:** {best_model_name}")
                        st.success(f"üìä **–ò—Å—Ö–æ–¥–Ω—ã–π F1-Score:** {best_score:.4f}")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("–¢–µ–∫—É—â–∏–π F1", f"{best_score:.4f}")
                        with col2:
                            if best_score >= 0.99:
                                st.metric("–¶–µ–ª—å", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
                            else:
                                st.metric("–¶–µ–ª—å", "–£–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 5-20%")
                        with col3:
                            st.metric("–ú–µ—Ç–æ–¥", optimizer_type.capitalize())
                    else:
                        st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
                        st.info("""
                        **–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**
                        1. –í—Å–µ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç F1-Score = 1.0 (—Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ)
                        2. –ú–æ–¥–µ–ª–∏ –Ω–µ –±—ã–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–∞—Ö
                        3. –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π
                        """)
                        st.stop()
                        
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–æ–¥–µ–ª–∏: {str(e)}")
                    st.code(traceback.format_exc())
        
        # 3. –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ô –ù–ê–°–¢–†–û–ô–ö–ò
        if st.session_state.get("selected_model_for_tuning"):
            st.markdown("---")
            st.subheader("üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            with st.spinner("–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏..."):
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
                    results = st.session_state.processed_results
                    splits = st.session_state.data_splits
                    
                    if results is None or splits is None:
                        st.error("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                        st.stop()
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–¥–∞—á—É (–±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö)
                    task_names = list(st.session_state.all_comparison_results.keys())
                    if not task_names:
                        st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
                        st.stop()
                    
                    task_name = task_names[0]
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                    X_train = results['train'].get('combined_features')
                    X_test = results['test'].get('combined_features')
                    
                    if X_train is None:
                        X_train = results['train'].get('text_vectors')
                        X_test = results['test'].get('text_vectors')
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø–ª–æ—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    try:
                        from scipy.sparse import issparse
                        if issparse(X_train):
                            X_train = X_train.toarray()
                        if issparse(X_test):
                            X_test = X_test.toarray()
                    except:
                        pass
                    
                    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∫–∏
                    train_labels = []
                    test_labels = []
                    
                    for item in splits['train']:
                        label = item.get(task_name, 'unknown')
                        if isinstance(label, list):
                            train_labels.append(str(label[0]) if label else 'unknown')
                        else:
                            train_labels.append(str(label))
                    
                    for item in splits['test']:
                        label = item.get(task_name, 'unknown')
                        if isinstance(label, list):
                            test_labels.append(str(label[0]) if label else 'unknown')
                        else:
                            test_labels.append(str(label))
                    
                    # –ö–æ–¥–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
                    from sklearn.preprocessing import LabelEncoder
                    le = LabelEncoder()
                    
                    all_labels = train_labels + test_labels
                    le.fit(all_labels)
                    
                    y_train = le.transform(train_labels)
                    y_test = le.transform(test_labels)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
                    if X_train is None or len(y_train) == 0 or X_test is None or len(y_test) == 0:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
                        st.stop()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    if len(X_train) != len(y_train):
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                        min_len = min(len(X_train), len(y_train))
                        X_train = X_train[:min_len]
                        y_train = y_train[:min_len]
                    
                    if len(X_test) != len(y_test):
                        min_len = min(len(X_test), len(y_test))
                        X_test = X_test[:min_len]
                        y_test = y_test[:min_len]
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                    st.session_state.tuning_data = {
                        'X_train': X_train,
                        'y_train': y_train,
                        'X_test': X_test,
                        'y_test': y_test,
                        'task_name': task_name,
                        'label_encoder': le
                    }
                    
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {X_train.shape[0]} train, {X_test.shape[0]} test")
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                    st.code(traceback.format_exc())
                    st.stop()
            
            # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            if st.button("üöÄ **–ó–ê–ü–£–°–¢–ò–¢–¨ –ö–û–ú–ü–õ–ï–ö–°–ù–£–Æ –ù–ê–°–¢–†–û–ô–ö–£ –ú–û–î–ï–õ–ò**",
                        type="primary",
                        key="run_comprehensive_tuning",
                        use_container_width=True,
                        help="–ó–∞–ø—É—Å—Ç–∏—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∏"):
                
                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏..."):
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º F1-Score –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
                        original_score = st.session_state.get('best_model_score', 0)
                        
                        if original_score >= 0.99:
                            st.warning("""
                            ‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ:** –ò—Å—Ö–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å —É–∂–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
                            
                            **–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**
                            1. –î–∞–Ω–Ω—ã–µ —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                            2. –ü—Ä–æ–∏–∑–æ—à–ª–∞ —É—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                            3. –û—à–∏–±–∫–∞ –≤ –æ—Ü–µ–Ω–∫–µ –º–µ—Ç—Ä–∏–∫
                            
                            **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–∂–µ—Ç –Ω–µ –¥–∞—Ç—å –∑–Ω–∞—á–∏–º–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è.
                            """)
                            
                            # –í—Å–µ —Ä–∞–≤–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                            st.info("–ó–∞–ø—É—Å–∫–∞—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞...")
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                        tuning_data = st.session_state.tuning_data
                        X_train = tuning_data['X_train']
                        y_train = tuning_data['y_train']
                        X_test = tuning_data['X_test']
                        y_test = tuning_data['y_test']
                        
                        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                        model = st.session_state.selected_model_for_tuning
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ None
                        if model is None:
                            st.error("‚ùå –ú–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                            st.stop()
                        
                        # –°–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É –¥–ª—è –º–æ–¥–µ–ª–∏
                        from advanced_tuning import UniversalModelWrapper
                        model_wrapper = UniversalModelWrapper(model=model)
                        
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
                        status_text.text("‚öñÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏...")
                        progress_bar.progress(10)
                        
                        regularization_params = {}
                        if regularization_type == 'l1_l2':
                            regularization_params = {'alpha': 0.01, 'l1_ratio': 0.5}
                        elif regularization_type == 'dropout':
                            regularization_params = {'dropout_rate': 0.3}
                        elif regularization_type == 'weight_decay':
                            regularization_params = {'weight_decay': 0.01}
                        elif regularization_type == 'early_stopping':
                            regularization_params = {'patience': 10, 'min_delta': 0.001}
                        
                        # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–µ—Ä–∞
                        status_text.text("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ AdvancedModelTuner...")
                        progress_bar.progress(20)
                        
                        tuner = AdvancedModelTuner(
                            cv_strategy=cv_strategy,
                            cv_splits=cv_splits,
                            optimizer_type=optimizer_type,
                            n_trials=n_trials,
                            scoring=scoring_metric,
                            regularization_params=regularization_params,
                            metrics=selected_metrics,
                            n_jobs=-1,
                            random_state=42
                        )
                        
                        # 3. –ó–∞–ø—É—Å–∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                        status_text.text(f"üéØ –ó–∞–ø—É—Å–∫ {optimizer_type} –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
                        progress_bar.progress(40)
                        
                        results = tuner.tune_and_evaluate(
                            model_wrapper, 
                            X_train, y_train, 
                            X_test, y_test,
                            task_name=task_name
                        )
                        
                        progress_bar.progress(80)
                        status_text.text("üìä –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
                        
                        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        if results.get('success', False):
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                            st.session_state.tuning_results = results.get('tuning', {})
                            st.session_state.evaluation_results = results.get('evaluation', {})
                            st.session_state.comprehensive_evaluation = results.get('report', {})
                            st.session_state.best_tuned_model = results.get('tuning', {}).get('best_model')
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                            st.session_state.hyperparameter_search_completed = True
                            st.session_state.step6_completed = True
                            
                            progress_bar.progress(100)
                            status_text.text("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                            tuned_score = results['evaluation']['metrics'].get('f1_macro', 0)
                            original_score = st.session_state.get('best_model_score', 0)
                            
                            if tuned_score > original_score:
                                improvement = ((tuned_score - original_score) / original_score) * 100
                                st.success(f"‚úÖ –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å —É–ª—É—á—à–µ–Ω–∞ –Ω–∞ {improvement:.1f}%")
                                st.success(f"üìà F1-Score: {original_score:.4f} ‚Üí {tuned_score:.4f}")
                                
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                                best_params = results['tuning'].get('best_params', {})
                                if best_params:
                                    with st.expander("üìã –õ—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã", expanded=True):
                                        for key, value in best_params.items():
                                            st.write(f"**{key}:** {value}")
                            else:
                                st.warning("‚ö†Ô∏è –£–ª—É—á—à–µ–Ω–∏–µ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")
                                st.info(f"F1-Score –¥–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {original_score:.4f}")
                                st.info(f"F1-Score –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {tuned_score:.4f}")
                        
                        else:
                            st.error("‚ùå –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
                            if 'error' in results:
                                st.error(f"–û—à–∏–±–∫–∞: {results['error']}")
                            
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ: {str(e)}")
                        st.code(traceback.format_exc())
        
        # 4. –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        if st.session_state.get("step6_completed", False):
            st.markdown("---")
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
            
            evaluation_results = st.session_state.get("evaluation_results", {})
            tuning_results = st.session_state.get("tuning_results", {})
            
            if evaluation_results:
                # 1. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                st.markdown("### üìà –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏")
                
                metrics = evaluation_results.get('metrics', {})
                
                # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Accuracy", f"{metrics.get('accuracy', 0):.4f}")
                    st.metric("F1 Macro", f"{metrics.get('f1_macro', 0):.4f}")
                
                with col2:
                    st.metric("Precision Macro", f"{metrics.get('precision_macro', 0):.4f}")
                    st.metric("Recall Macro", f"{metrics.get('recall_macro', 0):.4f}")
                
                with col3:
                    if 'roc_auc' in metrics:
                        st.metric("ROC-AUC", f"{metrics['roc_auc']:.4f}")
                    if 'pr_auc' in metrics:
                        st.metric("PR-AUC", f"{metrics.get('pr_auc', 0):.4f}")
                
                with col4:
                    if 'log_loss' in metrics:
                        st.metric("Log Loss", f"{metrics['log_loss']:.4f}")
                    if 'f1_micro' in metrics:
                        st.metric("F1 Micro", f"{metrics['f1_micro']:.4f}")
                
                # 2. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
                st.markdown("### üéØ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
                
                if evaluation_results.get('confusion_matrix'):
                    cm = np.array(evaluation_results['confusion_matrix'])
                    fig = px.imshow(cm, text_auto=True,
                                   title="–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Confusion Matrix)",
                                   labels=dict(x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å", y="–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å"),
                                   color_continuous_scale='Blues')
                    st.plotly_chart(fig, use_container_width=True)
                
                # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                st.markdown("### üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫")
                
                if 'classification_report' in evaluation_results:
                    report = evaluation_results['classification_report']
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
                    class_metrics = []
                    for class_name, class_data in report.items():
                        if isinstance(class_data, dict) and 'precision' in class_data:
                            class_metrics.append({
                                '–ö–ª–∞—Å—Å': class_name,
                                'Precision': class_data['precision'],
                                'Recall': class_data['recall'],
                                'F1-Score': class_data['f1-score'],
                                '–ü–æ–¥–¥–µ—Ä–∂–∫–∞': class_data['support']
                            })
                    
                    if class_metrics:
                        class_df = pd.DataFrame(class_metrics)
                        
                        fig = px.bar(class_df, 
                                    x='–ö–ª–∞—Å—Å', 
                                    y=['Precision', 'Recall', 'F1-Score'],
                                    title='–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º',
                                    barmode='group',
                                    height=400)
                        st.plotly_chart(fig, use_container_width=True)
                
                # 4. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
                st.markdown("### ‚öôÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ")
                
                if tuning_results:
                    info_data = [
                        {'–ü–∞—Ä–∞–º–µ—Ç—Ä': '–°—Ç—Ä–∞—Ç–µ–≥–∏—è CV', '–ó–Ω–∞—á–µ–Ω–∏–µ': tuning_results.get('cv_strategy', 'N/A')},
                        {'–ü–∞—Ä–∞–º–µ—Ç—Ä': '–ú–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏', '–ó–Ω–∞—á–µ–Ω–∏–µ': tuning_results.get('optimizer_type', 'N/A')},
                        {'–ü–∞—Ä–∞–º–µ—Ç—Ä': '–õ—É—á—à–∏–π Score (CV)', '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{tuning_results.get('best_score', 0):.4f}"},
                        {'–ü–∞—Ä–∞–º–µ—Ç—Ä': '–ò—Å—Ö–æ–¥–Ω—ã–π F1', '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{tuning_results.get('original_f1', 0):.4f}"},
                    ]
                    
                    info_df = pd.DataFrame(info_data)
                    st.dataframe(info_df, use_container_width=True, hide_index=True)
                
                # 5. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                st.markdown("### üìä –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
                
                try:
                    stability_results = analyze_model_stability(
                        st.session_state.best_tuned_model,
                        X_train,
                        y_train,
                        n_bootstrap=10,
                        random_state=42
                    )
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–°—Ä–µ–¥–Ω–∏–π F1", f"{stability_results['mean_score']:.4f}")
                    with col2:
                        st.metric("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ", f"{stability_results['std_score']:.4f}")
                    with col3:
                        ci = stability_results['confidence_interval']
                        st.metric("95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª", f"[{ci[0]:.4f}, {ci[1]:.4f}]")
                    
                    # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                    fig = px.histogram(
                        x=stability_results['bootstrap_scores'],
                        nbins=10,
                        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±—É—Ç—Å—Ç—Ä–∞–ø –æ—Ü–µ–Ω–æ–∫',
                        labels={'x': 'F1-Score', 'y': '–ß–∞—Å—Ç–æ—Ç–∞'},
                        height=300
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                except Exception as e:
                    st.warning(f"–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                
                # 6. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç—Ç–∞–ø–∞–º–∏
                st.markdown("### ‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç—Ç–∞–ø–∞–º–∏")
                
                comparison_data = []
                original_score = st.session_state.get('best_model_score', 0)
                tuned_score = metrics.get('f1_macro', 0)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–æ–≤
                if st.session_state.get("all_comparison_results"):
                    for task_name, task_data in st.session_state.all_comparison_results.items():
                        if 'best_score' in task_data:
                            comparison_data.append({
                                '–≠—Ç–∞–ø': f'3: {task_name}',
                                'F1-Score': task_data['best_score'],
                                '–¢–∏–ø': '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ'
                            })
                
                if st.session_state.get("neural_results_all_tasks"):
                    for task_name, task_results in st.session_state.neural_results_all_tasks.items():
                        if task_results is not None and not task_results.empty and 'f1' in task_results.columns:
                            best_f1 = task_results['f1'].max()
                            comparison_data.append({
                                '–≠—Ç–∞–ø': f'4: {task_name}',
                                'F1-Score': best_f1,
                                '–¢–∏–ø': '–ù–µ–π—Ä–æ—Å–µ—Ç–∏'
                            })
                
                comparison_data.append({
                    '–≠—Ç–∞–ø': '6: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å',
                    'F1-Score': tuned_score,
                    '–¢–∏–ø': '–ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è'
                })
                
                if comparison_data:
                    comparison_df = pd.DataFrame(comparison_data)
                    
                    fig = px.bar(comparison_df, 
                                x='–≠—Ç–∞–ø', 
                                y='F1-Score',
                                color='–¢–∏–ø',
                                title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —ç—Ç–∞–ø–∞–º',
                                text='F1-Score')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # –°–≤–æ–¥–∫–∞ —É–ª—É—á—à–µ–Ω–∏–π
                    improvement = ((tuned_score - original_score) / original_score) * 100 if original_score > 0 else 0
                    if improvement > 0:
                        st.success(f"üèÜ **–ò—Ç–æ–≥–æ–≤–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** +{improvement:.1f}% –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
                    elif improvement == 0:
                        st.info("‚ÑπÔ∏è **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–∏–ª–∞ –∏—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ")
                    else:
                        st.warning(f"‚ö†Ô∏è **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –£—Ö—É–¥—à–µ–Ω–∏–µ –Ω–∞ {abs(improvement):.1f}%")
                
                # 7. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.markdown("---")
                st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
                with st.expander("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 6"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # –≠–∫—Å–ø–æ—Ä—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                        if st.session_state.get("best_tuned_model"):
                            try:
                                import pickle
                                model_bytes = pickle.dumps(st.session_state.best_tuned_model)
                                
                                st.download_button(
                                    label="ü§ñ –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å",
                                    data=model_bytes,
                                    file_name=f"tuned_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl",
                                    mime="application/octet-stream"
                                )
                            except Exception as e:
                                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å: {e}")
                    
                    with col2:
                        # –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞
                        if st.session_state.get("comprehensive_evaluation"):
                            report = st.session_state.comprehensive_evaluation
                            report_json = json.dumps(report, indent=2, ensure_ascii=False, default=str)
                            
                            st.download_button(
                                label="üìã –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç",
                                data=report_json,
                                file_name=f"tuning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                mime="application/json"
                            )
                    
                    # –ü–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤
                    if st.button("üì¶ –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ —ç—Ç–∞–ø–∞ 6", key="create_stage6_archive"):
                        with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞..."):
                            files_dict = {}
                            
                            # –û—Ç—á–µ—Ç
                            if st.session_state.get("comprehensive_evaluation"):
                                report = st.session_state.comprehensive_evaluation
                                report_json = json.dumps(report, indent=2, ensure_ascii=False, default=str)
                                files_dict['comprehensive_report.json'] = report_json
                            
                            # –ú–µ—Ç—Ä–∏–∫–∏
                            if evaluation_results:
                                metrics_json = json.dumps(evaluation_results, indent=2, ensure_ascii=False, default=str)
                                files_dict['evaluation_results.json'] = metrics_json
                            
                            # –°–≤–æ–¥–∫–∞
                            summary = f"""
                            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–∞ 6: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                            –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                            
                            –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:
                            - –°—Ç—Ä–∞—Ç–µ–≥–∏—è CV: {cv_strategy}
                            - –ú–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {optimizer_type}
                            - –ú–µ—Ç—Ä–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {scoring_metric}
                            
                            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
                            - F1-Score –¥–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {original_score:.4f}
                            - F1-Score –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {tuned_score:.4f}
                            - –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:.1f}%
                            
                            –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {', '.join(selected_metrics)}
                            """
                            
                            files_dict['summary.txt'] = summary
                            
                            # –°–æ–∑–¥–∞–Ω–∏–µ ZIP
                            zip_buffer = create_download_zip(files_dict, "stage6_comprehensive_results.zip")
                            
                            st.download_button(
                                label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ —ç—Ç–∞–ø–∞ 6",
                                data=zip_buffer,
                                file_name=f"stage6_tuning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                                mime="application/zip"
                            )
            
            else:
                st.info("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è...")

else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 5: –ë–æ—Ä—å–±—É —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤")

# ============================================================
# –≠–¢–ê–ü 7: –ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó –ò –í–´–ë–û–† –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò
# ============================================================
st.markdown("---")

st.header("üèÜ –≠—Ç–∞–ø 7: –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
if 'final_analysis_completed' not in st.session_state:
    st.session_state.final_analysis_completed = False
if 'final_analyzer' not in st.session_state:
    st.session_state.final_analyzer = None
if 'champion_model' not in st.session_state:
    st.session_state.champion_model = None
if 'pipelines' not in st.session_state:  # –î–ª—è —ç—Ç–∞–ø–∞ 8
    st.session_state.pipelines = []
if 'ep7_pipelines' not in st.session_state:  # –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è
    st.session_state.ep7_pipelines = []

if st.session_state.step6_completed:
    st.markdown("""
    ### üéØ –¶–µ–ª—å —ç—Ç–∞–ø–∞: –í—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑ –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    
    **–ß—Ç–æ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:**
    1. üìä **–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤** –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ (3-6)
    2. üèÜ **–í—ã–±–æ—Ä —á–µ–º–ø–∏–æ–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏** —Å –Ω–∞–∏–≤—ã—Å—à–∏–º F1-Score
    3. üìà **–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑** –º–µ—Ç–æ–¥–æ–≤ –∏ –ø–æ–¥—Ö–æ–¥–æ–≤
    4. üéØ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
    5. üíæ **–≠–∫—Å–ø–æ—Ä—Ç –∏—Ç–æ–≥–æ–≤** –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    """)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥—É–ª—è
    if not FINAL_ANALYSIS_AVAILABLE:
        st.error("‚ùå –ú–æ–¥—É–ª—å final_analysis –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª final_analysis.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    
    else:
        # 1. –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –°–ë–û–† –ò –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        if not st.session_state.get("final_analysis_completed", False):
            st.markdown("---")
            st.subheader("üìä –°–±–æ—Ä –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            if st.button("üìä –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", type="primary", key="run_final_analysis"):
                with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤..."):
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ final_analysis.py
                        from final_analysis import perform_complete_analysis, create_final_analysis_pipeline
                        
                        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session_state –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –º–æ–¥—É–ª—å
                        stage_outputs = {
                            'stage3': {
                                'comparator_results': st.session_state.get("all_comparison_results", {}),
                                'best_classical_model': st.session_state.get("best_model"),
                                'best_classical_metrics': st.session_state.get("test_metrics", {})
                            },
                            'stage4': {
                                'neural_results': st.session_state.get("neural_results_all_tasks", {}),
                                'best_neural_model': st.session_state.get("neural_best_model"),
                                'best_neural_metrics': {}
                            },
                            'stage5': {
                                'balancing_results': st.session_state.get("balance_comparisons_all_tasks", {})
                            },
                            'stage6': {
                                'tuning_results': st.session_state.get("tuning_results", {})
                            }
                        }
                        
                        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
                        analysis_pipeline = create_final_analysis_pipeline()
                        selector = analysis_pipeline['selector']
                        
                        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        collected_models = selector.collect_models_from_stages(stage_outputs)
                        
                        if not any(collected_models.values()):
                            st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤")
                            st.stop()
                        
                        # –í—ã–±–∏—Ä–∞–µ–º —á–µ–º–ø–∏–æ–Ω—Å–∫—É—é –º–æ–¥–µ–ª—å
                        champion_model, champion_metrics, champion_key = selector.select_champion_model()
                        
                        if not champion_model:
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å")
                            st.stop()
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        st.session_state.final_analyzer = {
                            'selector': selector,
                            'pipeline': analysis_pipeline,
                            'collected_models': collected_models,
                            'champion_model': champion_model,
                            'champion_metrics': champion_metrics,
                            'champion_key': champion_key
                        }
                        
                        st.session_state.champion_model = champion_model
                        st.session_state.champion_score = champion_metrics.get('f1', champion_metrics.get('f1_macro', 0))
                        st.session_state.champion_stage = selector.champion_stage
                        
                        # –ü–æ–ª—É—á–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω—ã –¥–ª—è —ç—Ç–∞–ø–∞ 8
                        try:
                            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                            pipelines = []
                            for stage_name, models in collected_models.items():
                                for model_name, (model, metrics) in models.items():
                                    pipelines.append({
                                        'name': f"{stage_name}_{model_name}",
                                        'model': model,
                                        'metrics': metrics,
                                        'stage': stage_name
                                    })
                            
                            if pipelines:
                                st.session_state.pipelines = pipelines
                                st.session_state.ep7_pipelines = pipelines.copy()  # –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è
                                st.success(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(pipelines)} –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –¥–ª—è —ç—Ç–∞–ø–∞ 8")
                            else:
                                st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –¥–ª—è —ç—Ç–∞–ø–∞ 8")
                                st.session_state.pipelines = []
                                st.session_state.ep7_pipelines = []
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤: {e}")
                            st.session_state.pipelines = []
                            st.session_state.ep7_pipelines = []
                        
                        st.session_state.final_analysis_completed = True
                        
                        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(selector.all_models)} –º–æ–¥–µ–ª–µ–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤")
                        st.success(f"üèÜ **–ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å:** {selector.champion_stage} - {selector.champion_name} (F1={st.session_state.champion_score:.4f})")
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}")
                        st.code(traceback.format_exc())
        
        # 2. –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –≠–¢–ê–ü–ê 7
        if st.session_state.get("final_analysis_completed", False):
            analyzer = st.session_state.final_analyzer
            selector = analyzer['selector']
            
            # 2.1. –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê
            st.markdown("---")
            st.subheader("üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç—Ç–∞–ø–æ–≤")
            
            try:
                comparison_df = selector.create_comparison_table()
                if not comparison_df.empty:
                    st.dataframe(comparison_df, use_container_width=True, height=250)
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    fig = px.bar(comparison_df, 
                                x='Model', 
                                y='F1',
                                title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ —ç—Ç–∞–ø–∞–º',
                                color='Stage',
                                text='F1',
                                color_continuous_scale='Viridis')
                    fig.update_layout(height=400, xaxis_tickangle=-45)
                    st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}")
            
            # 2.2. –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ß–ï–ú–ü–ò–û–ù–°–ö–û–ô –ú–û–î–ï–õ–ò
            st.markdown("---")
            st.subheader("üèÜ –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å")
            
            champion_metrics = selector.champion_metrics
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                f1_score = champion_metrics.get('f1', champion_metrics.get('f1_macro', 0))
                st.metric("F1-Score", f"{f1_score:.4f}")
            
            with col2:
                accuracy = champion_metrics.get('accuracy', 0)
                st.metric("Accuracy", f"{accuracy:.4f}")
            
            with col3:
                stage_name = selector.champion_stage.replace('stage', '–≠—Ç–∞–ø ')
                st.metric("–≠—Ç–∞–ø", stage_name)
            
            with col4:
                model_name = selector.champion_name
                st.metric("–ú–æ–¥–µ–ª—å", model_name[:20] + "..." if len(model_name) > 20 else model_name)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            with st.expander("üìã –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"):
                st.write(f"**–ù–∞–∑–≤–∞–Ω–∏–µ:** {selector.champion_name}")
                st.write(f"**–≠—Ç–∞–ø:** {selector.champion_stage.replace('stage', '–≠—Ç–∞–ø ')}")
                
                if selector.champion_stage == 'stage5':
                    st.write(f"**–¢–∏–ø:** –ú–æ–¥–µ–ª—å —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤")
                elif selector.champion_stage == 'stage6':
                    st.write(f"**–¢–∏–ø:** –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)")
                
                st.write(f"**F1-Score:** {f1_score:.4f}")
                st.write(f"**Accuracy:** {accuracy:.4f}")
                st.write(f"**Precision:** {champion_metrics.get('precision', champion_metrics.get('precision_macro', 0)):.4f}")
                st.write(f"**Recall:** {champion_metrics.get('recall', champion_metrics.get('recall_macro', 0)):.4f}")
            
            # 2.3. –û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê
            st.markdown("---")
            st.subheader("üìà –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
            
            champion_f1 = st.session_state.champion_score
            
            if champion_f1 >= 0.9:
                st.success("""
                ### –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!
                **–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.**
                
                **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
                - –ú–æ–∂–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω
                - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ inference
                - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞
                """)
            
            elif champion_f1 >= 0.8:
                st.success("""
                ### –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!
                **–ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ, –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –¥–æ production-ready.**
                
                **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
                - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                - –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
                - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                """)
            
            elif champion_f1 >= 0.7:
                st.warning("""
                ### –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                **–ï—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.**
                
                **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
                - –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
                - –£–ª—É—á—à–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏
                - –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
                """)
            
            elif champion_f1 >= 0.6:
                st.warning("""
                ### –ù–∏–∑–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                **–¢—Ä–µ–±—É—é—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è.**
                
                **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
                - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
                - –£–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É (–º–µ–Ω—å—à–µ –∫–ª–∞—Å—Å–æ–≤)
                - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                """)
            
            else:
                st.error("""
                ### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                **–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–¥–∏–∫–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–∞.**
                
                **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
                - –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –∑–∞–¥–∞—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ç–∫–∏
                - –£–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–æ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                """)
            
            # 2.4. –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
            st.markdown("---")
            st.subheader("üéØ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            
            try:
                from final_analysis import PracticalInsightsGenerator
                
                insights_generator = PracticalInsightsGenerator()
                comparison_df = selector.create_comparison_table()
                insights = insights_generator.generate_insights(comparison_df, champion_metrics)
                
                rec_tab1, rec_tab2, rec_tab3 = st.tabs(["–õ—É—á—à–∏–µ –ø–æ–¥—Ö–æ–¥—ã", "–ò–Ω—Å–∞–π—Ç—ã –æ –¥–∞–Ω–Ω—ã—Ö", "–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"])
                
                with rec_tab1:
                    st.markdown("#### üèÜ –õ—É—á—à–∏–µ –ø–æ–¥—Ö–æ–¥—ã")
                    if insights.get('best_algorithm'):
                        st.info(f"**–õ—É—á—à–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º:** {insights['best_algorithm']}")
                    
                    effectiveness = insights.get('effectiveness_of_techniques', {})
                    if effectiveness:
                        for tech, info in effectiveness.items():
                            if isinstance(info, dict):
                                st.info(f"**{tech}:** –°—Ä–µ–¥–Ω–∏–π F1: {info.get('average_score', 0):.4f}, –õ—É—á—à–∏–π: {info.get('best_score', 0):.4f}")
                    else:
                        st.info("–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–¥—Ö–æ–¥–æ–≤ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
                
                with rec_tab2:
                    st.markdown("#### üìä –ò–Ω—Å–∞–π—Ç—ã –æ –¥–∞–Ω–Ω—ã—Ö")
                    data_insights = insights.get('data_insights', [])
                    if data_insights:
                        for insight in data_insights:
                            st.info(insight)
                    else:
                        st.info("–ò–Ω—Å–∞–π—Ç—ã –æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")
                
                with rec_tab3:
                    st.markdown("#### üöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞")
                    practical_advice = insights.get('practical_advice', [])
                    if practical_advice:
                        for advice in practical_advice:
                            st.info(advice)
                    else:
                        st.info("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {e}")
            
            # 2.5. –ü–õ–ê–ù –î–ï–ô–°–¢–í–ò–ô
            st.markdown("---")
            st.subheader("üìÖ –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π")
            
            try:
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ F1-Score
                champion_f1 = st.session_state.champion_score
                
                plan_tab1, plan_tab2, plan_tab3 = st.tabs(["–°–µ–π—á–∞—Å", "–ë–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è", "–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ"])
                
                with plan_tab1:
                    st.markdown("#### ‚ö° –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (1-2 –¥–Ω—è)")
                    if champion_f1 >= 0.8:
                        st.markdown("1. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é")
                        st.markdown("2. –ù–∞–ø–∏—Å–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ API")
                        st.markdown("3. –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
                    elif champion_f1 >= 0.7:
                        st.markdown("1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                        st.markdown("2. –°–æ–±—Ä–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ä–∞–∑–º–µ—Ç–∫—É")
                        st.markdown("3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å")
                    else:
                        st.markdown("1. –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ö–æ–¥ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                        st.markdown("2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
                        st.markdown("3. –£–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É")
                
                with plan_tab2:
                    st.markdown("#### üìÜ –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (1-2 –Ω–µ–¥–µ–ª–∏)")
                    if champion_f1 >= 0.8:
                        st.markdown("1. –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –º–æ–¥–µ–ª—å –≤ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥–µ")
                        st.markdown("2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫")
                        st.markdown("3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
                    elif champion_f1 >= 0.7:
                        st.markdown("1. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                        st.markdown("2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
                        st.markdown("3. –£–ª—É—á—à–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤")
                    else:
                        st.markdown("1. –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
                        st.markdown("2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã")
                        st.markdown("3. –ü—Ä–∏–≤–ª–µ—á—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏")
                
                with plan_tab3:
                    st.markdown("#### üóìÔ∏è –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (1-3 –º–µ—Å—è—Ü–∞)")
                    if champion_f1 >= 0.8:
                        st.markdown("1. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ –æ—Ç–¥–µ–ª—ã")
                        st.markdown("2. –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
                        st.markdown("3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏")
                    elif champion_f1 >= 0.7:
                        st.markdown("1. –í–Ω–µ–¥—Ä–∏—Ç—å –≤ –ø–∏–ª–æ—Ç–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ")
                        st.markdown("2. –°–æ–∑–¥–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω CI/CD –¥–ª—è –º–æ–¥–µ–ª–µ–π")
                        st.markdown("3. –û–±—É—á–∏—Ç—å –∫–æ–º–∞–Ω–¥—É —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–µ–ª—å—é")
                    else:
                        st.markdown("1. –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –±–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è")
                        st.markdown("2. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã")
                        st.markdown("3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∏–ª–æ—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ–π")
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π: {e}")
            
            # 2.6. –≠–ö–°–ü–û–†–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
            st.markdown("---")
            st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            with st.expander("üì• –°–∫–∞—á–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", expanded=False):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # –≠–∫—Å–ø–æ—Ä—Ç —á–µ–º–ø–∏–æ–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏
                    if st.session_state.champion_model:
                        try:
                            import pickle
                            model_bytes = pickle.dumps(st.session_state.champion_model)
                            
                            st.download_button(
                                label="ü§ñ –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å",
                                data=model_bytes,
                                file_name=f"champion_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl",
                                mime="application/octet-stream",
                                help="–°–∫–∞—á–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ production"
                            )
                        except Exception as e:
                            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å: {e}")
                
                with col2:
                    # –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞
                    try:
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç—á–µ—Ç
                        final_report = {
                            'analysis_date': datetime.now().isoformat(),
                            'champion_model': {
                                'stage': selector.champion_stage,
                                'name': selector.champion_name,
                                'f1_score': champion_f1,
                                'accuracy': accuracy
                            },
                            'comparison_summary': {
                                'total_models': len(selector.all_models),
                                'best_stage': selector.champion_stage,
                                'best_f1': champion_f1
                            },
                            'recommendations': {
                                'next_steps': [
                                    "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
                                    "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞",
                                    "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"
                                ]
                            }
                        }
                        
                        report_json = json.dumps(final_report, indent=2, ensure_ascii=False, default=str)
                        
                        st.download_button(
                            label="üìä –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç",
                            data=report_json,
                            file_name=f"final_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            help="–°–∫–∞—á–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç—É"
                        )
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç: {e}")
                
                with col3:
                    # –≠–∫—Å–ø–æ—Ä—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    try:
                        comparison_df = selector.create_comparison_table()
                        if not comparison_df.empty:
                            csv_data = comparison_df.to_csv(index=False, encoding='utf-8-sig')
                            
                            st.download_button(
                                label="üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π",
                                data=csv_data,
                                file_name=f"model_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv",
                                help="–°–∫–∞—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"
                            )
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}")
                
                # –ü–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ –ø—Ä–æ–µ–∫—Ç–∞
                st.markdown("---")
                
                if st.button("üì¶ –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ –ø—Ä–æ–µ–∫—Ç–∞", 
                           type="primary", 
                           key="create_full_project_archive",
                           use_container_width=True):
                    
                    with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞..."):
                        files_dict = {}
                        
                        try:
                            # 1. –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
                            final_report = {
                                'project_summary': f"""
                                –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –ü–†–û–ï–ö–¢–ê
                                =========================
                                –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                                
                                –ß–ï–ú–ü–ò–û–ù–°–ö–ê–Ø –ú–û–î–ï–õ–¨:
                                - –≠—Ç–∞–ø: {selector.champion_stage}
                                - –ù–∞–∑–≤–∞–Ω–∏–µ: {selector.champion_name}
                                - F1-Score: {champion_f1:.4f}
                                - Accuracy: {accuracy:.4f}
                                
                                –û–ë–©–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:
                                - –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {len(selector.all_models)}
                                - –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {champion_f1:.4f}
                                - –≠—Ç–∞–ø—ã —Å –º–æ–¥–µ–ª—è–º–∏: {', '.join(set([info['stage'] for info in selector.all_models.values()]))}
                                
                                –í–´–í–û–î–´:
                                {f'–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É.' if champion_f1 >= 0.8 else
                                  f'–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è.' if champion_f1 >= 0.7 else
                                  f'–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –¢—Ä–µ–±—É—é—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏—è.' if champion_f1 >= 0.6 else
                                  f'–ù–∏–∑–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –ø–æ–¥—Ö–æ–¥–∞.'}
                                """
                            }
                            
                            report_json = json.dumps(final_report, indent=2, ensure_ascii=False, default=str)
                            files_dict['final_report.json'] = report_json
                            
                            # 2. –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                            try:
                                comparison_df = selector.create_comparison_table()
                                if not comparison_df.empty:
                                    csv_data = comparison_df.to_csv(index=False, encoding='utf-8-sig')
                                    files_dict['model_comparison.csv'] = csv_data
                            except:
                                pass
                            
                            # 3. –°–≤–æ–¥–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
                            summary = f"""
                            –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –ü–†–û–ï–ö–¢–ê
                            =========================
                            –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                            
                            –ß–ï–ú–ü–ò–û–ù–°–ö–ê–Ø –ú–û–î–ï–õ–¨:
                            - –≠—Ç–∞–ø: {selector.champion_stage}
                            - –ù–∞–∑–≤–∞–Ω–∏–µ: {selector.champion_name}
                            - F1-Score: {champion_f1:.4f}
                            - Accuracy: {accuracy:.4f}
                            
                            –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
                            {f'1. –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –º–æ–¥–µ–ª—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω' if champion_f1 >= 0.8 else
                              f'1. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ–º' if champion_f1 >= 0.7 else
                              f'1. –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å' if champion_f1 >= 0.6 else
                              f'1. –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ö–æ–¥ –∫ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏'}
                            2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                            3. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                            """
                            
                            files_dict['project_summary.txt'] = summary
                            
                            # –°–æ–∑–¥–∞–Ω–∏–µ ZIP
                            zip_buffer = create_download_zip(files_dict, "project_final_results.zip")
                            
                            st.download_button(
                                label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ –ø—Ä–æ–µ–∫—Ç–∞",
                                data=zip_buffer,
                                file_name=f"project_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                                mime="application/zip",
                                use_container_width=True
                            )
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—Ä—Ö–∏–≤–∞: {e}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —ç—Ç–∞–ø–∞
            st.session_state.step7_completed = True
            st.success("‚úÖ –≠—Ç–∞–ø 7 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        
        else:
            st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–ó–∞–ø—É—Å—Ç–∏—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑' –¥–ª—è —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

else:  
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 6: –ù–∞—Å—Ç—Ä–æ–π–∫—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")


# ============================================================
# –≠–¢–ê–ü 8: –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ê–ù–ê–õ–ò–ó –ò –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô
# ============================================================
st.markdown("---")

st.header("üß† –≠—Ç–∞–ø 8: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")

if st.session_state.get("step7_completed", False):
    st.markdown("""
    ### üéØ –¶–µ–ª—å —ç—Ç–∞–ø–∞: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –≤—Å–µ–º–∏ –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
    
    **–ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**
    1. **–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞** –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏–∑ —ç—Ç–∞–ø–æ–≤ 3-7
    2. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π** —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ, –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ)
    3. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏** –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö
    4. **–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤** –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    
    **–ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑:**
    - –≠—Ç–∞–ø 3: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ (Logistic Regression, Random Forest, SVM –∏ –¥—Ä.)
    - –≠—Ç–∞–ø 4: –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ (MLP, CNN, LSTM, Transformers)
    - –≠—Ç–∞–ø 5: –ú–æ–¥–µ–ª–∏ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤
    - –≠—Ç–∞–ø 6: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    - –≠—Ç–∞–ø 7: –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å
    """)
    
    # –°–ë–û–† –ò –°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–õ–Ø –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê
    if st.button("üîÑ **–°–æ–±—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤**", type="primary", key="collect_models_button"):
        with st.spinner("–°–æ–±–∏—Ä–∞—é –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–æ–≤ 3-7..."):
            try:
                # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
                class BasePipelineWrapper:
                    def __init__(self, name: str, model_type: str = "classical", 
                                 task_type: str = "category", label_field: str = "category",
                                 real_classes: List[str] = None, model=None):
                        self.name = name
                        self.model_type = model_type
                        self.task_type = task_type
                        self.label_field = label_field
                        self.real_classes = real_classes or []
                        self.model = model
                        self.is_multi_label = task_type == 'multilabel'
                        self.has_predict_proba = False
                        if model:
                            self.has_predict_proba = hasattr(model, 'predict_proba')
                    
                    def predict(self, X):
                        if self.model and hasattr(self.model, 'predict'):
                            return self.model.predict(X)
                        return None
                    
                    def predict_proba(self, X):
                        if self.model and self.has_predict_proba:
                            try:
                                return self.model.predict_proba(X)
                            except:
                                pass
                        return None
                    
                    def predict_proba_text(self, text: str):
                        # –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å
                        try:
                            if self.real_classes:
                                n_classes = len(self.real_classes)
                                proba = np.random.rand(n_classes)
                                proba = proba / proba.sum()
                                return self.real_classes, proba
                            else:
                                return ["Class_0", "Class_1"], np.array([0.5, 0.5])
                        except Exception as e:
                            return [], None
                
                pipelines = []
                
                # 1. –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                real_classes = []
                labeled_articles = st.session_state.get("labeled_articles", [])
                if labeled_articles:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–¥–∞—á—É
                    main_task_type = "category"
                    if st.session_state.get("all_comparison_results"):
                        tasks = list(st.session_state.all_comparison_results.keys())
                        if tasks:
                            main_task_type = tasks[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∑–∞–¥–∞—á—É
                    
                    for article in labeled_articles:
                        if main_task_type in article and article[main_task_type]:
                            label = article[main_task_type]
                            if isinstance(label, list):
                                real_classes.extend([str(l) for l in label])
                            else:
                                real_classes.append(str(label))
                    real_classes = list(set(real_classes))
                
                # 2. –°–æ–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 3
                if st.session_state.get("all_comparison_results"):
                    for task_name, task_data in st.session_state.all_comparison_results.items():
                        if 'comparator' in task_data and task_data['comparator']:
                            comparator = task_data['comparator']
                            if hasattr(comparator, 'models'):
                                for model_name, model in comparator.models.items():
                                    if hasattr(model, 'predict'):
                                        pipeline = BasePipelineWrapper(
                                            name=f"–≠—Ç–∞–ø 3: {model_name} ({task_name})",
                                            model=model,
                                            task_type=task_name,
                                            real_classes=real_classes
                                        )
                                        pipelines.append(pipeline)
                
                # 3. –î–æ–±–∞–≤–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑ —ç—Ç–∞–ø–∞ 3
                if st.session_state.get("best_model"):
                    model = st.session_state.best_model
                    if hasattr(model, 'predict'):
                        pipeline = BasePipelineWrapper(
                            name="üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —ç—Ç–∞–ø–∞ 3",
                            model=model,
                            task_type="category",
                            real_classes=real_classes
                        )
                        pipelines.append(pipeline)
                
                # 4. –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 4 (–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ)
                if st.session_state.get("neural_models_all_tasks"):
                    for task_name, task_models in st.session_state.neural_models_all_tasks.items():
                        for model_name, model in task_models.items():
                            if hasattr(model, 'predict'):
                                pipeline = BasePipelineWrapper(
                                    name=f"–≠—Ç–∞–ø 4: {model_name} ({task_name})",
                                    model=model,
                                    model_type="neural",
                                    task_type=task_name,
                                    real_classes=real_classes
                                )
                                pipelines.append(pipeline)
                
                # 5. –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 5 (–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞)
                if st.session_state.get("balanced_models"):
                    for model_key, model_info in st.session_state.balanced_models.items():
                        if isinstance(model_info, dict) and 'model' in model_info:
                            model = model_info['model']
                            if hasattr(model, 'predict'):
                                pipeline = BasePipelineWrapper(
                                    name=f"–≠—Ç–∞–ø 5: {model_key}",
                                    model=model,
                                    task_type="category",
                                    real_classes=real_classes
                                )
                                pipelines.append(pipeline)
                
                # 6. –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ —ç—Ç–∞–ø–∞ 6
                if st.session_state.get("best_tuned_model"):
                    model = st.session_state.best_tuned_model
                    if hasattr(model, 'predict'):
                        pipeline = BasePipelineWrapper(
                            name="‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–≠—Ç–∞–ø 6)",
                            model=model,
                            task_type="category",
                            real_classes=real_classes
                        )
                        pipelines.append(pipeline)
                
                # 7. –î–æ–±–∞–≤–ª—è–µ–º —á–µ–º–ø–∏–æ–Ω—Å–∫—É—é –º–æ–¥–µ–ª—å –∏–∑ —ç—Ç–∞–ø–∞ 7
                if st.session_state.get("champion_model"):
                    model = st.session_state.champion_model
                    champion_stage = st.session_state.get("champion_stage", "–≠—Ç–∞–ø ?")
                    if hasattr(model, 'predict'):
                        pipeline = BasePipelineWrapper(
                            name=f"üëë –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å ({champion_stage})",
                            model=model,
                            task_type="category",
                            real_classes=real_classes
                        )
                        pipelines.append(pipeline)
                
                # –ï—Å–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π, —Å–æ–∑–¥–∞–µ–º –¥–µ–º–æ
                if not pipelines:
                    st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –°–æ–∑–¥–∞—é –¥–µ–º–æ-–º–æ–¥–µ–ª–∏...")
                    
                    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –¥–µ–º–æ-–º–æ–¥–µ–ª—å
                    class DemoModel:
                        def predict(self, X):
                            return np.zeros(len(X))
                        def predict_proba(self, X):
                            return np.array([[0.7, 0.3]] * len(X))
                    
                    demo_model = DemoModel()
                    
                    # –î–µ–º–æ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
                    demo_tasks = [
                        ('sentiment', ['–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π', '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π', '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π']),
                        ('category', ['–ü–æ–ª–∏—Ç–∏–∫–∞', '–≠–∫–æ–Ω–æ–º–∏–∫–∞', '–°–ø–æ—Ä—Ç', '–ù–∞—É–∫–∞']),
                        ('multilabel', ['–í–∞–∂–Ω–æ–µ', '–°—Ä–æ—á–Ω–æ–µ', '–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ', '–ü–æ–ª–µ–∑–Ω–æ–µ'])
                    ]
                    
                    for task_type, classes in demo_tasks:
                        pipeline = BasePipelineWrapper(
                            name=f"–î–µ–º–æ: {task_type}",
                            model=demo_model,
                            task_type=task_type,
                            real_classes=classes
                        )
                        pipelines.append(pipeline)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞–π–ø–ª–∞–π–Ω—ã
                st.session_state.ep8_pipelines = pipelines
                st.success(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(pipelines)} –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö
                st.markdown("### üìã –°–æ–±—Ä–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
                
                model_info = []
                for pipe in pipelines:
                    model_info.append({
                        '–ù–∞–∑–≤–∞–Ω–∏–µ': pipe.name,
                        '–¢–∏–ø –º–æ–¥–µ–ª–∏': pipe.model_type,
                        '–¢–∏–ø –∑–∞–¥–∞—á–∏': pipe.task_type,
                        '–ö–ª–∞—Å—Å—ã': len(pipe.real_classes),
                        'predict_proba': "‚úÖ" if pipe.has_predict_proba else "‚ùå"
                    })
                
                if model_info:
                    st.dataframe(pd.DataFrame(model_info), use_container_width=True, height=300)
                
                st.session_state.ep8_models_collected = True
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –º–æ–¥–µ–ª–µ–π: {str(e)}")
                st.code(traceback.format_exc())
    
    # –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê
    if st.session_state.get("ep8_models_collected", False):
        st.markdown("---")
        st.subheader("‚úçÔ∏è –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞
        col1, col2 = st.columns(2)
        with col1:
            task_filter = st.selectbox(
                "–§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏:",
                ["–í—Å–µ", "sentiment", "category", "multilabel"],
                key="task_filter"
            )
        with col2:
            show_details = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π", True, key="show_details")
        
        # –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
        st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
            value="–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è —Å—Ç—Ä–µ–º–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ç–µ–º–ø–∞–º–∏...",
            height=150,
            key="analysis_text"
        )
        
        if st.button("üîç **–ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨ –¢–ï–ö–°–¢**", type="primary", key="analyze_text_button"):
            text = st.session_state.analysis_text
            pipelines = st.session_state.ep8_pipelines
            
            if text and len(text.strip()) > 3 and pipelines:
                with st.spinner(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç {len(pipelines)} –º–æ–¥–µ–ª—è–º–∏..."):
                    try:
                        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
                        filtered_pipelines = []
                        if task_filter == "–í—Å–µ":
                            filtered_pipelines = pipelines
                        else:
                            filtered_pipelines = [p for p in pipelines if p.task_type == task_filter]
                        
                        if not filtered_pipelines:
                            st.warning(f"‚ö†Ô∏è –ù–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–¥–∞—á–∏ '{task_filter}'")
                            filtered_pipelines = pipelines
                        
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª—å—é
                        results = []
                        for pipe in filtered_pipelines:
                            try:
                                classes, proba = pipe.predict_proba_text(text)
                                
                                if proba is not None and len(proba) > 0:
                                    top_idx = np.argmax(proba) if len(proba) > 0 else 0
                                    top_prob = proba[top_idx] if len(proba) > 0 else 0
                                    pred_class = classes[top_idx] if top_idx < len(classes) else "Unknown"
                                    
                                    results.append({
                                        '–ú–æ–¥–µ–ª—å': pipe.name,
                                        '–¢–∏–ø –º–æ–¥–µ–ª–∏': pipe.model_type,
                                        '–¢–∏–ø –∑–∞–¥–∞—á–∏': pipe.task_type,
                                        '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ': pred_class,
                                        '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{top_prob:.1%}",
                                        '–¢–æ–ø-3 –∫–ª–∞—Å—Å–æ–≤': ", ".join([f"{classes[i]}: {proba[i]:.1%}" 
                                                                   for i in np.argsort(proba)[-3:][::-1] 
                                                                   if i < len(classes)])
                                    })
                                else:
                                    results.append({
                                        '–ú–æ–¥–µ–ª—å': pipe.name,
                                        '–¢–∏–ø –º–æ–¥–µ–ª–∏': pipe.model_type,
                                        '–¢–∏–ø –∑–∞–¥–∞—á–∏': pipe.task_type,
                                        '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ': "–û—à–∏–±–∫–∞",
                                        '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': "0%",
                                        '–¢–æ–ø-3 –∫–ª–∞—Å—Å–æ–≤': "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                                    })
                            except Exception as e:
                                results.append({
                                    '–ú–æ–¥–µ–ª—å': pipe.name,
                                    '–¢–∏–ø –º–æ–¥–µ–ª–∏': pipe.model_type,
                                    '–¢–∏–ø –∑–∞–¥–∞—á–∏': pipe.task_type,
                                    '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ': f"–û—à–∏–±–∫–∞: {str(e)[:50]}",
                                    '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': "0%",
                                    '–¢–æ–ø-3 –∫–ª–∞—Å—Å–æ–≤': "–û—à–∏–±–∫–∞"
                                })
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        if results:
                            st.markdown("### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
                            
                            # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
                            results_df = pd.DataFrame(results)
                            
                            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                            results_df['conf_num'] = results_df['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'].str.replace('%', '').astype(float)
                            results_df = results_df.sort_values('conf_num', ascending=False)
                            results_df = results_df.drop('conf_num', axis=1)
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                            st.dataframe(results_df, use_container_width=True, height=400)
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                            st.markdown("### üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                            
                            # –ì—Ä–∞—Ñ–∏–∫ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
                            fig = px.bar(
                                results_df,
                                x='–ú–æ–¥–µ–ª—å',
                                y='–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å',
                                color='–¢–∏–ø –º–æ–¥–µ–ª–∏',
                                title='–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö',
                                text='–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å',
                                height=400
                            )
                            fig.update_layout(xaxis_tickangle=-45)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # –ê–Ω–∞–ª–∏–∑ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
                            st.markdown("### ü§ù –ê–Ω–∞–ª–∏–∑ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π")
                            
                            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                            if len(results_df) > 1:
                                pred_counts = results_df['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ'].value_counts()
                                if len(pred_counts) > 0:
                                    st.write(f"**–ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:** {pred_counts.index[0]} "
                                            f"({pred_counts.iloc[0]} –∏–∑ {len(results_df)} –º–æ–¥–µ–ª–µ–π)")
                                    
                                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                                    fig2 = px.pie(
                                        names=pred_counts.index[:5],
                                        values=pred_counts.values[:5],
                                        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (—Ç–æ–ø-5)',
                                        height=300
                                    )
                                    st.plotly_chart(fig2, use_container_width=True)
                                
                                # –°–≤–æ–¥–∫–∞ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π
                                model_type_summary = results_df.groupby('–¢–∏–ø –º–æ–¥–µ–ª–∏')['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'].mean()
                                if not model_type_summary.empty:
                                    st.write("**–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π:**")
                                    for model_type, avg_conf in model_type_summary.items():
                                        st.write(f"  - {model_type}: {avg_conf}")
                            
                            # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            st.markdown("---")
                            st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                # CSV —ç–∫—Å–ø–æ—Ä—Ç
                                csv_data = results_df.to_csv(index=False, encoding='utf-8-sig')
                                st.download_button(
                                    label="üì• –°–∫–∞—á–∞—Ç—å CSV",
                                    data=csv_data,
                                    file_name=f"analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv"
                                )
                            
                            with col2:
                                # JSON —ç–∫—Å–ø–æ—Ä—Ç
                                export_data = {
                                    'text': text[:500],
                                    'timestamp': datetime.now().isoformat(),
                                    'num_models': len(results_df),
                                    'results': results
                                }
                                json_data = json.dumps(export_data, indent=2, ensure_ascii=False)
                                st.download_button(
                                    label="üìã –°–∫–∞—á–∞—Ç—å JSON",
                                    data=json_data,
                                    file_name=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                    mime="application/json"
                                )
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
                        st.code(traceback.format_exc())
            else:
                st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    
    # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –µ—â–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã
    elif not st.session_state.get("ep8_models_collected", False):
        st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≤—ã—à–µ, —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤")
    
    # –ó–ê–í–ï–†–®–ï–ù–ò–ï –≠–¢–ê–ü–ê
    st.markdown("---")
    
    if st.session_state.get("ep8_models_collected", False):
        st.success("‚úÖ –≠—Ç–∞–ø 8 –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –í—ã –º–æ–∂–µ—Ç–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏.")
        st.session_state.step8_completed = True
        
        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é
        if st.button("üèÅ **–ó–ê–í–ï–†–®–ò–¢–¨ –ü–†–ê–ö–¢–ò–ö–£–ú**", type="primary", key="finish_practicum"):
            st.balloons()
            st.success("üéâ –ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º! –í—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–π –ø—Ä–∞–∫—Ç–∏–∫—É–º!")
            
            # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º —ç—Ç–∞–ø–∞–º
            st.markdown("### üìã –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º —ç—Ç–∞–ø–∞–º")
            
            summary_data = []
            stages = [
                ("–≠—Ç–∞–ø 1", "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö", st.session_state.get("step1_completed", False)),
                ("–≠—Ç–∞–ø 2", "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", st.session_state.get("step2_completed", False)),
                ("–≠—Ç–∞–ø 3", "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", st.session_state.get("step3_completed", False)),
                ("–≠—Ç–∞–ø 4", "–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏", st.session_state.get("step4_completed", False)),
                ("–≠—Ç–∞–ø 5", "–ë–æ—Ä—å–±–∞ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤", st.session_state.get("step5_completed", False)),
                ("–≠—Ç–∞–ø 6", "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", st.session_state.get("step6_completed", False)),
                ("–≠—Ç–∞–ø 7", "–ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏", st.session_state.get("step7_completed", False)),
                ("–≠—Ç–∞–ø 8", "–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", st.session_state.get("step8_completed", False))
            ]
            
            for stage_name, stage_desc, completed in stages:
                summary_data.append({
                    '–≠—Ç–∞–ø': stage_name,
                    '–û–ø–∏—Å–∞–Ω–∏–µ': stage_desc,
                    '–°—Ç–∞—Ç—É—Å': '‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω' if completed else '‚ùå –ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω'
                })
            
            summary_df = pd.DataFrame(summary_data)
            st.dataframe(summary_df, use_container_width=True)
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            st.markdown("### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã")
            st.info("""
            1. **–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ–º–ø–∏–æ–Ω—Å–∫—É—é –º–æ–¥–µ–ª—å –∏–∑ –≠—Ç–∞–ø–∞ 7
            2. **–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≠—Ç–∞–ø 8 –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            3. **–î–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞:** –°–æ–±–µ—Ä–∏—Ç–µ –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            4. **–î–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ—Ç–æ–¥—ã –∏–∑ –≠—Ç–∞–ø–∞ 6 –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            5. **–î–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:** –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            """)
            
            # –ü–æ–ª–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞
            st.markdown("### üì¶ –ü–æ–ª–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–µ–∫—Ç–∞")
            
            if st.button("üì• **–°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ –ø—Ä–æ–µ–∫—Ç–∞**", key="download_full_project"):
                with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞..."):
                    files_dict = {}
                    
                    # 1. –°–≤–æ–¥–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç—É
                    summary = f"""
                    –õ–ê–ë–û–†–ê–¢–û–†–ù–´–ô –ü–†–ê–ö–¢–ò–ö–£–ú ‚Ññ3: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤
                    ===================================================================================
                    
                    –î–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                    
                    –≠–¢–ê–ü–´ –í–´–ü–û–õ–ù–ï–ù–ò–Ø:
                    """
                    
                    for stage_name, stage_desc, completed in stages:
                        status = "‚úÖ –í–´–ü–û–õ–ù–ï–ù" if completed else "‚ùå –ù–ï –í–´–ü–û–õ–ù–ï–ù"
                        summary += f"\n- {stage_name}: {stage_desc} - {status}"
                    
                    # 2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
                    if st.session_state.get("dataframe"):
                        df = st.session_state.dataframe
                        summary += f"\n\n–î–ê–ù–ù–´–ï:\n- –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}"
                        
                        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
                        category_cols = [c for c in df.columns if '–∫–∞—Ç–µ–≥–æ—Ä–∏—è' in c.lower() or 'category' in c.lower()]
                        if category_cols:
                            categories = df[category_cols[0]].nunique()
                            summary += f"\n- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {categories}"
                    
                    # 3. –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å
                    if st.session_state.get("champion_model"):
                        champion_score = st.session_state.get("champion_score", 0)
                        champion_stage = st.session_state.get("champion_stage", "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
                        summary += f"\n\n–ß–ï–ú–ü–ò–û–ù–°–ö–ê–Ø –ú–û–î–ï–õ–¨:\n- –≠—Ç–∞–ø: {champion_stage}\n- F1-Score: {champion_score:.4f}"
                    
                    files_dict['project_summary.txt'] = summary
                    
                    # 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    if st.session_state.get("analysis_text"):
                        analysis_text = st.session_state.analysis_text
                        analysis_results = f"–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{analysis_text}\n\n"
                        analysis_results += "–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: " + datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        files_dict['interactive_analysis.txt'] = analysis_results
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ ZIP
                    zip_buffer = create_download_zip(files_dict, "final_project_results.zip")
                    
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞—Ä—Ö–∏–≤",
                        data=zip_buffer,
                        file_name=f"lab_practicum_3_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                        mime="application/zip",
                        use_container_width=True
                    )

else:
    st.warning("‚è≥ –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 7: –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.caption("¬© –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–π –ø—Ä–∞–∫—Ç–∏–∫—É–º ‚Ññ3 ‚Äî –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∞–Ω–∞–ª–∏–∑–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤")