"""
–≠—Ç–∞–ø 8: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ –∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ (3-7)
"""

import numpy as np
import pandas as pd
import streamlit as st
import warnings
import traceback
import json
from typing import Dict, List, Tuple, Optional, Any, Union
from collections import Counter
import re
from datetime import datetime

warnings.filterwarnings('ignore')


class BasePipelineWrapper:
    """
    –ë–∞–∑–æ–≤–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π –≤—Å–µ—Ö —Ç–∏–ø–æ–≤
    """
    def __init__(self, name: str, model_type: str = "classical", 
                 task_type: str = "category", label_field: str = "category",
                 real_classes: List[str] = None, model=None):
        self.name = name
        self.model_type = model_type
        self.task_type = task_type
        self.label_field = label_field
        self.real_classes = real_classes or []
        self.model = model
        self.is_multi_label = task_type == 'multilabel'
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.has_predict_proba = False
        if model:
            self.has_predict_proba = hasattr(model, 'predict_proba')
    
    def predict(self, X):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        if self.model and hasattr(self.model, 'predict'):
            return self.model.predict(X)
        return None
    
    def predict_proba(self, X):
        """–ú–µ—Ç–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        if self.model and self.has_predict_proba:
            try:
                return self.model.predict_proba(X)
            except:
                pass
        return None


class ClassicalPipelineWrapper(BasePipelineWrapper):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, name: str, model, task_type: str = "category", 
                 label_field: str = "category", real_classes: List[str] = None,
                 vectorizer=None):
        super().__init__(name, "classical", task_type, label_field, real_classes, model)
        self.vectorizer = vectorizer
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–∞—Ö –∏–∑ –º–æ–¥–µ–ª–∏
        self._extract_class_info()
    
    def _extract_class_info(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–ª–∞—Å—Å–∞—Ö –∏–∑ –º–æ–¥–µ–ª–∏"""
        if hasattr(self.model, 'classes_'):
            self.real_classes = list(self.model.classes_)
        elif hasattr(self.model, 'label_encoder') and self.model.label_encoder is not None:
            self.real_classes = list(self.model.label_encoder.classes_)
        elif hasattr(self.model, 'model') and hasattr(self.model.model, 'classes_'):
            self.real_classes = list(self.model.model.classes_)
    
    def predict_proba_text(self, text: str) -> Tuple[List[str], Optional[np.ndarray]]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∑–∞—Ç–æ—Ä, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç
            if self.vectorizer and hasattr(self.vectorizer, 'transform'):
                features = self.vectorizer.transform([text])
                if hasattr(self.model, 'predict_proba'):
                    proba = self.model.predict_proba(features)[0]
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç predict_proba, –∏—Å–ø–æ–ª—å–∑—É–µ–º predict
                    pred = self.model.predict(features)[0]
                    n_classes = len(self.real_classes) if self.real_classes else 2
                    proba = np.zeros(n_classes)
                    if isinstance(pred, (int, np.integer)):
                        if pred < n_classes:
                            proba[pred] = 1.0
                        else:
                            proba[0] = 1.0
                    else:
                        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞, –∏—â–µ–º –≤ real_classes
                        if self.real_classes and str(pred) in self.real_classes:
                            idx = self.real_classes.index(str(pred))
                            proba[idx] = 1.0
                        else:
                            proba[0] = 1.0
                
                return self.real_classes or [f"Class_{i}" for i in range(len(proba))], proba
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –≤–µ–∫—Ç–æ—Ä–∑–∞—Ç–æ—Ä–∞, –Ω–æ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç —Å–≤–æ–π –º–µ—Ç–æ–¥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            elif hasattr(self.model, 'predict_proba_text'):
                return self.model.predict_proba_text(text)
            
            # Fallback: —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            else:
                if self.real_classes:
                    n_classes = len(self.real_classes)
                    proba = np.random.rand(n_classes)
                    proba = proba / proba.sum()
                    return self.real_classes, proba
                else:
                    return ["Class_0", "Class_1"], np.array([0.5, 0.5])
                    
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –≤ {self.name}: {str(e)}")
            return [], None


class NeuralPipelineWrapper(BasePipelineWrapper):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, name: str, model, task_type: str = "category",
                 label_field: str = "category", real_classes: List[str] = None):
        super().__init__(name, "neural", task_type, label_field, real_classes, model)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PyTorch
        self.torch_available = hasattr(model, 'model') and hasattr(model.model, 'to')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–∞—Ö
        if hasattr(model, 'classes_'):
            self.real_classes = list(model.classes_)
        elif hasattr(model, 'label_encoder') and model.label_encoder is not None:
            self.real_classes = list(model.label_encoder.classes_)
    
    def predict_proba_text(self, text: str) -> Tuple[List[str], Optional[np.ndarray]]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª—å—é"""
        try:
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥ predict_proba_text
            if hasattr(self.model, 'predict_proba_text'):
                return self.model.predict_proba_text(text)
            
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç predict_proba –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç
            elif hasattr(self.model, 'predict_proba') and hasattr(self.model, 'prepare_texts'):
                try:
                    prepared = self.model.prepare_texts([text])
                    proba = self.model.predict_proba(prepared)[0]
                    classes = self.real_classes or [f"Class_{i}" for i in range(len(proba))]
                    return classes, proba
                except:
                    pass
            
            # Fallback –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
            if self.real_classes:
                n_classes = len(self.real_classes)
                proba = np.random.rand(n_classes)
                proba = proba / proba.sum()
                return self.real_classes, proba
            else:
                return ["Positive", "Negative"], np.array([0.7, 0.3])
                
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ {self.name}: {str(e)}")
            return [], None


class InteractiveModelAnalyzer:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ–ª–µ–π
    """
    
    def __init__(self, pipelines: List[BasePipelineWrapper]):
        self.pipelines = pipelines
        self.results_cache = {}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω—ã –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
        self.pipelines_by_task = self._group_pipelines_by_task()
    
    def _group_pipelines_by_task(self) -> Dict[str, List[BasePipelineWrapper]]:
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á"""
        groups = {
            'sentiment': [],
            'category': [],
            'multilabel': []
        }
        
        for pipe in self.pipelines:
            task_type = pipe.task_type
            if task_type in groups:
                groups[task_type].append(pipe)
            else:
                # –ï—Å–ª–∏ —Ç–∏–ø –∑–∞–¥–∞—á–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –≤ category
                groups['category'].append(pipe)
        
        return groups
    
    def analyze_text(self, text: str, task_filter: str = None) -> Dict[str, Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            task_filter: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        results = {}
        
        if not text or len(text.strip()) < 3:
            return results
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        tasks_to_analyze = [task_filter] if task_filter else list(self.pipelines_by_task.keys())
        
        for task_type in tasks_to_analyze:
            if task_type in self.pipelines_by_task:
                task_pipelines = self.pipelines_by_task[task_type]
                task_results = {}
                
                for pipe in task_pipelines:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                        classes, proba = pipe.predict_proba_text(text)
                        
                        if proba is not None and len(proba) > 0:
                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º multi-label
                            if pipe.is_multi_label:
                                threshold = 0.5
                                predicted_labels = []
                                predicted_probs = []
                                
                                for i, prob in enumerate(proba):
                                    if i < len(classes) and prob >= threshold:
                                        predicted_labels.append(classes[i])
                                        predicted_probs.append(float(prob))
                                
                                task_results[pipe.name] = {
                                    'classes': classes,
                                    'proba': proba.tolist(),
                                    'pred': predicted_labels if predicted_labels else ["–ù–µ—Ç –º–µ—Ç–æ–∫"],
                                    'top_prob': float(np.max(proba)) if len(proba) > 0 else 0,
                                    'model_type': pipe.model_type,
                                    'task_type': task_type,
                                    'is_multi_label': True,
                                    'predicted_labels': predicted_labels,
                                    'predicted_probs': predicted_probs,
                                    'success': True
                                }
                            else:
                                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º single-label
                                if len(proba) > 0:
                                    top_idx = int(np.argmax(proba))
                                    pred_label = classes[top_idx] if top_idx < len(classes) else str(top_idx)
                                    
                                    task_results[pipe.name] = {
                                        'classes': classes,
                                        'proba': proba.tolist(),
                                        'pred': pred_label,
                                        'top_prob': float(np.max(proba)),
                                        'model_type': pipe.model_type,
                                        'task_type': task_type,
                                        'is_multi_label': False,
                                        'success': True
                                    }
                        else:
                            task_results[pipe.name] = {
                                'error': '–ù–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π',
                                'success': False
                            }
                            
                    except Exception as e:
                        task_results[pipe.name] = {
                            'error': str(e)[:100],
                            'success': False
                        }
                
                if task_results:
                    results[task_type] = task_results
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        cache_key = f"{text[:50]}_{task_filter or 'all'}"
        self.results_cache[cache_key] = {
            'timestamp': datetime.now().isoformat(),
            'text_preview': text[:100],
            'results': results
        }
        
        return results
    
    def get_text_statistics(self, text: str) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        stats = {
            'length_chars': len(text),
            'length_words': 0,
            'sentences': 0,
            'unique_words': 0,
            'avg_word_length': 0,
            'top_words': []
        }
        
        if text:
            # –°–ª–æ–≤–∞
            words = re.findall(r'\b\w+\b', text.lower())
            stats['length_words'] = len(words)
            
            # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentences = re.split(r'[.!?]+', text)
            stats['sentences'] = len([s for s in sentences if s.strip()])
            
            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            unique_words = set(words)
            stats['unique_words'] = len(unique_words)
            
            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
            if words:
                stats['avg_word_length'] = sum(len(w) for w in words) / len(words)
            
            # –¢–æ–ø —Å–ª–æ–≤
            word_counts = Counter(words)
            stats['top_words'] = word_counts.most_common(10)
        
        return stats


class InteractiveAnalysisUI:
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    """
    
    def __init__(self):
        self.analyzer = None
        self.text_statistics = {}
        
    def render_sidebar(self):
        """–†–µ–Ω–¥–µ—Ä –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏"""
        st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
        
        # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        task_options = {
            'all': '–í—Å–µ —Ç–∏–ø—ã –∑–∞–¥–∞—á',
            'sentiment': '–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏',
            'category': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π',
            'multilabel': '–ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è'
        }
        
        selected_task = st.sidebar.selectbox(
            "–¢–∏–ø –∑–∞–¥–∞—á–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
            list(task_options.keys()),
            format_func=lambda x: task_options[x]
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        show_details = st.sidebar.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π", True)
        show_charts = st.sidebar.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏", True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
        export_results = st.sidebar.checkbox("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", False)
        
        return {
            'selected_task': selected_task,
            'show_details': show_details,
            'show_charts': show_charts,
            'export_results': export_results
        }
    
    def render_text_input(self):
        """–†–µ–Ω–¥–µ—Ä –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞"""
        st.header("‚úçÔ∏è –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤
        sample_texts = {
            "–ü—Ä–∏–º–µ—Ä 1 (—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è —Å—Ç—Ä–µ–º–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ç–µ–º–ø–∞–º–∏...",
            "–ü—Ä–∏–º–µ—Ä 2 (–ø–æ–ª–∏—Ç–∏–∫–∞)": "–ù–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã –±—ã–ª–∏ –ø—Ä–∏–Ω—è—Ç—ã –ø–∞—Ä–ª–∞–º–µ–Ω—Ç–æ–º –ø–æ—Å–ª–µ –¥–æ–ª–≥–∏—Ö –æ–±—Å—É–∂–¥–µ–Ω–∏–π...",
            "–ü—Ä–∏–º–µ—Ä 3 (—Å–ø–æ—Ä—Ç)": "–°–ø–æ—Ä—Ç—Å–º–µ–Ω—ã –ø–æ–∫–∞–∑–∞–ª–∏ –≤—ã–¥–∞—é—â–∏–µ—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö..."
        }
        
        # –í—ã–±–æ—Ä –ø—Ä–∏–º–µ—Ä–∞
        sample_option = st.selectbox(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞:",
            ["–°–≤–æ–π —Ç–µ–∫—Å—Ç"] + list(sample_texts.keys())
        )
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        if sample_option == "–°–≤–æ–π —Ç–µ–∫—Å—Ç":
            default_text = st.session_state.get('interactive_text', '')
            text_input = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
                value=default_text,
                height=200,
                placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏..."
            )
        else:
            text_input = st.text_area(
                "–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
                value=sample_texts[sample_option],
                height=200
            )
        
        # –ö–Ω–æ–ø–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            analyze_button = st.button(
                "üîç **–ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨ –¢–ï–ö–°–¢**",
                type="primary",
                use_container_width=True
            )
        
        return text_input, analyze_button
    
    def render_model_statistics(self, pipelines: List[BasePipelineWrapper]):
        """–†–µ–Ω–¥–µ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–µ–π"""
        st.sidebar.header("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–µ–π")
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–æ —Ç–∏–ø–∞–º
        model_types = Counter([p.model_type for p in pipelines])
        task_types = Counter([p.task_type for p in pipelines])
        
        st.sidebar.metric("–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π", len(pipelines))
        st.sidebar.metric("–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ", model_types.get('classical', 0))
        st.sidebar.metric("–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ", model_types.get('neural', 0))
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–¥–∞—á–∞—Ö
        with st.sidebar.expander("–¢–∏–ø—ã –∑–∞–¥–∞—á:"):
            for task_type, count in task_types.items():
                st.write(f"‚Ä¢ {task_type}: {count}")
    
    def render_results(self, text: str, results: Dict, settings: Dict):
        """–†–µ–Ω–¥–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        if not results:
            st.warning("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞
        with st.expander("üìù –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞", expanded=True):
            stats = self.analyzer.get_text_statistics(text)
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–°–∏–º–≤–æ–ª–æ–≤", stats['length_chars'])
            with col2:
                st.metric("–°–ª–æ–≤", stats['length_words'])
            with col3:
                st.metric("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π", stats['sentences'])
            with col4:
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤", stats['unique_words'])
            
            # –¢–æ–ø —Å–ª–æ–≤
            if stats['top_words']:
                st.subheader("–ß–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞:")
                top_words_df = pd.DataFrame(stats['top_words'], columns=['–°–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–∞'])
                st.dataframe(top_words_df, use_container_width=True)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
        task_display_names = {
            'sentiment': 'üìà –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏',
            'category': 'üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π',
            'multilabel': 'üè∑Ô∏è –ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è'
        }
        
        for task_type, task_results in results.items():
            if task_results:
                display_name = task_display_names.get(task_type, task_type)
                st.markdown(f"### {display_name}")
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                table_data = []
                for model_name, info in task_results.items():
                    if info.get('success', False):
                        if info.get('is_multi_label', False):
                            pred_display = ", ".join(info.get('predicted_labels', []))[:50]
                            if len(info.get('predicted_labels', [])) > 3:
                                pred_display += "..."
                        else:
                            pred_display = info.get('pred', 'N/A')
                        
                        table_data.append({
                            '–ú–æ–¥–µ–ª—å': model_name,
                            '–¢–∏–ø': info.get('model_type', 'N/A'),
                            '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ': pred_display,
                            '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{info.get('top_prob', 0):.1%}",
                            '–ö–ª–∞—Å—Å—ã': len(info.get('classes', []))
                        })
                
                if table_data:
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    df_results = pd.DataFrame(table_data)
                    df_results['conf_num'] = df_results['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'].str.replace('%', '').astype(float)
                    df_results = df_results.sort_values('conf_num', ascending=False)
                    df_results = df_results.drop('conf_num', axis=1)
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                    st.dataframe(df_results, use_container_width=True)
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                    if settings['show_charts']:
                        self._render_results_charts(task_type, task_results)
                else:
                    st.info("‚ÑπÔ∏è –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏")
        
        # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if settings['export_results']:
            self._export_results(text, results)
    
    def _render_results_charts(self, task_type: str, task_results: Dict):
        """–†–µ–Ω–¥–µ—Ä –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            import plotly.graph_objects as go
            import plotly.express as px
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
            model_names = []
            confidences = []
            
            for model_name, info in task_results.items():
                if info.get('success', False) and 'top_prob' in info:
                    model_names.append(model_name)
                    confidences.append(info['top_prob'])
            
            if model_names and confidences:
                # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
                fig = go.Figure(data=[
                    go.Bar(
                        x=model_names,
                        y=confidences,
                        text=[f"{c:.1%}" for c in confidences],
                        textposition='auto',
                        marker_color='lightblue'
                    )
                ])
                
                fig.update_layout(
                    title=f'–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π ({task_type})',
                    xaxis_title='–ú–æ–¥–µ–ª—å',
                    yaxis_title='–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å',
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                if task_results:
                    best_model_name = max(task_results.items(), 
                                        key=lambda x: x[1].get('top_prob', 0) if x[1].get('success', False) else 0)[0]
                    best_model_info = task_results[best_model_name]
                    
                    if 'proba' in best_model_info and 'classes' in best_model_info:
                        proba = best_model_info['proba']
                        classes = best_model_info['classes']
                        
                        if len(proba) > 0 and len(classes) > 0:
                            # –ë–µ—Ä–µ–º —Ç–æ–ø-10 –∫–ª–∞—Å—Å–æ–≤
                            indices = np.argsort(proba)[-10:][::-1]
                            top_classes = [classes[i] for i in indices if i < len(classes)]
                            top_probs = [proba[i] for i in indices if i < len(proba)]
                            
                            fig2 = px.bar(
                                x=top_probs,
                                y=top_classes,
                                orientation='h',
                                title=f'–¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {best_model_name}',
                                labels={'x': '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', 'y': '–ö–ª–∞—Å—Å'}
                            )
                            
                            st.plotly_chart(fig2, use_container_width=True)
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏: {e}")
    
    def _export_results(self, text: str, results: Dict):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        st.markdown("---")
        st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        export_data = {
            'text': text[:500],
            'timestamp': datetime.now().isoformat(),
            'statistics': self.analyzer.get_text_statistics(text),
            'results': results
        }
        
        col1, col2 = st.columns(2)
        
        with col1:
            # JSON —ç–∫—Å–ø–æ—Ä—Ç
            json_str = json.dumps(export_data, indent=2, ensure_ascii=False)
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å JSON",
                data=json_str,
                file_name=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col2:
            # CSV —ç–∫—Å–ø–æ—Ä—Ç (—Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
            try:
                all_data = []
                for task_type, task_results in results.items():
                    for model_name, info in task_results.items():
                        if info.get('success', False):
                            row = {
                                'task_type': task_type,
                                'model_name': model_name,
                                'model_type': info.get('model_type', ''),
                                'prediction': str(info.get('pred', '')),
                                'confidence': info.get('top_prob', 0),
                                'num_classes': len(info.get('classes', []))
                            }
                            all_data.append(row)
                
                if all_data:
                    df_export = pd.DataFrame(all_data)
                    csv_data = df_export.to_csv(index=False, encoding='utf-8')
                    
                    st.download_button(
                        label="üìä –°–∫–∞—á–∞—Ç—å CSV",
                        data=csv_data,
                        file_name=f"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
            except:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CSV —Ñ–∞–π–ª")
    
    def render_comparison_analysis(self, results: Dict):
        """–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not results or len(results) < 2:
            return
        
        st.markdown("---")
        st.header("üìà –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        all_models = []
        for task_type, task_results in results.items():
            for model_name, info in task_results.items():
                if info.get('success', False):
                    all_models.append({
                        'task_type': task_type,
                        'model_name': model_name,
                        'confidence': info.get('top_prob', 0),
                        'model_type': info.get('model_type', 'unknown')
                    })
        
        if all_models:
            df_comparison = pd.DataFrame(all_models)
            
            # –¢–æ–ø –º–æ–¥–µ–ª–µ–π –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            st.subheader("üèÜ –¢–æ–ø –º–æ–¥–µ–ª–µ–π")
            df_top = df_comparison.sort_values('confidence', ascending=False).head(10)
            st.dataframe(df_top, use_container_width=True)
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π
            st.subheader("üìä –ü–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π")
            type_stats = df_comparison.groupby('model_type')['confidence'].agg(['mean', 'count']).round(3)
            st.dataframe(type_stats, use_container_width=True)
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
            st.subheader("üìä –ü–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á")
            task_stats = df_comparison.groupby('task_type')['confidence'].agg(['mean', 'count']).round(3)
            st.dataframe(task_stats, use_container_width=True)


def build_pipelines_from_stages() -> List[BasePipelineWrapper]:
    """
    –°–±–æ—Ä –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    """
    pipelines = []
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∑–∞—Ç–æ—Ä –∏–∑ —ç—Ç–∞–ø–∞ 2
    vectorizer = st.session_state.get("vectorizer")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    main_task_type = st.session_state.get("label_field_select", "category")
    if main_task_type == 'categories':
        main_task_type = 'multilabel'
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö
    real_classes = []
    labeled_articles = st.session_state.get("labeled_articles", [])
    if labeled_articles and main_task_type in ['sentiment', 'category']:
        for article in labeled_articles:
            if main_task_type in article and article[main_task_type]:
                real_classes.append(str(article[main_task_type]))
        real_classes = list(set(real_classes))
    
    # 1. –ú–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 3 (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ)
    if st.session_state.get("comparator"):
        comparator = st.session_state.comparator
        if hasattr(comparator, 'models'):
            for model_name, model_info in comparator.models.items():
                if hasattr(model_info, 'predict'):
                    wrapper = ClassicalPipelineWrapper(
                        name=f"–≠—Ç–∞–ø 3: {model_name}",
                        model=model_info,
                        task_type=main_task_type,
                        label_field=main_task_type,
                        real_classes=real_classes,
                        vectorizer=vectorizer
                    )
                    pipelines.append(wrapper)
    
    # 2. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏–∑ —ç—Ç–∞–ø–∞ 3
    if st.session_state.get("best_model"):
        model = st.session_state.best_model
        if hasattr(model, 'predict'):
            wrapper = ClassicalPipelineWrapper(
                name="üèÜ –õ—É—á—à–∞—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å",
                model=model,
                task_type=main_task_type,
                label_field=main_task_type,
                real_classes=real_classes,
                vectorizer=vectorizer
            )
            pipelines.append(wrapper)
    
    # 3. –ú–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 4 (–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ)
    if st.session_state.get("neural_models"):
        for model_name, model in st.session_state.neural_models.items():
            if hasattr(model, 'predict'):
                wrapper = NeuralPipelineWrapper(
                    name=f"–≠—Ç–∞–ø 4: {model_name}",
                    model=model,
                    task_type=main_task_type,
                    label_field=main_task_type,
                    real_classes=real_classes
                )
                pipelines.append(wrapper)
    
    # 4. –ú–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–∞–ø–∞ 5 (—Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π)
    if st.session_state.get("balanced_models"):
        for model_key, model in st.session_state.balanced_models.items():
            if hasattr(model, 'predict'):
                wrapper = ClassicalPipelineWrapper(
                    name=f"–≠—Ç–∞–ø 5: {model_key}",
                    model=model,
                    task_type=main_task_type,
                    label_field=main_task_type,
                    real_classes=real_classes,
                    vectorizer=vectorizer
                )
                pipelines.append(wrapper)
    
    # 5. –ú–æ–¥–µ–ª—å –∏–∑ —ç—Ç–∞–ø–∞ 6 (–Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è)
    if st.session_state.get("best_tuned_model"):
        model = st.session_state.best_tuned_model
        if hasattr(model, 'predict'):
            wrapper = ClassicalPipelineWrapper(
                name="‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–≠—Ç–∞–ø 6)",
                model=model,
                task_type=main_task_type,
                label_field=main_task_type,
                real_classes=real_classes,
                vectorizer=vectorizer
            )
            pipelines.append(wrapper)
    
    # 6. –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å –∏–∑ —ç—Ç–∞–ø–∞ 7
    if st.session_state.get("champion_model"):
        model = st.session_state.champion_model
        champion_stage = st.session_state.get("champion_stage", "–≠—Ç–∞–ø ?")
        if hasattr(model, 'predict'):
            wrapper = ClassicalPipelineWrapper(
                name=f"üëë –ß–µ–º–ø–∏–æ–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å ({champion_stage})",
                model=model,
                task_type=main_task_type,
                label_field=main_task_type,
                real_classes=real_classes,
                vectorizer=vectorizer
            )
            pipelines.append(wrapper)
    
    # 7. –î–µ–º–æ-–º–æ–¥–µ–ª–∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á (–µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö)
    if not pipelines:
        st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –°–æ–∑–¥–∞–Ω—ã –¥–µ–º–æ-–º–æ–¥–µ–ª–∏.")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –¥–µ–º–æ-–º–æ–¥–µ–ª—å
        class DemoModel:
            def predict(self, X):
                return np.zeros(len(X))
            def predict_proba(self, X):
                return np.array([[0.7, 0.3]] * len(X))
        
        demo_model = DemoModel()
        
        # –î–µ–º–æ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
        demo_tasks = [
            ('sentiment', ['–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π', '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π', '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π']),
            ('category', ['–ü–æ–ª–∏—Ç–∏–∫–∞', '–≠–∫–æ–Ω–æ–º–∏–∫–∞', '–°–ø–æ—Ä—Ç', '–ù–∞—É–∫–∞']),
            ('multilabel', ['–í–∞–∂–Ω–æ–µ', '–°—Ä–æ—á–Ω–æ–µ', '–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ', '–ü–æ–ª–µ–∑–Ω–æ–µ'])
        ]
        
        for task_type, classes in demo_tasks:
            wrapper = ClassicalPipelineWrapper(
                name=f"–î–µ–º–æ: {task_type}",
                model=demo_model,
                task_type=task_type,
                label_field=task_type,
                real_classes=classes,
                vectorizer=None
            )
            pipelines.append(wrapper)
    
    return pipelines


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç—Ç–∞–ø–∞ 8"""
    
    st.set_page_config(
        page_title="–≠—Ç–∞–ø 8: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
        page_icon="üîç",
        layout="wide"
    )
    
    st.title("üîç –≠—Ç–∞–ø 8: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
    st.markdown("""
    ### üìã –û–±–∑–æ—Ä —ç—Ç–∞–ø–∞
    
    –≠—Ç–æ—Ç —ç—Ç–∞–ø –ø–æ–∑–≤–æ–ª—è–µ—Ç:
    1. **–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç** –≤—Å–µ–º–∏ –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
    2. **–°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
    3. **–í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å** –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö
    4. **–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    
    ---
    """)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    if not st.session_state.get("step7_completed", False):
        st.warning("""
        ‚ö†Ô∏è **–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —ç—Ç–∞–ø—ã!**
        
        –î–ª—è —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–≥–æ —ç—Ç–∞–ø–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:
        1. ‚úÖ –≠—Ç–∞–ø 3: –û–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏
        2. ‚úÖ –≠—Ç–∞–ø 4: –û–±—É—á–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        3. ‚úÖ –≠—Ç–∞–ø 5: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤
        4. ‚úÖ –≠—Ç–∞–ø 6: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        5. ‚úÖ –≠—Ç–∞–ø 7: –í—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        
        –í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º —ç—Ç–∞–ø–∞–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.
        """)
        
        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞
        if st.button("üîÑ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π"):
            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å
            pipelines = build_pipelines_from_stages()
            if pipelines:
                st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(pipelines)} –º–æ–¥–µ–ª–µ–π. –ú–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å.")
                st.session_state.step7_completed = True
                st.rerun()
            else:
                st.error("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–∞—Ö.")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è UI
    ui = InteractiveAnalysisUI()
    
    # –°–±–æ—Ä –º–æ–¥–µ–ª–µ–π –∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤
    with st.spinner("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª–∏ –∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤..."):
        pipelines = build_pipelines_from_stages()
    
    if not pipelines:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤.")
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–µ–π
    ui.render_model_statistics(pipelines)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = InteractiveModelAnalyzer(pipelines)
    ui.analyzer = analyzer
    
    # –†–µ–Ω–¥–µ—Ä –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    settings = ui.render_sidebar()
    
    # –†–µ–Ω–¥–µ—Ä –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
    text_input, analyze_button = ui.render_text_input()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≤ session_state
    if text_input:
        st.session_state.interactive_text = text_input
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
    if analyze_button and text_input:
        with st.spinner(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç {len(pipelines)} –º–æ–¥–µ–ª—è–º–∏..."):
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            task_filter = None if settings['selected_task'] == 'all' else settings['selected_task']
            results = analyzer.analyze_text(text_input, task_filter)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if results:
                ui.render_results(text_input, results, settings)
                ui.render_comparison_analysis(results)
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö
    with st.expander("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"):
        model_info = []
        for pipe in pipelines:
            model_info.append({
                '–ù–∞–∑–≤–∞–Ω–∏–µ': pipe.name,
                '–¢–∏–ø –º–æ–¥–µ–ª–∏': pipe.model_type,
                '–¢–∏–ø –∑–∞–¥–∞—á–∏': pipe.task_type,
                '–ö–ª–∞—Å—Å—ã': len(pipe.real_classes),
                'predict_proba': "‚úÖ" if pipe.has_predict_proba else "‚ùå"
            })
        
        if model_info:
            st.dataframe(pd.DataFrame(model_info), use_container_width=True)
        else:
            st.info("–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    st.session_state.ep8_pipelines = pipelines
    st.session_state.ep8_completed = True
    
    st.success("‚úÖ –≠—Ç–∞–ø 8 –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –∏ –Ω–∞–∂–º–∏—Ç–µ '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å'")


if __name__ == "__main__":
    main()