"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/validation/test
—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from collections import Counter
import json
from typing import Dict, List, Tuple, Any
import traceback
import os


class StratifiedDataSplitter:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, seed: int = 42):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞
        
        Args:
            seed: —Å–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        """
        self.seed = seed
        np.random.seed(seed)
        self.splits = None
        print(f"üé≤ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω StratifiedDataSplitter —Å seed={seed}")
    
    def split_stratified(self, 
                        data: List[Dict], 
                        train_ratio: float = 0.7, 
                        val_ratio: float = 0.15,
                        test_ratio: float = 0.15,
                        stratify_column: str = 'category',
                        save_splits: bool = True,
                        output_dir: str = "data_splits") -> Dict[str, List[Dict]]:
        """
        –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        
        Args:
            data: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏
            train_ratio: –¥–æ–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            val_ratio: –¥–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            test_ratio: –¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            stratify_column: –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            save_splits: —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–¥–µ–ª—ã –Ω–∞ –¥–∏—Å–∫
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            —Å–ª–æ–≤–∞—Ä—å —Å —Ä–∞–∑–±–∏—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {'train': [...], 'validation': [...], 'test': [...]}
        """
        print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ {len(data)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìä –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è: train={train_ratio}, val={val_ratio}, test={test_ratio}")
        print(f"üè∑Ô∏è –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–æ–ª–æ–Ω–∫–µ: {stratify_column}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π
        total_ratio = train_ratio + val_ratio + test_ratio
        if abs(total_ratio - 1.0) > 0.001:
            print(f"‚ö†Ô∏è –°—É–º–º–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π {total_ratio} != 1.0, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º...")
            train_ratio = train_ratio / total_ratio
            val_ratio = val_ratio / total_ratio
            test_ratio = test_ratio / total_ratio
        
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
            df = pd.DataFrame(data)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω DataFrame: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
            
            if df.empty:
                print("‚ö†Ô∏è DataFrame –ø—É—Å—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Ä–∞–∑–¥–µ–ª—ã")
                return {'train': [], 'validation': [], 'test': []}
            
            # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
            if stratify_column not in df.columns:
                print(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ '{stratify_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É—é —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ.")
                return self._split_random(data, train_ratio, val_ratio, test_ratio)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            df[stratify_column] = df[stratify_column].astype(str)
            
            # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            categories = df[stratify_column].unique()
            print(f"üìä –ö–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {len(categories)}")
            
            if len(categories) == 0:
                print("‚ö†Ô∏è –ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—é —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
                return self._split_random(data, train_ratio, val_ratio, test_ratio)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –æ—Ç–¥–µ–ª—å–Ω–æ
            train_data = []
            val_data = []
            test_data = []
            
            category_stats = {}
            
            for category in categories:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_df = df[df[stratify_column] == category].copy()
                category_records = category_df.to_dict('records')
                category_count = len(category_records)
                
                if category_count < 3:
                    # –ï—Å–ª–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤ train
                    print(f"  ‚ö†Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ({category_count}), –¥–æ–±–∞–≤–ª—è–µ–º –≤ train")
                    train_data.extend(category_records)
                    category_stats[category] = {'train': category_count, 'validation': 0, 'test': 0}
                    continue
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ä–∞–∑–¥–µ–ª–æ–≤
                train_size = max(1, int(category_count * train_ratio))
                test_size = max(1, int(category_count * test_ratio))
                val_size = category_count - train_size - test_size
                
                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞
                if val_size < 0:
                    val_size = 0
                    train_size = category_count - test_size
                
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                try:
                    np.random.shuffle(category_records)
                    
                    train_data.extend(category_records[:train_size])
                    val_data.extend(category_records[train_size:train_size + val_size])
                    test_data.extend(category_records[train_size + val_size:])
                    
                    category_stats[category] = {
                        'train': train_size,
                        'validation': val_size,
                        'test': test_size
                    }
                    
                except Exception as e:
                    print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {e}")
                    # –ü—Ä–æ—Å—Ç–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                    train_data.extend(category_records[:train_size])
                    val_data.extend(category_records[train_size:train_size + val_size])
                    test_data.extend(category_records[train_size + val_size:])
            
            # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–±–æ—Ä—ã
            np.random.shuffle(train_data)
            np.random.shuffle(val_data)
            np.random.shuffle(test_data)
            
            self.splits = {
                'train': train_data,
                'validation': val_data,
                'test': test_data
            }
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._print_statistics(category_stats, train_data, val_data, test_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if save_splits:
                self._save_splits(output_dir)
            
            return self.splits
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏: {e}")
            print(traceback.format_exc())
            return self._split_random(data, train_ratio, val_ratio, test_ratio)
    
    def _split_random(self, data: List[Dict], train_ratio: float, val_ratio: float, test_ratio: float) -> Dict[str, List[Dict]]:
        """–ü—Ä–æ—Å—Ç–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"""
        print("üé≤ –ò—Å–ø–æ–ª—å–∑—É—é —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ...")
        
        np.random.shuffle(data)
        
        n = len(data)
        train_end = int(n * train_ratio)
        val_end = train_end + int(n * val_ratio)
        
        train_data = data[:train_end]
        val_data = data[train_end:val_end]
        test_data = data[val_end:]
        
        self.splits = {
            'train': train_data,
            'validation': val_data,
            'test': test_data
        }
        
        print(f"üìä –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ:")
        print(f"  Train: {len(train_data)} –∑–∞–ø–∏—Å–µ–π ({len(train_data)/n*100:.1f}%)")
        print(f"  Validation: {len(val_data)} –∑–∞–ø–∏—Å–µ–π ({len(val_data)/n*100:.1f}%)")
        print(f"  Test: {len(test_data)} –∑–∞–ø–∏—Å–µ–π ({len(test_data)/n*100:.1f}%)")
        
        return self.splits
    
    def _save_splits(self, output_dir: str = "data_splits"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –Ω–∞ –¥–∏—Å–∫"""
        if not self.splits:
            print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        for split_name, data in self.splits.items():
            filename = os.path.join(output_dir, f"{split_name}.jsonl")
            with open(filename, 'w', encoding='utf-8') as f:
                for item in data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω {split_name} –Ω–∞–±–æ—Ä: {filename} ({len(data)} –∑–∞–ø–∏—Å–µ–π)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'splits': {k: len(v) for k, v in self.splits.items()},
            'seed': self.seed,
            'total_records': sum(len(v) for v in self.splits.values()),
            'created_at': pd.Timestamp.now().isoformat()
        }
        
        metadata_file = os.path.join(output_dir, "split_metadata.json")
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω–∞—è: {metadata_file}")
    
    def load_splits(self, input_dir: str = "data_splits") -> Dict[str, List[Dict]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–¥–µ–ª–æ–≤ —Å –¥–∏—Å–∫–∞"""
        splits = {}
        
        for split_name in ['train', 'validation', 'test']:
            filename = os.path.join(input_dir, f"{split_name}.jsonl")
            if os.path.exists(filename):
                data = []
                with open(filename, 'r', encoding='utf-8') as f:
                    for line in f:
                        data.append(json.loads(line.strip()))
                splits[split_name] = data
                print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω {split_name} –Ω–∞–±–æ—Ä: {filename} ({len(data)} –∑–∞–ø–∏—Å–µ–π)")
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                splits[split_name] = []
        
        self.splits = splits
        return splits
    
    def _print_statistics(self, category_stats: Dict, train_data: List[Dict], val_data: List[Dict], test_data: List[Dict]):
        """–ü–µ—á–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"""
        
        print(f"\n{'='*60}")
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ó–î–ï–õ–ï–ù–ò–Ø –î–ê–ù–ù–´–•")
        print('='*60)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_train = len(train_data)
        total_val = len(val_data)
        total_test = len(test_data)
        total = total_train + total_val + total_test
        
        print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total}")
        print(f"  Train: {total_train} ({total_train/total*100:.1f}%)")
        print(f"  Validation: {total_val} ({total_val/total*100:.1f}%)")
        print(f"  Test: {total_test} ({total_test/total*100:.1f}%)")
        
        print(f"\n{'='*60}")
        print("‚úÖ –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print('='*60)
    
    def get_split_statistics_df(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –≤–∏–¥–µ DataFrame"""
        if not self.splits:
            return pd.DataFrame()
        
        stats = []
        for split_name, data in self.splits.items():
            if data:
                df = pd.DataFrame(data)
                if 'category' in df.columns:
                    category_counts = df['category'].value_counts()
                    for category, count in category_counts.items():
                        stats.append({
                            'split': split_name,
                            'category': category,
                            'count': count
                        })
        
        return pd.DataFrame(stats)